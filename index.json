[{"categories":["月霜天的小笔记"],"content":"一、什么是幂等？ 幂等（idempotent、idempotence）是一个数学与计算机学概念，常见于抽象代数中。 在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“setTrue()”函数就是一个幂等函数,无论多次执行，其结果都是一样的.更复杂的操作幂等保证是利用唯一交易号(流水号)实现。 幂等性：就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:1:0","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"二、使用场景 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:2:0","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"1、前端重复提交 用户注册，用户创建商品等操作，前端都会提交一些数据给后台服务，后台需要根据用户提交的数据在数据库中创建记录。如果用户不小心多点了几次，后端收到了好几次提交，这时就会在数据库中重复创建了多条记录。这就是接口没有幂等性带来的 bug。 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:2:1","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"2、接口超时重试 对于给第三方调用的接口，有可能会因为网络原因而调用失败，这时，一般在设计的时候会对接口调用加上失败重试的机制。如果第一次调用已经执行了一半时，发生了网络异常。这时再次调用时就会因为脏数据的存在而出现调用异常。 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:2:2","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"3、消息重复消费 在使用消息中间件来处理消息队列，且手动 ack 确认消息被正常消费时。如果消费者突然断开连接，那么已经执行了一半的消息会重新放回队列。 当消息被其他消费者重新消费时，如果没有幂等性，就会导致消息重复消费时结果异常，如数据库重复数据，数据库数据冲突，资源重复等。 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:2:3","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"三、解决方案 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:3:0","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"1、token机制 通过token 机制实现接口的幂等性,这是一种比较通用性的实现方法。 流程： 1、客户端会先发送一个请求去获取 token，服务端会生成一个全局唯一的 ID 作为 token 保存在 redis 中，同时把这个 ID 返回给客户端 2、客户端第二次调用业务请求的时候必须携带这个 token 3、服务端会校验这个 token，如果校验成功，则执行业务，并删除 redis 中的 token 4、如果校验失败，说明 redis 中已经没有对应的 token，则表示重复操作，直接返回指定的结果给客户端 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:3:1","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"2、mysql锁 这种实现方式是利用 mysql 唯一索引的特性 流程： 1、建立一张去重表，其中某个字段需要建立唯一索引 2、客户端去请求服务端，服务端会将这次请求的一些信息插入这张去重表中 3、因为表中某个字段带有唯一索引，如果插入成功，证明表中没有这次请求的信息，则执行后续的业务逻辑 4、如果插入失败，则代表已经执行过当前请求，直接返回 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:3:2","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"3、redis锁 这种实现方式是基于 SETNX 命令实现的 流程： 1、客户端先请求服务端，会拿到一个能代表这次请求业务的唯一字段 2、将该字段以 SETNX 的方式存入 redis 中，并根据业务设置相应的超时时间 3、如果设置成功，证明这是第一次请求，则执行后续的业务逻辑 4、如果设置失败，则代表已经执行过当前请求，直接返回 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:3:3","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"总结 这几种实现幂等的方式其实都是大同小异的，类似的还有使用状态机、悲观锁、乐观锁的方式来实现，都是比较简单的。 类似于分布锁： 数据库锁，一个表中包含方法名等字段，并在方法名字段上创建唯一索引 redis锁，setnx为锁添加一个超时时间 zookeeper锁：创建目录，在目录下创建临时顺序节点，获取最小顺序节点号 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:4:0","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的GO"],"content":"在标准库中有个sync/errgroup，实现对多goroutine进行错误处理。 接下来我们看一下源码： type Group struct { cancel func() wg sync.WaitGroup errOnce sync.Once err error } func WithCancel(ctx context.Context) (*Group, context.Context) { ctx, cancel := context.WithCancel(ctx) return \u0026Group{cancel: cancel}, ctx } func (g *Group) Wait() error { g.wg.Wait() if g.cancel != nil { g.cancel() } return g.err } func (g *Group) Go(f func() error) { g.wg.Add(1) go func() { defer g.wg.Done() if err := f(); err != nil { g.errOnce.Do(func() { g.err = err if g.cancel != nil { g.cancel() } }) } }() } 很简单的实现，使用sync.WaitGroup做并发控制，用sync.Once做错误返回，使用context做上下文的处理。 ","date":"2021-07-05","objectID":"/2021/07/errgroup%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/:0:0","tags":["sync","errgroup"],"title":"Errgroup的实际应用","uri":"/2021/07/errgroup%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/"},{"categories":["月霜天的GO"],"content":"例子一 func main() { g := new(errgroup.Group) var urls = []string{ \"http://www.golang.org/\", \"https://golang2.eddycjy.com/\", \"https://eddycjy.com/\", } for _, url := range urls { url := url g.Go(func() error { resp, err := http.Get(url) if err == nil { resp.Body.Close() } return err }) } if err := g.Wait(); err == nil { fmt.Println(\"Successfully fetched all URLs.\") } else { fmt.Printf(\"Errors: %+v\", err) } } ","date":"2021-07-05","objectID":"/2021/07/errgroup%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/:1:0","tags":["sync","errgroup"],"title":"Errgroup的实际应用","uri":"/2021/07/errgroup%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/"},{"categories":["月霜天的GO"],"content":"例子二 func main() { g, ctx := errgroup.WithContext(context.Background()) svr := http.NewServer() // http server g.Go(func() error { fmt.Println(\"http\") go func() { \u003c-ctx.Done() fmt.Println(\"http ctx done\") svr.Shutdown(context.TODO()) }() return svr.Start() }) // signal g.Go(func() error { exitSignals := []os.Signal{os.Interrupt, syscall.SIGTERM, syscall.SIGQUIT, syscall.SIGINT} // SIGTERM is POSIX specific sig := make(chan os.Signal, len(exitSignals)) signal.Notify(sig, exitSignals...) for { fmt.Println(\"signal\") select { case \u003c-ctx.Done(): fmt.Println(\"signal ctx done\") return ctx.Err() case \u003c-sig: // do something return nil } } }) // inject error g.Go(func() error { fmt.Println(\"inject\") time.Sleep(time.Second) fmt.Println(\"inject finish\") return errors.New(\"inject error\") }) err := g.Wait() // first error return fmt.Println(err) } ","date":"2021-07-05","objectID":"/2021/07/errgroup%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/:2:0","tags":["sync","errgroup"],"title":"Errgroup的实际应用","uri":"/2021/07/errgroup%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/"},{"categories":["月霜天的GO"],"content":"虽然golang的定时器经过几版的改进优化，但是仍然是性能的大杀手。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:0:0","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"golang1.13和1.14的区别 golang在1.10版本之前是由一个独立的timerproc通过小顶堆和futexsleep来管理定时任务。1.10版本之后是把独立的timerproc和小顶堆分成最多64个timerproc协程和四叉堆，用来休眠的方式还是 futexsleep 而1.14版的timer是把存放定时事件的四叉堆放到了P结构中，同时取消了timerproc协程，转而使用netpoll的epoll wait来做就近时间的休眠等待。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:1:0","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"函数签名 对于NewTimer函数，我们可以找到实现 time/sleep.go#L82。其实我们可以发现，NewTimer、NewTicker、After其实都是调用addTimer来新增定时任务。 type Timer struct { C \u003c-chan Time r runtimeTimer } // NewTimer creates a new Timer that will send // the current time on its channel after at least duration d. func NewTimer(d Duration) *Timer { c := make(chan Time, 1) t := \u0026Timer{ C: c, r: runtimeTimer{ when: when(d), f: sendTime, arg: c, }, } startTimer(\u0026t.r) return t } func sendTime(c interface{}, seq uintptr) { select { case c.(chan Time) \u003c- Now(): default: } } func NewTicker(d Duration) *Ticker { if d \u003c= 0 { panic(errors.New(\"non-positive interval for NewTicker\")) } c := make(chan Time, 1) t := \u0026Ticker{ C: c, r: runtimeTimer{ when: when(d), period: int64(d), f: sendTime, arg: c, }, } startTimer(\u0026t.r) return t } 这里主要分成两步： 1、创建一个Timer对象，包含一个具有缓冲区channel的c，用来接收Timer消息的，包含的runtimeTimer结构体，when是代表timer触发的绝对时间(当前时间+d)，f是timer触发时的回调函数，arg是传给f的参数。 2、调用startTimer，实际上是调用runtime包下的addtimer函数。 3、NewTicker调用的是相同的函数，只是多了一个字段period，表示计时器再次被唤醒的时间，做轮询触发。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:2:0","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"golang1.13的定时器原理 首先会初始化一个长度为64的timers数组，通过协程的p的id取模来分配timersBucket，如果发现新的定时任务比较新，那么调用notewakeup来激活唤醒timerproc的futex等待。如果发现没有实例化timerproc，则启动。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:0","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"1、添加定时器 func addtimer(t *timer) { tb := t.assignBucket() lock(\u0026tb.lock) ok := tb.addtimerLocked(t) unlock(\u0026tb.lock) if !ok { badTimer() } } 可以看到addtimer做了两件事： 1、assignBucket找到可以被插入的bucket 2、addtimerLocked将timer插入到bucket ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:1","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"2、timersBucket const timersLen = 64 // timer包含每个P的堆，timer进入队列中关联当前的P，所以每个P中timer都是独立于其他P的 // 如果GOMAXPROCS \u003e timersLen，那么timersBucket可能会管理多个P var timers [timersLen]struct { timersBucket // 内存对齐 pad [cpu.CacheLinePadSize - unsafe.Sizeof(timersBucket{})%cpu.CacheLinePadSize]byte } type timersBucket struct { lock mutex gp *g created bool sleeping bool rescheduling bool sleepUntil int64 waitnote note t []*timer } 在runtime中，有64个全局定义的timer bucket。每个bucket负责管理timer。timer的整个生命周期包括创建、销毁、唤醒、睡眠等都是由timer bucket管理和调度。 问：为什么是64个timer bucket? 答：在1.10版本之前，只有1个timers对象，在添加定时器任务时都需要对timers进行加锁和解锁操作，影响性能；当timer过多，timers中的t很多，添加进四叉堆操作可能耗时比较长，可能会导致timer的延迟。因此引入全局64个分桶的策略，将timer分散到桶中，每个桶只负责自己的timer，有效降低了锁的粒度和timer调度的负担。 而根据最优的情况下，应该是分桶的数量应该要和GOMAXPROCS数量一致，有多少个P就有多少个timer bucket。但是，这就涉及到P的动态分配问题，所以在性能的权衡下，使用64 能够覆盖大多数的场景。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:2","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"3、分配桶 func (t *timer) assignBucket() *timersBucket { id := uint8(getg().m.p.ptr().id) % timersLen t.tb = \u0026timers[id].timersBucket return t.tb } ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:3","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"4、添加timer到四叉堆 func (tb *timersBucket) addtimerLocked(t *timer) bool { // 此时when应该是当前时间+duration if t.when \u003c 0 { t.when = 1\u003c\u003c63 - 1 } // 将timer添加到四叉堆中 t.i = len(tb.t) tb.t = append(tb.t, t) if !siftupTimer(tb.t, t.i) { return false } // 首次添加 if t.i == 0 { // 如果timerproc在sleep，唤醒它 if tb.sleeping \u0026\u0026 tb.sleepUntil \u003e t.when { tb.sleeping = false notewakeup(\u0026tb.waitnote) } // 如果timerproc被挂起了，重新调度 if tb.rescheduling { tb.rescheduling = false goready(tb.gp, 0) } // 如果timer的桶还没有创建，创建并开始timerproc if !tb.created { tb.created = true go timerproc(tb) } } return true } 问：为什么是四叉堆？ 答：上推节点的操作更快；对缓存更友好。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:4","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"5、timerproc // timerproc 外层循环不会退出 func timerproc(tb *timersBucket) { tb.gp = getg() for { lock(\u0026tb.lock) // 修改睡眠标识 tb.sleeping = false // 当前时间 now := nanotime() delta := int64(-1) for { // 如果桶内没有timer，退出 if len(tb.t) == 0 { delta = -1 break } // 获取最早触发的timer t := tb.t[0] delta = t.when - now // 还没有到达触发时间，退出 if delta \u003e 0 { break } ok := true if t.period \u003e 0 { // 需要周期性触发定时器，需要修改timer的触发时间，重新添加到最小堆中 // leave in heap but adjust next time to fire t.when += t.period * (1 + -delta/t.period) if !siftdownTimer(tb.t, 0) { ok = false } } else { // 从最小堆中移除 last := len(tb.t) - 1 if last \u003e 0 { tb.t[0] = tb.t[last] tb.t[0].i = 0 } tb.t[last] = nil tb.t = tb.t[:last] if last \u003e 0 { if !siftdownTimer(tb.t, 0) { ok = false } } t.i = -1 // 下标标记为-1，deltimer发现下标为-1时就不删除了 } f := t.f arg := t.arg seq := t.seq unlock(\u0026tb.lock) if !ok { badTimer() } if raceenabled { raceacquire(unsafe.Pointer(t)) } f(arg, seq) lock(\u0026tb.lock) } if delta \u003c 0 || faketime \u003e 0 { // 如果桶中没有timer，把协程挂起 tb.rescheduling = true goparkunlock(\u0026tb.lock, waitReasonTimerGoroutineIdle, traceEvGoBlock, 1) continue } // 如果还有timer，睡眠到桶内最早触发的时间点后唤醒 tb.sleeping = true tb.sleepUntil = now + delta noteclear(\u0026tb.waitnote) unlock(\u0026tb.lock) notetsleepg(\u0026tb.waitnote, delta) } } ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:5","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"6、小结 1、首选预分配64个的timer bucket，timer bucket里面是一个四叉堆存放timer 2、每次新增的timer，添加到四叉堆中，会尝试唤醒和调度bucket 3、第一次新增的bucket会运行协程timerproc。timerproc是一个死循环，周期性地检查定时器状态。 4、每次从最小堆中取出timer，如果是计时器，则重新加入到bucket中。如果bucket没有timer，则将timerproc挂起。如果还有timer，则睡眠到bucket中堆顶唤醒的时间。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:6","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"深度分析golang1.14定时器 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:0","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"1、timer type timer struct { // If this timer is on a heap, which P's heap it is on. // puintptr rather than *p to match uintptr in the versions // of this struct defined in other packages. pp puintptr // 计时器所在的处理器P的指针地址 // Timer wakes up at when, and then at when+period, ... (period \u003e 0 only) // each time calling f(arg, now) in the timer goroutine, so f must be // a well-behaved function and not block. when int64 // 计时器被唤醒的时间 period int64 // 计时器再次被唤醒的时间（周期） f func(interface{}, uintptr) // 回调函数，每次在计时器被唤醒时都会调用 arg interface{} // 回调函数的参数 seq uintptr // 回调函数的参数，仅在netpoll的应用场景下使用 // What to set the when field to in timerModifiedXX status. nextwhen int64 // 当计时器状态为timerModifiedXX时，将会使用nextwhen设置到where字段上 // The status field holds one of the values below. status uint32 // 计时器当前的状态值 } ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:1","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"2、p 在添加方式上，go1.14发生了变更，改为将每个timer存储在处理器p上。这也是我们之前提到的优化结构，64只能泛指大多数情况，实际都是需要p进行处理。所以go1.14里的p结构中有了timers字段。 type p struct { ... timersLock mutex timers []*timer ... } 同样，在timers数组仍是一个最小四叉堆。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:2","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"3、定时器状态 // Values for the timer status field. const ( // timer尚未设置状态 timerNoStatus = iota // 等待timer启动 timerWaiting // 运行timer的回调方法 timerRunning // timer已经被删除，但仍然在某些p的堆中 timerDeleted // timer即将被删除 timerRemoving // timer已经停止，且不存在任何p的堆中 timerRemoved // timer正在被修改 timerModifying // timer已被修改为更早的时间，新的时间被设置在nextwhen字段中， timerModifiedEarlier // timer已被修改为更迟的时间，新的时间被设置在nextwhen字段中， timerModifiedLater // timer已经被修改，正在被移动 timerMoving ) 因为涉及到p的管理，所以新增了10个timer的状态管理。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:3","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"4、启动定时器 func addtimer(t *timer) { // when must never be negative; otherwise runtimer will overflow // during its delta calculation and never expire other runtime timers. // 边界条件判断 if t.when \u003c 0 { t.when = maxWhen } // timer的状态为timerNoStatus if t.status != timerNoStatus { throw(\"addtimer called with initialized timer\") } t.status = timerWaiting when := t.when pp := getg().m.p.ptr() lock(\u0026pp.timersLock) // 清除处理器p中的计时器队列，可以加快创建和删除计时器的程序的速度 cleantimers(pp) // 将当前所新创建的timer新增到p的堆中 doaddtimer(pp, t) unlock(\u0026pp.timersLock) // 唤醒网络轮询器中休眠的线程，检查timer被唤醒的时间(when)是否在当前轮询预期运行的时间(pollerPollUntil)内，若是则唤醒 wakeNetPoller(when) } 添加timer到当前的p上，这应该只在一个新创建的timer中调用，这避免了更改某些p的最小堆timer的when字段的风险，因为这可能导致最小堆乱序。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:4","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"5、停止定时器 在定时器的运行中，一般会调用timer.Stop方法来停止/删除定时器，其实就是让这个timer从处理器p的堆中移除。 timerWaiting/timerModifiedLater：修改timer状态为timerDeleted，删除数量+1 timerModifiedEarlier：修改timer状态为timerDeleted，删除数量+1，adjustTimers+1 timerDeleted/timerRemoving/timerRemoved：无需变更，已经满足条件 timerRunning/timerMoving/timerModifying：正在执行、移动中，无法停止，等待下一次状态检查再处理 timerNoStatus：无法停止，不满足条件 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:5","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"6、修改/重置定时器 在程序调度中，有些因为逻辑改变，需要重置定时器。一般会调用timer.Reset()来重设Duration值。 func resettimer(t *timer, when int64) { modtimer(t, when, t.period, t.f, t.arg, t.seq) } 实际调用modtimer方法。 timerRunning/timerRemoving/timerMoving/timerModifying：等待状态改变 timerDeleted-\u003etimerModifying-\u003etimerModifiedXXX timerNoStatus/timerRemoved-\u003etimerModifying-\u003etimerWaiting timerWaiting/timerModifiedXXX-\u003etimerModifying-\u003etimerModifiedXXX 在处理完处理器的状态后，会分为两种情况进行处理： 1、待修改的定时器已经被删除：由于原定时器没有了，所以会调用doaddtimer方法创建一个定时器，并赋值原先的timer，再调用wakeNetPoller在预定的时间唤醒网络轮询器 2、正常逻辑处理：如果修改后的定时器的触发时间小于原本的触发是按，则修改定时器状态为timerModifiedEalier，并调用wakeNetPoller在预定的时间唤醒网络轮询器 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:6","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"7、触发定时器 前面提到过，timers已经归属到p中去了，所以定时器的触发分成两个部分： 通过调度器在调度时进行定时器的触发 通过系统监控检查并触发定时器（到期未执行） 1、调度器触发 调度器触发一般分为两种情况。 一种是调度循环中调用checkTimers方法进行计时器的触发 func schedule() { _g_ := getg() ... top: pp := _g_.m.p.ptr() pp.preempt = false ... checkTimers(pp, 0) ... execute(gp, inheritTime) } 另一种是当前处理器p没有可执行的timer，且没有可执行的G。那么按照调度模型，就会去窃取其他定时器和G: func findrunnable() (gp *g, inheritTime bool) { _g_ := getg() ... top: _p_ := _g_.m.p.ptr() ... now, pollUntil, _ := checkTimers(_p_, 0) ... } 我们来进一步分析checkTimers方法： 1、检查处理器p上是否有需要处理的timer 2、如果没有需要执行的timer，则直接返回；否则，判断标记为删除的timer数量如果小于p上的timer数量则直接返回 3、对需要处理的timer，根据时间将timers重新排序 4、在调整完timers后，调用runtimer方法真正执行timer，触发定时器 5、在最后的阶段，如果被标记为删除的timer数量如果大于p上的timer数量，则对标记为删除的timer进行清理。 2、系统监控触发 通过每次调度器调度和窃取的是否触发，还是有一定的随机性。 因此需要一个系统监控来触发定时器。 func sysmon() { ... for { ... next, _ := timeSleepUntil() if debug.schedtrace \u003c= 0 \u0026\u0026 (sched.gcwaiting != 0 || atomic.Load(\u0026sched.npidle) == uint32(gomaxprocs)) { lock(\u0026sched.lock) if atomic.Load(\u0026sched.gcwaiting) != 0 || atomic.Load(\u0026sched.npidle) == uint32(gomaxprocs) { if next \u003e now { atomic.Store(\u0026sched.sysmonwait, 1) unlock(\u0026sched.lock) // Make wake-up period small enough // for the sampling to be correct. sleep := forcegcperiod / 2 if next-now \u003c sleep { sleep = next - now } shouldRelax := sleep \u003e= osRelaxMinNS if shouldRelax { osRelax(true) } notetsleep(\u0026sched.sysmonnote, sleep) if shouldRelax { osRelax(false) } now = nanotime() next, _ = timeSleepUntil() lock(\u0026sched.lock) atomic.Store(\u0026sched.sysmonwait, 0) noteclear(\u0026sched.sysmonnote) } idle = 0 delay = 20 } unlock(\u0026sched.lock) } ... // poll network if not polled for more than 10ms lastpoll := int64(atomic.Load64(\u0026sched.lastpoll)) if netpollinited() \u0026\u0026 lastpoll != 0 \u0026\u0026 lastpoll+10*1000*1000 \u003c now { atomic.Cas64(\u0026sched.lastpoll, uint64(lastpoll), uint64(now)) list := netpoll(0) // non-blocking - returns list of goroutines if !list.empty() { incidlelocked(-1) injectglist(\u0026list) incidlelocked(1) } } if next \u003c now { startm(nil, false) } ... } } 1、在每次系统监控时，都会在流程上调用timeSleepUntil方法去获取下一个定时器应触发的时间，以及保存改定时器已经打开的定时器堆的p. 2、检查当前是否存在GC，若正在STW则获取调度互斥锁。若发现下一个timer触发时间已经过去，则重新调用timeSleepUntil获取下一个定时器的时间和相应的p。 3、如果发现超过10ms没有进行netpoll网络轮询，则主动调用netpoll方法触发轮询 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:7","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"8、运行定时器 这里来分析一下runtimer方法： 只有被标记为timerWaiting状态的定时器才能运行，尝试将状态更新为timerRunning，然后执行runOneTimer方法。 标记为timerDeleted状态的定时器会去删除定时器，标记为timerModifiedXXX状态的定时器会去重新添加定时器。 func runOneTimer(pp *p, t *timer, now int64) { f := t.f arg := t.arg seq := t.seq if t.period \u003e 0 { // ticker，需要再次触发 // 重新计算下一次的触发时间，并且更新其在最小堆 delta := t.when - now t.when += t.period * (1 + -delta/t.period) siftdownTimer(pp.timers, 0) // 将状态修改为timerWaiting if !atomic.Cas(\u0026t.status, timerRunning, timerWaiting) { badTimer() } // 设置p的下一次触发时间 updateTimer0When(pp) } else { // 移除timer dodeltimer0(pp) if !atomic.Cas(\u0026t.status, timerRunning, timerNoStatus) { badTimer() } } unlock(\u0026pp.timersLock) // 回调方法 f(arg, seq) lock(\u0026pp.timersLock) } ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:8","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"9、小结 通过大致的go1.14源码分析，可以看出有以下改变： 在每个处理器p中，timers以最小四叉堆方式存储 在调度器的每轮跳读中都会对定时器进行触发和检查 在系统监听netpoll会定时进行定时器的触发和检查 在定时器的处理中，10个状态的流转和处理变化 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:9","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"总结 go1.13最多可以开到GOMAXPROCS数量的timerproc协程，当然不超过64。但我们要知道timerproc自身就是协程，也需要runtime pmg的调度。反而go 1.14把检查到期定时任务的工作交给了runtime.schedule，不需要额外的调度，每次runtime.schedule和findrunable时直接运行到期的定时任务。 线程上下文切换开销？新添加的定时任务的到期时间更小时，不管是使用futex还是epoll_wait系统调用都会被唤醒重新休眠，被唤醒的线程会产生上下文切换。但由于go1.14没有timerproc的存在，新定时任务可直接插入或多次插入后再考虑是否休眠。 结论，golang 1.13的定时器在任务繁多时，必然会造成更多的上线文切换及runtime pmg调度，而golang 1.14做了更好的优化。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:5:0","tags":["linux","develop"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的小随笔"],"content":"零、前言 redis的主要知识点 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:1:0","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"一、基础 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:0","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"1、redis是什么？ Redis是一个数据库，不过与传统RDBM(关系型数据库)不同，Redis属于NoSQL，也就是非关系型数据库，它的存储结构是Key-Value。Redis的数据直接存在内存中，读写速度非常快，因此 Redis被广泛应用于缓存方向。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:1","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"2、NoSQL的BASE理论 BASE理论是CAP中一致性的妥协。和传统事务的ACID截然不同，BASE不追求强一致性，而是允许数据在一段时间内是不一致的，但最终达到一致状态，从而获得更高的可用性和性能。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:2","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"3、常用的redis命令 读操作是get a，表示获取a对应的数据 写操作是setex a t b，表示将a的数据设置为b，并且在t秒后过期。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:3","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"4、Redis的过期键清除策略 过期键清除策略有三种，分别是定时删除、定期删除和惰性删除。 定时删除，是在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作 定期删除，每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键 惰性删除，是指使用的时候，发现Key过期了，此时再进行删除 Redis过期键采用的是定期删除+惰性删除二者结合的方式进行删除的。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:4","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"5、如果过期键没有被访问，而周期性删除又跟不上新键产生的速度，内存不就慢慢耗尽了吗？ Redis支持内存淘汰，配置参数maxmemory_policy决定了内存淘汰策略的策略。这个参数一共有8个枚举值。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:5","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"6、内存淘汰用到的是LRU算法？ Redis用的是近似LRU算法，LRU算法需要一个双向链表来记录数据的最近被访问顺序，但是出于节省内存的考虑，Redis的LRU算法并非完整的实现。 Redis通过对少量键进行取样，然后和目前维持的淘汰池综合比较，回收其中的最久未被访问的键。通过调整每次回收时的采样数量maxmemory-samples，可以实现调整算法的精度。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:6","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"二、数据结构 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:0","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"1、redis的数据结构 对外暴露5种Redis对象，分别是String、List、Hash、Set、Zset。底层实现依托于sds、ziplist、skiplist、dict等更基础数据结构。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:1","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"2、Redis字符串的特点 Redis的字符串如果保存的对象是整数类型，那么就用int存储。如果不能用整数表示，就用SDS来表示，SDS通过记录长度，和预分配空间，可以高效计算长度，进行append操作。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:2","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"3、hash扩容过程 两张Hash表，平常起作用的都是0号表，当装载因子超过阈值时就会进行Rehash，将0号每上每一个bucket慢慢移动到1号表，所以叫渐进式Rehash，这种方式可以减少迁移系统的影响。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:3","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"4、rehash过程 当周期函数发现为装载因子超过阈值时就会进行Rehash。Rehash的流程大概分成三步。 首先，生成新Hash表ht[1]，为 ht[1] 分配空间。此时字典同时持有ht[0]和ht[1]两个哈希表。字典的偏移索引从静默状态-1，设置为0，表示Rehash 工作正式开始。 然后，迁移ht[0]数据到ht[1]。在 Rehash进行期间，每次对字典执行增删查改操作，程序会顺带迁移一个ht[0]上的数据，并更新偏移索引。与此同时，周期函数也会定时迁移一批。 最后，ht[1]和ht[0]指针对象交换。随着字典操作的不断执行， 最终在某个时间点上，ht[0]的所有键值对都会被Rehash至 ht[1]，此时再将ht[1]和ht[0]指针对象互换，同时把偏移索引的值设为-1，表示Rehash操作已完成。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:4","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"5、如果字典正在Rehash，此时有请求过来，Redis会怎么处理？ 针对新增Key，是往ht[1]里面插入。针对读请求，先从ht[0]读，没找到再去ht[1]找。至于删除和更新，其实本质是先找到位置，再进行操作，所以和读请求一样，先找ht[0]，再找ht[1]，找到之后再进行操作。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:5","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"6、跳表的实现 跳表本质上是对链表的一种优化，通过逐层跳步采样的方式构建索引，以加快查找速度。如果只用普通链表，只能一个一个往后找。跳表就不一样了，可以高层索引，一次跳跃多个节点，如果找过头了，就用更下层的索引。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:6","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"7、每个节点有多少层？ 使用概率均衡的思路，确定新插入节点的层数。Redis使用随机函数决定层数。直观上来说，默认1层，和丢硬币一样，如果是正面就继续往上，这样持续迭代，最大层数32层。 50%的概率被分配到第一层，25%的概率被分配到第二层，12.5%的概率被分配到第三层。这种方式保证了越上层数量越少，自然跨越起来越方便。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:7","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"8、Redis的Zset为什么同时需要字典和跳表来实现 Zset是一个有序列表，字典和跳表分别对应两种查询场景，**字典用来支持按成员查询数据，跳表则用以实现高效的范围查询，**这样两个场景，性能都做到了极致。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:8","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"三、系统容灾 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:0","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"1、Redis是基于内存的存储，如果服务重启，数据不就丢失了吗？ 可以通过持久化机制，备份数据。 有两种方式，一种是开启RDB，RDB是Redis的二进制快照文件，优点是文件紧凑，占用空间小，恢复速度比较快。同时，由于是子进程Fork的模式，对Redis本身读写性能的影响很小。 另一种方式是AOF，AOF中记录了Redis的操作命令，可以重放请求恢复现场，AOF的文件会比RDB大很多。 出于性能考虑，如果开启了AOF，会将命令先记录在AOF缓冲，之后再刷入磁盘。数据刷入磁盘的 时机根据参数决定，有三种模式：1.关闭时刷入；2.每秒定期刷入；3.执行命令后立刻触发。 AOF的优点是故障情况下，丢失的数据会比RDB更少。如果是执行命令后立马刷入，AOF会拖累执行速度，所以一般都是配置为每秒定期刷入，这样对性能影响不会很大。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:1","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"2、这样看起来，AOF文件会越来越大，最后磁盘都装不下 不会的，Redis可以在AOF文件体积变得过大时，自动地在后台Fork一个子进程，专门对AOF进行重写。说白了，就是针对相同Key的操作，进行合并，比如同一个Key的set操作，那就是后面覆盖前面。 在重写过程中，Redis不但将新的操作记录在原有的AOF缓冲区，而且还会记录在AOF重写缓冲区。一旦新AOF文件创建完毕，Redis 就会将重写缓冲区内容，追加到新的AOF文件，再用新AOF文件替换原来的AOF文件。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:2","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"3、Redis机器挂掉怎么办？ 可以用主从模式部署，即有一个或多个备用机器，备用机会作为Slave同步Master的数据，在Redis出现问题的时候，把Slave升级为Master。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:3","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"4、主从可以自动切换吗？ 本身是不能，但可以写脚本实现，只是需要考虑的问题比较多。Redis已经有了现成的解决方案：哨兵模式。哨兵来监测Redis服务是否正常，异常情况下，由哨兵代理切换。为避免哨兵成为单点，哨兵也需要多机部署 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:4","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"5、如果Master挂掉，会选择哪个Slave呢？ 当哨兵集群选举出哨兵Leader后，由哨兵Leader从Redis从节点中选择一个Redis节点作为主节点： 1、过滤故障的节点； 2、选择优先级slave-priority最大的从节点作为主节点，如不存在，则继续 3、选择复制偏移量最大的从节点作为主节点，如果都一样，则继续。这里解释下，数据偏移量记录写了多少数据，主服务器会把偏移量同步给从服务器，当主从的偏移量一致，则数据是完全同步 4、选择runid最小的从节点作为主节点。Redis每次启动的时候生成随机的runid作为Redis的标识 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:5","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"6、哨兵Leader，那它是怎么来的呢？ 每一个哨兵节点都可以成为Leader，当一个哨兵节点确认Redis集群的主节点主观下线后，会请求其他哨兵节点要求将自己选举为Leader。被请求的哨兵节点如果没有同意过其他哨兵节点的选举请求，则同意该请求，也就是选举票数+1，否则不同意。 如果一个哨兵节点获得的选举票数超过节点数的一半，且大于quorum配置的值，则该哨兵节点选举为Leader；否则重新进行选举。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:6","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"四、性能优化 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:5:0","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"1、redis性能 只能说在十万级。使用之前，要跑BenchMark，实际情况下会受带宽、负载、单个数据大小、是否开启多线程等因素影响，脱开具体场景谈性能，就没有意义。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:5:1","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"2、Redis性能这么高，那它是协程模型，还是多线程模型 Redis是单线程Reactor模型，通过高效的IO复用以及内存处理实现高性能。如果是6.0之前我会毫不犹豫说是单线程，6.0之后，我还是会说单线程，但会补充一句，IO解包通过多线程进行了优化，而处理逻辑，还是单线程。 另外，如果考虑到RDB的Fork，一些定时任务的处理，那么Redis也可以说多进程，这没有问题。但是Redis对数据的处理，至始至终，都是单线程。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:5:2","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"3、6.0版本发布的多线程功能 多线程功能，主要用于提高解包的效率。和传统的Multi Reactor多线程模型不同，Redis的多线程只负责处理网络IO的解包和协议转换，一方面是因为Redis的单线程处理足够快，另一方面也是为了兼容性做考虑。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:5:3","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"4、如果数据太大，Redis存不下了怎么办 使用集群模式。也就是将数据分片，不同的Key根据Hash路由到不同的节点。集群索引是通过一致性Hash算法来完成，这种算法可以解决服务器数量发生改变时，所有的服务器缓存在同一时间失效的问题。 同时，基于Gossip协议，集群状态变化时，如新节点加入、节点宕机、Slave提升为新Master，这些变化都能传播到整个集群的所有节点并达成一致。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:5:4","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"5、一致性Hash 传统的Hash分片，可以将某个Key，落到某个节点。但有一个问题，当节点扩容或者缩容，路由会被完全打乱。如果是缓存场景，很容易造成缓存雪崩问题。 为了优化这种情况，一致性Hash就应运而生了。一致性Hash是说将数据和服务器，以相同的Hash函数，映射到同一个Hash环上，针对一个对象，在哈希环上顺时针查找距其最近的机器，这个机器就负责处理该对象的相关请求。 这种情况下，增加节点，只会分流后面一个节点的数据。减少节点，那么请求会由后一个节点继承。也就是说，节点变化操作，最多只会影响后面一个节点的数据。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:5:5","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"五、应用场景 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:0","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"1、Redis经常用作缓存，那数据一致性怎么保证？ 从设计思路来说，有Cache Aside和Read/Write Through两种模式，前者是把缓存责任交给应用层，后者是将缓存的责任，放置到服务提供方。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:1","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"2、哪种模式更好 两种模式各有优缺点，从透明性考虑，服务方比较合适；如果从性能极致来说，业务方会更有优势，毕竟可以减去服务RPC的损耗。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:2","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"3、如果数据发生变化，如何更新缓存 更新方式的话，大概有四种： 1、数据存到数据库中，成功后，再让缓存失效，等到读缓存不命中的时候，再加载进去； 2、通过消息队列更新缓存 3、先更新缓存，再更新服务，这种情况相当于把Cache也做Buffer用 4、起一个同步服务，作为MySQL一个从节点，通过解析binlog同步重要缓存 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:3","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"4、缓存雪崩 缓存雪崩表示在某一时间段，缓存集中失效，导致请求全部走数据库，有可能搞垮数据库，使整个服务瘫痪。雪崩原因一般是由于缓存过期时间设置得相同造成的。 针对这种情况，可以借鉴ETCD中Raft选举的优化，让过期时间随机化，避免同一批请求，在同一时间过期。另一方面，还可以业务层面容灾，为热点数据使用双缓存。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:4","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"5、缓存穿透 缓存穿透指请求数据库里面根本没有的数据，高频请求不存在的Key，有可能是正常的业务逻辑，但更可能的，是黑客的攻击。 可以用布隆过滤器来应对，布隆过滤器是一种比较巧妙的概率型数据结构，特点是高效地插入和查询，可以用来告诉我们 某样东西一定不存在或者可能存在。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:5","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"6、布隆过滤器的实现 布隆过滤器底层是一个64位的整型，将字符串用多个Hash函数映射不同的二进制位置，将整型中对应位置设置为1。 在查询的时候，如果一个字符串所有Hash函数映射的值都存在，那么数据可能存在。为什么说可能呢，就是因为其他字符可能占据该值，提前点亮。 可以看到，布隆过滤器优缺点都很明显，优点是空间、时间消耗都很小，缺点是结果不是完全准确。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:6","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"7、缓存击穿 指某一热键，被超高的并发访问，在失效的一瞬间，还没来得及重新产生，就有海量数据，直达数据库。 这种情况和缓存雪崩的不同之处，在于雪崩是大量缓存赶巧儿一起过期，击穿只是单个超热键失效。 这种超高频Key，可以让它不过期，再单独实现数据同步逻辑，来维护数据的一致性。当然，无论如何，对后端肯定是需要限频的，不然如果Redis数据丢失，数据库还是会被打崩。限频方式可以是分布式锁或分布式令牌桶。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:7","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"8、redis消息队列 Redis本身没有支持AMQP规范，消息可靠性不强。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:8","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"9、redis在秒杀场景的应用 Redis主要是起到选拔流量的作用，记录商品总数，还有就是已下单数，等达到总数之后拦截所有请求。可以多放些请求进来，然后塞入消息队列。 蚂蚁金服的云Redis提到消息队列可以用Redis来实现，但我觉得更好的方式是用Kafka这种标准消息队列组件。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:9","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"10、redis分布式锁 锁是计算机领域一个非常常见的概念，分布式锁也依赖存储组件，针对请求量的不同，可以选择Etcd、MySQL、Redis等。前两者可靠性更强，Redis性能更高。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:10","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小随笔"],"content":"11、redis限流 在微服务架构下，限频器也需要分布式化。无论是哪种算法，都可以结合Redis来实现。这里我比较熟悉的是基于Redis的分布式令牌桶。 很显然，Redis负责管理令牌，微服务需要进行函数操作，就向Redis申请令牌，如果Redis当前还有令牌，就发放给它。拿到令牌，才能进行下一步操作。 另一方面，令牌不光要消耗，还需要补充，出于性能考虑，可以使用懒生成的方式：使用令牌时，顺便生成令牌。这样子还有个好处：令牌的获取，和令牌的生成，都可以在一个Lua脚本中，保证了原子性。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:11","tags":["linux","develop"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的GO"],"content":"限流又称为流量控制，是限制到达系统的并发请求数，当达到限制条件时可以拒绝请求，可以起到保护下游服务，熔断流量的作用。常用的限流策略有漏桶算法、令牌桶算法、滑动窗口。 ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:0:0","tags":["golang","源码库"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的GO"],"content":"限流算法 ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:1:0","tags":["golang","源码库"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的GO"],"content":"计数器算法 计数器算法是限流算法中最简单也是最容易实现的一种算法。设置某段时间内的计数器是一个定值，当请求值在范围内则放行，如果超过计数器则限流。 func New(duration time.Duration, allowRequests int32) *fixedWindowCounter { c := \u0026fixedWindowCounter{duration: duration, allowRequests: allowRequests} go func() { for { select { case \u003c-time.After(c.duration): atomic.StoreInt32(\u0026c.currentRequests, 0) } } }() return c } func (c *fixedWindowCounter) Take() error { curRequest := atomic.LoadInt32(\u0026c.currentRequests) if curRequest \u003e= c.allowRequests { return ErrExceededLimit } if !atomic.CompareAndSwapInt32(\u0026c.currentRequests, curRequest, curRequest+1) { return ErrExceededLimit } return nil } ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:1:1","tags":["golang","源码库"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的GO"],"content":"滑动窗口 计数器算法虽然简单，但是会有临界问题，如果有恶意请求在时间边界处大量请求，这会导致瞬间的请求量变大。 所以引入滑动窗口，例如把1分钟化成6格，每格就是10秒，每过10秒，滑动窗口就会向右滑动一格，每个格子都有自己的计数器。 由此可见，当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。 var ( ErrExceededLimit = errors.New(\"Too many requests, exceed the limit. \") ) type slidingWindowCounter struct { total, slot time.Duration durationRequests chan int32 inDurRequests int32 currentRequests, allowRequests int32 } func New(slot, total time.Duration, allowRequests int32) *slidingWindowCounter { c := \u0026slidingWindowCounter{durationRequests: make(chan int32, total/slot/1000), total: total, slot: slot, allowRequests: allowRequests} go func() { go sliding(c) go calculate(c) }() return c } func (c *slidingWindowCounter) Take() error { curRequest := atomic.LoadInt32(\u0026c.currentRequests) if curRequest \u003e= c.allowRequests { return ErrExceededLimit } if !atomic.CompareAndSwapInt32(\u0026c.currentRequests, curRequest, curRequest+1) { return ErrExceededLimit } atomic.AddInt32(\u0026c.inDurRequests,1) return nil } func sliding(c *slidingWindowCounter) { for { select { case \u003c-time.After(c.slot): t := atomic.SwapInt32(\u0026c.inDurRequests, 0) c.durationRequests \u003c- t } } } func calculate(c *slidingWindowCounter) { // 通道加满 for { \u003c-time.After(c.slot) if len(c.durationRequests) == cap(c.durationRequests) { break } } // 定时从通道中取出数据，对currentRequests置0 for { \u003c-time.After(c.slot) t := \u003c- c.durationRequests if t != 0 { atomic.AddInt32(\u0026c.currentRequests, -t) } } } ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:1:2","tags":["golang","源码库"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的GO"],"content":"漏桶算法 水（请求）先到漏桶中，漏桶以一定速率出水，当水的流入速度过大时会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。 var ( ErrExceededLimit = errors.New(\"Too many requests, exceed the limit. \") ) type leakyBucket struct { duration time.Duration bucketSize chan struct{} allowRequests int32 } func New(duration time.Duration, bucketSize, allowRequests int32) *leakyBucket { c := \u0026leakyBucket{duration: duration, bucketSize: make(chan struct{}, allowRequests/bucketSize), allowRequests: allowRequests} go func() { for { select { case \u003c-time.After(time.Duration(c.duration.Nanoseconds()/int64(c.allowRequests))): c.bucketSize \u003c- struct{}{} } } }() return c } func (c *leakyBucket) Take() error { select { case \u003c-c.bucketSize: return nil default: } return ErrExceededLimit } ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:1:3","tags":["golang","源码库"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的GO"],"content":"令牌桶算法 令牌桶是一种常见于用于控制速率的控流算法。系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。 var ( ErrExceededLimit = errors.New(\"Too many requests, exceed the limit. \") ) type leakyBucket struct { duration time.Duration token chan struct{} allowRequests int32 } func New(duration time.Duration, allowRequests int32) *leakyBucket { c := \u0026leakyBucket{duration: duration, token: make(chan struct{}, allowRequests), allowRequests: allowRequests} go func() { for { select { case \u003c-time.After(time.Duration(c.duration.Nanoseconds()/int64(c.allowRequests))): c.token \u003c- struct{}{} } } }() return c } func (c *leakyBucket) Take() error { select { case \u003c-c.token: return nil default: } return ErrExceededLimit } ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:1:4","tags":["golang","源码库"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的GO"],"content":"小结 计数器算法优点是简单，能够满足简单的限流需求，缺点是临界问题，流量曲线可能不够平滑，会有“突刺现象”，在窗口切换时可能会产生两倍于阈值的流量请求。 滑动窗口算法作为对计数器算法的改进，能有效解决窗口切换时可能会产生两倍于阈值的流量请求的问题。 漏桶算法的出水速度是恒定的，那么瞬时大流量，将有大部分请求会被丢弃。 令牌桶算法生成的令牌速度是恒定的，而请求去拿令牌桶是没有速度限制的，这意味着面对瞬时流量，可以短时间内拿到大量令牌。 ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:1:5","tags":["golang","源码库"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的GO"],"content":"限流源码 ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:2:0","tags":["golang","源码库"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的GO"],"content":"golang.org/x/time/rate 是一个令牌桶算法。 Limiter有三个主要的方法 Allow、Reserve和Wait，最常用的是Wait和Allow方法 这三个方法每调用一次都会消耗一个令牌，这三个方法的区别在于没有令牌时，他们的处理方式不同 Allow： 如果没有令牌，则直接返回false Reserve：如果没有令牌，则返回一个reservation， Wait：如果没有令牌，则等待直到获取一个令牌或者其上下文被取消。 tokens更新的策略： 1、 成功获取到令牌或成功预约(Reserve)到令牌 2、预约取消时(Cancel)并且需要还原令牌到令牌桶中时 3、重新设置限流器的速率时(SetLimit) 4、重新设置限流器的容量时(SetBurst) Limit类型 // Limit 就是float64的别名，定义事件的最大频率，表示每秒发生的事件数。0表示无限制。 type Limit float64 // Inf 是无限速率限制允许所有事件(即使突发为0) const Inf = Limit(math.MaxFloat64) // Every 指定向Token桶中防止token的间隔，计算出每秒的数据量 func Every(interval time.Duration) Limit { if interval \u003c= 0 { return Inf } return 1 / Limit(interval.Seconds()) } Limiter结构体 // The methods AllowN, ReserveN, and WaitN consume n tokens. type Limiter struct { mu sync.Mutex limit Limit burst int // 令牌桶的最大数量，如果burst=0且limit=Inf，则允许处理任何事件 tokens float64 // 可用令牌数 last time.Time // 记录上次limiter的tokens被更新的时间 lastEvent time.Time // 记录速率受限的时间点（过去时间点或未来时间点） } Revervation结构体 // Reservation 预定令牌的操作，timeToAct 是本次预约需要等待到的指定时间点才有足够预约的令牌。 type Reservation struct { ok bool // 到截止时间是否能够获取足够的令牌 lim *Limiter tokens int // 需要获取的令牌数 timeToAct time.Time // 需要等待的时间点 limit Limit // 代表预定的时间，可以被更改 } Limiter消费token Limiter有3个消费token的方法，分别是Allow/Reverse/Wait，最终这些方法调用reserveN和advance来实现。 advance的实现 // advance 更新令牌桶的状态，计算出令牌桶未更新的时间，然后计算出需要向令牌桶中添加的令牌数 func (lim *Limiter) advance(now time.Time) (newNow time.Time, newLast time.Time, newTokens float64) { // last不能在now之后，否则计算出来的elapsed为负数，会导致令牌桶数量减少 last := lim.last if now.Before(last) { last = now } // 根据令牌桶的余数计算出令牌桶未进行更新的最大时间 maxElapsed := lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens) elapsed := now.Sub(last) if elapsed \u003e maxElapsed { elapsed = maxElapsed } // 根据未更新的时间（未向桶中加入令牌的时间段）计算出产生的令牌数 delta := lim.limit.tokensFromDuration(elapsed) tokens := lim.tokens + delta if burst := float64(lim.burst); tokens \u003e burst { tokens = burst } return now, last, tokens } reverseN的实现 // reserveN is a helper method for AllowN, ReserveN, and WaitN. // reserveN 判断在maxFutureReserve时间内是否有足够的令牌 func (lim *Limiter) reserveN(now time.Time, n int, maxFutureReserve time.Duration) Reservation { lim.mu.Lock() if lim.limit == Inf { lim.mu.Unlock() return Reservation{ ok: true, // 桶中有足够的令牌 lim: lim, tokens: n, timeToAct: now, } } // 更新桶的状态，tokens为桶可用的令牌数 now, last, tokens := lim.advance(now) // 计算取完后桶中剩下的令牌数 tokens -= float64(n) // 如果tokens\u003c0，说明tokens不够，计算需要等待的时间 var waitDuration time.Duration if tokens \u003c 0 { waitDuration = lim.limit.durationFromTokens(-tokens) } ok := n \u003c= lim.burst \u0026\u0026 waitDuration \u003c= maxFutureReserve // Prepare reservation r := Reservation{ ok: ok, lim: lim, limit: lim.limit, } if ok { r.tokens = n r.timeToAct = now.Add(waitDuration) } // 更新桶中的token，时间，lastEvent if ok { lim.last = now lim.tokens = tokens lim.lastEvent = r.timeToAct } else { lim.last = last } lim.mu.Unlock() return r } 这上面提到了durationFromTokens和tokensFromDuration两种方法。 // durationFromTokens 限制令牌所花费的时间 func (limit Limit) durationFromTokens(tokens float64) time.Duration { seconds := tokens / float64(limit) return time.Nanosecond * time.Duration(1e9*seconds) // 1s * seconds } // tokensFromDuration 根据时间可以产生的令牌数 func (limit Limit) tokensFromDuration(d time.Duration) float64 { // Split the integer and fractional parts ourself to minimize rounding errors. // See golang.org/issues/34861. // 之前的版本如下 // return d.Seconds() * float64(limit) // 这里的d.Seconds()已经是小数了，两个小数相乘会带来精度的缺失。 sec := float64(d/time.Second) * float64(limit) nsec := float64(d%time.Second) * float64(limit) return sec + nsec/1e9 } Limiter归还token func (r *Reservation) CancelAt(now time.Time) { if !r.ok { return } r.lim.mu.Lock() defer r.lim.mu.Unlock() // 如果无需限流或tokens为0或过了截止时间，无需处理取消操作 if r.lim.limit == Inf || r.tokens == 0 || r.timeToAct.Before(now) { return } // 计算需要还原的令牌数量 restoreTokens := float64(r.tokens) - r.limit.tokensFromDuration(r.lim.lastEvent.Sub(r.timeToAct)) if restoreTokens \u003c= 0 { return } // 重新计算令牌桶的状态 now, _, tokens := r.lim.advance(now) // 还原当前令牌桶的令牌数量，当前的令牌数tokens加上需要还原的令牌数restoreTokens tokens += restoreT","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:2:1","tags":["golang","源码库"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的GO"],"content":"uber-go/ratelimit 基于漏桶实现。 例子 rl := ratelimit.New(100) // per second prev := time.Now() for i := 0; i \u003c 10; i++ { now := rl.Take() fmt.Println(i, now.Sub(prev)) prev = now } // Output: // 0 0 // 1 10ms // 2 10ms // 3 10ms // 4 10ms // 5 10ms // 6 10ms // 7 10ms // 8 10ms // 9 10ms 基本实现 要实现上面的每秒固定速率，很简单。 在ratelimit的New函数中，传入的参数是每秒允许请求量(Requests Per Second)。 我们就能很轻松计算出每个请求的时间间隔： perRequest := time.Second / time.Duration(rate) 如图，当请求1处理结束后，记录请求1的处理完成时间，记为limiter.last。请求2到达时，如果此时的时间与limiter.last的时间间隔小于preRequest，那么sleep一段时间。 sleepFor = t.PreRequest - now.Sub(t.last) if sleepFor \u003e 0 { t.clock.Sleep(sleepFor) t.last = now.Add(sleepFor) } else { t.last = now } 然而，在现实请求中，流量经常是突发的，有些请求间隔比较长，有些请求间隔比较短。 所以uber引入最大松弛量，把之前间隔比较长的请求时间，匀给后面的使用。 而实现起来也很简单，就是把每个请求多出的等待时间累加起来，给后面的请求冲抵。 t.sleepFor += t.preReqeust - now.Sub(t.last) if t.sleepFor \u003c t.maxSlack { t.sleepFor = t.maxSlack } if t.sleepFor \u003e 0 { t.clock.Sleep(t.sleepFor) t.last = now.Add(t.sleepFor) t.sleepFor = 0 } else { t.last = now } 源码解析： func New(rate int, opts ...Option) Limiter { return newAtomicBased(rate, opts...) } // buildConfig combines defaults with options. func buildConfig(opts []Option) config { c := config{ clock: clock.New(), slack: 10, per: time.Second, } for _, opt := range opts { opt.apply(\u0026c) } return c } func newAtomicBased(rate int, opts ...Option) *atomicLimiter { config := buildConfig(opts) // 两个请求的最小时间间隔 perRequest := config.per / time.Duration(rate) l := \u0026atomicLimiter{ perRequest: perRequest, maxSlack: -1 * time.Duration(config.slack) * perRequest, // 最大松弛量 clock: config.clock, } initialState := state{ last: time.Time{}, sleepFor: 0, } atomic.StorePointer(\u0026l.state, unsafe.Pointer(\u0026initialState)) return l } func (t *atomicLimiter) Take() time.Time { var ( newState state taken bool interval time.Duration ) for !taken { now := t.clock.Now() previousStatePointer := atomic.LoadPointer(\u0026t.state) oldState := (*state)(previousStatePointer) newState = state{ last: now, sleepFor: oldState.sleepFor, } // 如果是第一次请求，更新状态 if oldState.last.IsZero() { taken = atomic.CompareAndSwapPointer(\u0026t.state, previousStatePointer, unsafe.Pointer(\u0026newState)) continue } newState.sleepFor += t.perRequest - now.Sub(oldState.last) // 例如请求1完成后，请求2在几个小时后到达，那么对于now.Sub(oldState.last)会非常大，而这里newState.sleepFor表示允许冲抵的最长时间。 if newState.sleepFor \u003c t.maxSlack { // t.maxSlack默认10个请求的间隔大小 newState.sleepFor = t.maxSlack } if newState.sleepFor \u003e 0 { // 代表此前的请求多余出的时间，无法完全冲抵此次所需量 newState.last = newState.last.Add(newState.sleepFor) interval, newState.sleepFor = newState.sleepFor, 0 } taken = atomic.CompareAndSwapPointer(\u0026t.state, previousStatePointer, unsafe.Pointer(\u0026newState)) } t.clock.Sleep(interval) return newState.last } ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:2:2","tags":["golang","源码库"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的GO"],"content":"原子操作 我们先给原子操作下一个定义： 原子(atom)：在化学反应中不可再分的基本微粒。 原子操作(atomic operation)：不会被线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会有任何的上下文切换。 简单来说，就是多个线程对同一块内存的操作是串行的，不会因为并发操作而同时读写内存。 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:1:0","tags":["源码解析","golang"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"原子性 在处理器层面，基于缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。通过加锁保证从系统内存中读取或写入一个字节是原子的，也就是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。 总线锁 如果多个处理器同时对共享变量进行读写操作(i++)，那么共享变量就会被多个处理器同时进行操作，这样读写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。 总线锁其实就是处理器提供一个LOCK#信号，当一个处理器在总线上输出信号时，其他处理器的请求将被阻塞，那么改处理器就能独占共享内存。 在同一时刻，只需保证对某个内存地址的操作是原子性即可，但总线锁把CPU和内存之间的通信锁住了，使得其他处理器不能操作其他内存地址的数据，所以总线锁的开销比较大，缓存锁可以在某些场合代替总线锁进行优化。 缓存锁 内存区域如果被缓存在处理器的缓存行中，并且在LOCK#操作期间，那么当它执行操作回写到内存时，处理器不能在总线上声明LOCK#信号，而是修改内部的内存地址，允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性会阻止同时修改两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行数据时，会使缓存行无效。 但有两种情况下处理器不会使用缓存锁定： 1、当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行(cache line)，则处理器会调用总线锁 2、有些处理器不支持缓存锁定。 锁机制虽然能保证原子性，但是锁机制最主要的问题：多线程竞争的情况下，会出现线程阻塞和唤醒锁带来的性能问题，互斥同步(阻塞同步)。 锁机制采用的是悲观锁策略，并不是一种特别高效的解决方案。可以采用乐观锁，每次不加锁，而是假设没有冲突去完成某项操作，如果有冲突就重试，知道成功为止。这就是无锁操作CAS(Compare and swap)。 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:2:0","tags":["源码解析","golang"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"CAS CAS是一条原子指令，CAS(V,O,N)，包含三个值分别为：V内存地址存放的实际值，O预期的值(旧值)，N更新的值，作用是让CPU先比较旧值O和内存实际值V，如果相等就表明没有被其他线程修改过，就会把新值N赋值给V。反之，V和O不相等，不能把N赋值给V，返回V即可。 伪代码： func CompareAndSwap(addr *int, oldValue,newValue int) bool { if addr == nil { return false } if *addr == oldValue { *addr = newValue return true } return false } 不过上面的代码可能会发生一个问题，也就是ABA问题。因为CAS需要在操作值的时候检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变回了A，那么使用CAS检查时会发现它的值没有发生变化，但实际上发生了变化。ABA问题的解决思路就是使用版本号，在遍历前面追加版本号，每次更新的时候都会把版本号加1，那么A-B-A就会变成1A-2B-3A。 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:3:0","tags":["源码解析","golang"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"go包中的原子操作 在src/sync/atomic/doc.go下，把底层硬件提供的原子操作封装成了Go的函数，分为5个系列： 1、SwapXXX(addr *int32, new int32) (old int32)：原子性的将new的值保存到*addr并返回旧值 2、CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)：原子性比较*addr和old的值，如果相同则将new赋值给*addr并返回true 3、AddInt32(addr *int32, delta int32) (new int32)：原子性的将delta的值加到*addr并返回新值 4、LoadInt32(addr *int32) (val int32)：原子性的获取*addr的值 5、StoreInt32(addr *int32, val int32)：原子性的将val的值保存到*addr ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:4:0","tags":["源码解析","golang"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"源码解析 原子操作是基于汇编实现的，基于plan9的。 我们可以看一下value.go文件的源码。 type Value struct { v interface{} } 虽然这里是interface类型，但是这里其实是分解了类型和值的。 type ifaceWords struct { typ unsafe.Pointer data unsafe.Pointer } ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:5:0","tags":["源码解析","golang"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"Value的写入 func (v *Value) Store(x interface{}) { if x == nil { panic(\"sync/atomic: store of nil value into Value\") } vp := (*ifaceWords)(unsafe.Pointer(v)) xp := (*ifaceWords)(unsafe.Pointer(\u0026x)) for { typ := LoadPointer(\u0026vp.typ) if typ == nil { // Attempt to start first store. // Disable preemption so that other goroutines can use // active spin wait to wait for completion; and so that // GC does not see the fake type accidentally. runtime_procPin() if !CompareAndSwapPointer(\u0026vp.typ, nil, unsafe.Pointer(^uintptr(0))) { runtime_procUnpin() continue } // Complete first store. StorePointer(\u0026vp.data, xp.data) StorePointer(\u0026vp.typ, xp.typ) runtime_procUnpin() return } if uintptr(typ) == ^uintptr(0) { // First store in progress. Wait. // Since we disable preemption around the first store, // we can wait with active spinning. continue } // First store completed. Check type and overwrite data. if typ != xp.typ { panic(\"sync/atomic: store of inconsistently typed value into Value\") } StorePointer(\u0026vp.data, xp.data) return } } // Disable/enable preemption, implemented in runtime. func runtime_procPin() func runtime_procUnpin() 通过报错信息和注释我们知道，存入的值不能为nil，类型必须与原类型相同。 写入步骤： 1、判断写入值不能为nil，否则触发panic 2、将oldValue和newValue转换成ifaceWords类型，方便获取类型和值 3、为了保证原子性，循环处理，当已经有Store正在写入时，会进行等待。 4、如果还没有写入数据，类型为空，那么会开始第一次写入操作，会先调用runtime_procPin方法禁止调度器对当前goroutine的抢占 5、调用CAS方法来判断当前地址是否有被抢占，如果失败，就会解除抢占锁，解除禁止调度器，循环等待 6、设置中间值成功后，可以安全的把v设为传入的新值了，写入值和类型。 7、第一次写入没有完成，通过uintptr(typ) == ^uintptr(0)来判断，因为还是第一次放入的中间类型，会继续等待第一次完成 8、如果第一次写入完成，会检查类型是否一致，然后写入数据 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:5:1","tags":["源码解析","golang"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"Value的读取 func (v *Value) Load() (x interface{}) { vp := (*ifaceWords)(unsafe.Pointer(v)) typ := LoadPointer(\u0026vp.typ) if typ == nil || uintptr(typ) == ^uintptr(0) { // First store not yet completed. return nil } data := LoadPointer(\u0026vp.data) xp := (*ifaceWords)(unsafe.Pointer(\u0026x)) xp.typ = typ xp.data = data return } 先转换oldValue，然后根据类型判断是否有数据或第一次写入有没有完成，通过检查后，获取值。 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:5:2","tags":["源码解析","golang"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"总结 golang包中的原子操作可以看成是乐观锁，而互斥锁可以看成是悲观锁。 原子锁操作更加轻量，可以在不形成临界区和创建互斥量的情况下并发安全的值替换操作，可以大大减少同步对程序性能的损耗。 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:6:0","tags":["源码解析","golang"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"参考资料 原子操作 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:7:0","tags":["源码解析","golang"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的小笔记"],"content":"一、简介 当集群中的某个服务需要升级时，我们需要停止目前与该服务的相关的所有pod，然后下载新版本镜像并创建新的pod。如果集群规模比较大，则这个工作就会很麻烦。kubernetes提供了滚动升级功能来解决这个问题。 ","date":"2021-03-24","objectID":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/:1:0","tags":["kubernetes","pod"],"title":"Pod升级与回滚","uri":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/"},{"categories":["月霜天的小笔记"],"content":"二、Deployment的升级 nginx-deployment.yamlapiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deploymentspec:selector:matchLabels:app:nginxreplicas:3template:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.7.9ports:- containerPort:80 当pod的镜像需要被升级为nginx:1.9.1时，可以通过kubectl set image命令 kubectl set image deployment/nginx-deploymnet nginx=nginx:1.9.1 或通过kubectl edit修改Deployment配置。 在Deployment的定义中，可以通过spec.strategy指定Pod更新的策略，目前支持Recreate（重建）和RollingUpdate（滚动更新），默认值为滚动更新。 Recreate：表示Deployment在更新pod时，会先杀掉所有正在运行的Pod，然后创建新的Pod RollingUpdate：会以滚动更新的方式逐个更新Pod。 spec.strategy.rollingUpdate.maxUnavailable：用于指定Deployment在更新过程中不可用状态的Pod数量上限。 spec.strategy.rollingUpdate.maxSurge：用于指定Deployment更新Pod的过程中Pod总数超过Pod期望副本数部分的最大值。 多重更新（Rollover） 如果Deployment的上一次更新正在进行，此时用户再次发起Deployment的更新操作，那么Deployment会为每一次更新都创建一个ReplicaSet，而每次在新的ReplicaSet创建成功后，会逐个增加Pod副本数，同时将之前正在扩容的ReplicaSet停止扩容，并将其加入旧版本ReplicaSet列表中，然后开始缩容至0的操作。 ","date":"2021-03-24","objectID":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/:2:0","tags":["kubernetes","pod"],"title":"Pod升级与回滚","uri":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/"},{"categories":["月霜天的小笔记"],"content":"三、Deployment的回滚 可以使用kubectl rollout history命令检查Deployment部署的历史记录。 kubectl rollout history deployment/nginx-deployment 注意：这里需要在新建Deployment时使用--record参数。 如果需要查看特定版本的详细信息，则可以加上--revision=\u003cN\u003e参数。 撤销本次发布并回滚到上一个部署版本 kubectl rollout undo deployment/nginx-deployment 当然，也可以使用--to-revision参数指定回滚到的部署版本号。 ","date":"2021-03-24","objectID":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/:3:0","tags":["kubernetes","pod"],"title":"Pod升级与回滚","uri":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/"},{"categories":["月霜天的小笔记"],"content":"四、暂停和恢复Deployment的部署操作 对于一次复杂的Deployment配置修改，为了避免频繁触发Deployment的更新操作，可以先暂停Deployment的更新操作，然后进行配置修改，再恢复Deployment，一次触发完整的更新操作。 通过使用kubectl rollout pause暂停Deployment的更新操作 kubectl rollout pause deployment/nginx-deployment 通过使用kubectl rollout resume恢复操作 kubectl rollout resume deploy/nginx-deployment ","date":"2021-03-24","objectID":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/:4:0","tags":["kubernetes","pod"],"title":"Pod升级与回滚","uri":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/"},{"categories":["月霜天的小笔记"],"content":"五、其他更新操作 1、RC的滚动更新 kubectl rolling-update命令，通过配置文件 RC名字不与旧RC相同；在selector中应至少有一个Label与旧RC的Label不同，以标识其为新RC。 kubectl rolling-update redis-master -f redis-master-ctl-v2.yaml kubectl rolling-update命令，不通过配置文件 kubectl rolling-update redis-master --image=redis-master:2.0 执行结果是旧RC被删除，新的RC将使用旧RC的名称 2、DaemonSet的更新策略 OnDelete：默认的升级策略，新的Pod并不会自动创建，直到用户手动删除旧版本的Pod，才触发新建操作。 RollingUpdate：整个过程和Deployment类似，但不支持查看DaemonSet的更新历史记录；不能通过rollback回滚，必须通过再次提交旧版本配置的方式实现。 3、Statefulset的更新策略 实现了RollingUpdate、OnDelete和Paritioned策略。 Partition:3表示索引3以上的对象更新。 ","date":"2021-03-24","objectID":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/:5:0","tags":["kubernetes","pod"],"title":"Pod升级与回滚","uri":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/"},{"categories":["月霜天的小笔记"],"content":"一、简介 在大多数情况下，我们不关心pod会被调度到哪个节点，只关心pod是否被成功调度到集群的一个可用节点。但是，在真实生产环境中存在一种需求：希望某种pod全部运行在一个或一些节点上。比如需要ssd的pod都运行在具有ssd磁盘的目标节点上。 ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:1:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"二、全自动调度 deployment或rc的主要功能之一就是自动部署一个容器应用的多份副本，以及持续监控副本的数量，在集群中始终维持用户指定的副本数量。 nginx-deployment.yamlapiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deploymentspec:selector:matchLabels:app:nginxreplicas:3template:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.7.9ports:- containerPort:80 使用kubectl create命令创建这个deployment： # kubectl create -f nginx-deployment.yaml deployment \"nginx-deployment\" created 可以看到Deployment已经创建好3个副本，并且所有副本都是最新可用的。从调度策略上来说，这3个pod由系统全自动完成调度，用户无法干预调度过程和结果。 ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:2:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"三、NodeSelector：定向调度 通过Node的标签（Label）和Pod的nodeSelector属性相匹配来讲Pod调度到指定的一些Node上。 1、通过kubectl label命令给目标Node打上一些标签： kubectl label nodes \u003cnode-name\u003e \u003clabel-key\u003e=\u003clabel-value\u003e 2、在Pod的定义中加上nodeSelector的设置 apiVersion:v1kind:ReplicationControllermetadata:name:redis-masterlabels:name:redis-masterspec:replicas:3selector:name:redis-mastertemplate:metadata:labels:name:redis-masterspec:containers:- name:masterimage:reids-masterports:- containerPort:6379nodeSelector: # 节点标签选择器zone:north 如果给多个Node都定义了相同的标签，则scheduler会根据调度算法从Node组中挑选一个可用的Node进行调度。 除了用户可以自行给Node添加标签，kubernetes也会给Node预定义一些标签。 kubernetes.io/hostname kubernetes.io/os kubernetes.io/arch ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:3:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"四、NodeAffinity：Node亲和性调度 NodeAffinity为Node亲和性的调度策略，是用于替换NodeSelector的全新调度策略。目前有两种节点亲和性表达。 RequiredDuringSchedulingIgnoredDuringExecution：必须满足指定的规则才能调度Pod到Node上，相当于硬限制。 PreferredDuringSchedulingIgnoredDuringExecution：强调优先满足指定规则，调度器会尝试调度Pod到Node上，但不强求，相当于软限制。多个优先级规则还可以设置权重(weight)值，以定义执行的先后顺序。 IgnoredDuringExecution：如果一个Pod所在的结点在Pod运行期间标签发生了变更，不再符合Pod的结点亲和性需求，则系统将忽略Node上的Label变化，该Pod能继续在该节点上运行。 apiVersion:v1kind:Podmetadata:name:with-node-affinityspec:affinity:nodeAffinity:# 要求只在amd64的节点上运行requiredDuringSchedulingIgnoredDuringExecution:nodeSelectorTerms:- matchExpressions:- key:beta.kubernetes.io/archoperator:Invalues:- amd64preferredDuringSchedulingIgnoredDuringExecution:- weight:1# 尽量运行在磁盘类型为ssd的节点上preference:matchExpressions:- key:disk-typeoperator:Invalues:- ssdcontainers:- name:with-node-affinityimage:pause:2.0 NodeAffinity语法支持的操作符包括In、NotIn、Exists、DoesNotExist、Gt、Lt。 NodeAffinity规则设置的注意事项： 如果同时定义了nodeSelector和nodeAffinity，那么必须两个条件都得到满足，Pod才能最终运行在指定的Node上 如果nodeAffinity指定了多个nodeSelectorTerms，那么其中一个能够匹配成功即可 如果nodeSelectorTerms中有多个matchExpressions，则一个节点必须满足所有matchExpressions才能运行Pod。 ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:4:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"五、PodAffinity：Pod亲和与互斥调度策略 如果在具有标签相同的Node上运行了一个或多个符合条件的Pod，那么Pod应该运行在这个Node上。 topologyKey：节点所属的topoloty kubernets.io/hostname failure-domain.beta.kubernetse.io/zone failure-domain.beta.kubernets.io/region pod的亲和与互斥的条件设置也是RequiredDuringSchedulingIgnoredDuringExecution和PreferredDuringSchedulingIgnoredDuringExecution。 Pod的亲和性被定义在podAffinity，Pod的互斥性被定义在podAntiAffinity。 1、参考目标Pod 创建一个名为pod-flag的pod，带有标签security=S1和app=nginx。 apiVerson:v1kind:Podmetadata:name:pod-flaglabels:security:\"S1\"app:\"nginx\"spec:containers:- name:nginximage:nginx 2、Pod的亲和性调度 apiVerson:v1kind:Podmetadata:name:pod-affinityspec:affinity:podAffinity:requiredDuringSchedulingIgnoredDuringExecution:- labelSelector:matchExpressions:- key:securityoperator:Invalues:- S1topologyKey:kubernets.io/hostnamecontainers:- name:with-pod-affinityimage:pause:2.0 3、Pod的互斥性调度 apiVerson:v1kind:Podmetadata:name:anti-affinityspec:affinity:podAffinity:requiredDuringSchedulingIgnoredDuringExecution:- labelSelector:matchExpressions:- key:securityoperator:Invalues:- S1topologyKey:failure-domain.beta.kubernets.io/zonepodAntiAffinity:requiredDuringSchedulingIgnoredDuringExecution:- labelSelector:matchExpressions:- key:securityoperator:Invalues:- nginxtopologyKey:kubernets.io/hostnamecontainers:- name:anti-pod-affinityimage:pause:2.0 新pod与security=S1的pod为同一个zone，但不与app=nginx的Pod为同一个zone。 topologyKey的限制（出于性能和安全方面考虑）： 在Pod亲和性和RequiredDuringScheduing的Pod互斥性的定义中，不允许使用空的topologyKey。 如果Admission Controller包含了LimitPodHardAntiAffinityTopology，那么针对Required DuringScheduling的Pod互斥性定义就被限制为kubernetes.io/hostname，要使用自定义的topologyKey就要改写或禁用该控制器。 在PreferredDruingScheduling类型的Pod互斥性定义中，空的topologyKey会被解释为kubernets.io/hostname、failure-domain.beta.kubernetse.io/zone、failure-domain.beta.kubernets.io/region的组合。 如果不是上述情况，就可以采用任意合法的topologyKey。 PodAffinity规则设置的注意事项： 除了设置Label Selector和topologyKey，用户还可以指定Namespace列表来进行限制，同样，使用Label Selector对Namespace进行选择。 在所有关联requiredDuringSchedulingIgnoredDuringExecution的matchExpressions全部满足之后，系统才能将Pod调度到某个Node上。 ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:5:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"六、Taints和Tolerations（污点和容忍） 在Node上设置一个或多个Taint之后，除非Pod明确声明能够容忍这些污点，否则无法在这些Node上运行。Toleration是Pod的属性，让Pod能够运行在标注了taint的Node上。 # kubectl taint nodes node1 key=value:NoSchedule 然后在pod上声明toleration。 tolerations:- key:\"key\"operator:\"Equal\"value:\"value\"effect:\"NoSchedule\"tolerations:- key:\"key\"operator:\"Exists\"effect:\"NoSchedule\" 如果不指定operator，默认值为Equal。空的key配合Exists能够匹配所有键和值。空的effect能够匹配所有的effect。 NoSchedule：不调度 PreferNoSchedule：不优先调度 NoExecute：不运行，已经在这个节点上的Pod会被驱逐。 ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:6:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"七、Pod Priority Preemption：Pod优先级调度 优先级抢占调度策略的核心行为分别是驱逐（Eviction）和抢占（Preemption）。Evection是kubelet行为，即当一个Node发生资源不足情况时，该节点上的kubelet进程会发生驱逐动作，此时kubelet会综合考虑Pod的优先级、资源申请量与实际使用量等信息计算哪些Pod需要被驱逐；当同样优先级的Pod需要被驱逐时，实际使用的资源量超过申请量最大倍数的高耗能Pod会被首先驱逐。 服务质量等级Qos： Guaranteed：pod设置了limit或limit=request Burstable：pod里的一个容器limit！=request Best-Effort：limit和request均未设置 1、创建PriorityClasses apiVersion:scheduling.k8s.io/v1beta1kind:PriorityClassmetadata:name:high-priorityvalue:1000000globalDefault:falsedescription:\"This priority class should be used for service pods only\" 2、可以在任意pod中引用优先级类别 apiVersion:v1kind:Podmetadata:name:nginxlabels:env:testspec:containers:- name:nginximage:nginximagePullPolicy:IfNotPresentpriorityClassName:high-priority ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:7:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"八、其他情况 1、DaemonSet：在每个Node上都调度一个Pod 2、Job和CronJob的批处理调度，可以设置任务数completions和并行度parallelism ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:8:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"一、简介 pod在整个生命周期中被系统定义为各种状态，熟悉pod的各种状态对于理解如何设置pod的调度策略、重启策略都是很有必要的。 ","date":"2021-03-22","objectID":"/2021/03/pod%E5%9F%BA%E7%A1%80/:1:0","tags":["kubernetes","pod"],"title":"Pod的基础","uri":"/2021/03/pod%E5%9F%BA%E7%A1%80/"},{"categories":["月霜天的小笔记"],"content":"二、pod状态 Pending：API Server已经创建该Pod，但在Pod内还有一个或多个容器的镜像没有创建，包括正在下载镜像的过程 Running：Pod内所有容器均已创建，且至少有一个容器处于运行状态。正在启动状态或重启状态 Succeeded：Pod内所有容器均成功执行后退出，且不会再重启 Failed：Pod内所有容器均已退出，但至少有一个容器退出为失败状态，退出码不为0 Unknown：由于某种原因无法获取该Pod的状态，可能由于网络通信不畅导致（无法连接API Server） ","date":"2021-03-22","objectID":"/2021/03/pod%E5%9F%BA%E7%A1%80/:2:0","tags":["kubernetes","pod"],"title":"Pod的基础","uri":"/2021/03/pod%E5%9F%BA%E7%A1%80/"},{"categories":["月霜天的小笔记"],"content":"三、Pod重启策略 pod的重启策略（RestartPolicy）应用于Pod内的所有容器，并且仅在Pod所处的Node上由kubelet进行判断和重启操作。当某个容器异常退出或健康检查失败时，kubelet会根据重启策略来进行相应的操作。 Always：默认策略，当容器失效时，由kubelet自动重启容器 OnFailure：当容器终止运行且退出码不为0时，由kubelet自动重启该容器 Never：不论容器的运行状态都不重启 kubelet重启容器的时间间隔以sync-frequency乘以2来计算，例如1、2、4、8倍等，最长5min，并且在成功重启后10min后重置该时间。 每种控制器对pod的重启策略要求： RC和DaemonSet：必须为Always，需要保证容器持续运行 Job：OnFailure或Never，确保容器执行完成后不再重启 kubelet：在pod失效后重启，不论将RestartPolicy设置为什么值，也不会对pod进行健康检查 常见的状态转换场景（最终状态） pod包含的容器数 pod当前的状态 发生事件 always OnFailure Never 1 running 成功退出 running succeed succeed 1 running 失败退出 running running failed 2 running 1个失败退出 running running running 2 running oom running running failed ","date":"2021-03-22","objectID":"/2021/03/pod%E5%9F%BA%E7%A1%80/:3:0","tags":["kubernetes","pod"],"title":"Pod的基础","uri":"/2021/03/pod%E5%9F%BA%E7%A1%80/"},{"categories":["月霜天的小笔记"],"content":"四、健康检查 LivenessProbe存活探针：判断容器是否存活（running状态）。如果探针探测到容器不健康，kubelet会杀掉容器，并根据容器的重启策略处理。如果容器不包含存活探针，那么会认为容器一直健康。 ReadinessProbe就绪探针：判断容器服务是否可用（ready状态），达到ready状态的pod才能接受请求。如果在运行过程中ready状态变为false，则系统自动将其从service的后端endpoint列表中隔离出去，后续再把恢复到ready状态的pod加回到endpoint列表。这样就能保证客户端再访问service时不会被转发到服务不可用的pod实例上。 三种实现方式： ExecAction：在容器内部执行命令，如果命令的状态码返回0，则表明容器健康。 livenessProbe:exec:command:- cat- /tmp/health TCPSocketAction：通过容器的IP地址和端口号Port执行TCP检查，如果能够建立TCP连接，则表明容器健康 livenessProbe:tcpSocket:port:80 HTTPGetAction：通过容器的IP地址、端口号及路径调用HTTP Get方法，如果响应的状态码大于等于200且小于400，则认为容器健康 livenessProbe:httpGet:path:/_status/healthzport:80 对于每种探测方式，都需要设置参数 initialDelaySeconds：启动容器后进行首次健康检查的等待时间 timeoutSeconds：健康检查发送请求后等待响应的超时时间 ","date":"2021-03-22","objectID":"/2021/03/pod%E5%9F%BA%E7%A1%80/:4:0","tags":["kubernetes","pod"],"title":"Pod的基础","uri":"/2021/03/pod%E5%9F%BA%E7%A1%80/"},{"categories":["月霜天的GO"],"content":"我们来看一下sync包下有哪些常见的使用：cond.go map.go mutex.go once.go pool.go rwmutex.go waitgroup.go ","date":"2021-02-26","objectID":"/2021/02/mutex/:0:0","tags":["golang","源码分析"],"title":"Mutex的源码解析","uri":"/2021/02/mutex/"},{"categories":["月霜天的GO"],"content":"什么是sync？ Package sync provides basic synchronization primitives such as mutual exclusion locks. Other than the Once and WaitGroup types, most are intended for use by low-level library routines. Higher-level synchronization is better done via channels and communication. Values containing the types defined in this package should not be copied. 这句话的大意是： 包同步提供基本的同步原语，例如互斥锁。 除一次和等待组类型外，大多数都供低级库例程使用。 较高级别的同步最好通过渠道和通信来完成。 包含此包中定义的类型的值不应复制。 ","date":"2021-02-26","objectID":"/2021/02/mutex/:1:0","tags":["golang","源码分析"],"title":"Mutex的源码解析","uri":"/2021/02/mutex/"},{"categories":["月霜天的GO"],"content":"互斥锁(一代锁) 先介绍一下 a \u0026^ b是怎么一回事？ a \u0026^ b = (a\u0026b)^a, 作用是以a为基础，与b相异的部分保留，相同位清0。换言之，清除a中ab都为1的位。 func (m *Mutex) Lock() { // 快速加锁，将state状态更新为locked if atomic.CompareAndSwapInt32(\u0026m.state, 0, mutexLocked) { return } awoke := false // 当前goroutine是否被唤醒 for { old := m.state // 保存state状态 new := old | mutexLocked // 新值设为locked if old\u0026mutexLocked != 0 { // 如果处于加锁状态，新的goroutine加入队列 new = old + 1\u003c\u003cmutexWaiterShift } if awoke { // 如果被唤醒，新值需要重置为0 new \u0026^= mutexWoken } // 两种情况会走到这里：1、休眠中被唤醒；2、加锁失败重新进入循环 // cas更新，如果更新失败，说明有其他goroutine抢先，重新循环 if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { // 如果state更新成功 // 1、old为0，抢锁成功，break // 2、old为1，cas只是为了更新waiter计数 if old\u0026mutexLocked == 0 { break } // 阻塞等待唤醒 runtime_Semacquire(\u0026m.sema) // 有goroutine释放了锁，当前goroutine被唤醒 awoke = true } } } func (m *Mutex) Unlock() { // 更新state为unlocked new := atomic.AddInt32(\u0026m.state, -mutexLocked) if (new+mutexLocked)\u0026mutexLocked == 0 { // 0\u00261=0，说明state是0，也就是说没有加锁的锁解锁会panic panic(\"sync: unlock of unlocked mutex\") } old := new for { // 不需要唤醒的情况 // 1、等待队列为0 // 2、goroutine已经抢到锁了 // 3、已经有goroutine被唤醒了 if old\u003e\u003emutexWaiterShift == 0 || old\u0026(mutexLocked|mutexWoken) != 0 { return } // waiter计数位减1，设置state为woken，可能会有多个goroutine被唤醒 new = (old - 1\u003c\u003cmutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { runtime_Semrelease(\u0026m.sema) // 唤醒睡眠的goroutine return } old = m.state } } ","date":"2021-02-26","objectID":"/2021/02/mutex/:2:0","tags":["golang","源码分析"],"title":"Mutex的源码解析","uri":"/2021/02/mutex/"},{"categories":["月霜天的GO"],"content":"一般来说，模块作者需要使用一种方法来只是不应该使用某个已发布的模块。 出现一个严重的安全漏洞 不闲不兼容或bug 版本发布错误 出现过模块最新版本为1.0.0，错误发布1.1.0，然后在github上把版本删除，使用1.0.1版本，但是有人使用代理模块并且下载了1.1.0版本，所以其他人再下载指定latest会下载1.1.0版本的代码。 ","date":"2021-02-25","objectID":"/2021/02/golang_retract/:0:0","tags":["golang"],"title":"Golang 1.16版本新特性 =\u003e 撤回版本(retract)","uri":"/2021/02/golang_retract/"},{"categories":["月霜天的GO"],"content":"准备工作 retract模块，github的完整路径是https://github.com/betterfor/retract，你可以使用自己的模块实验。 awesomeProjcet，本地模块，使用了test包的依赖的简单main函数。 请确保golang版本是1.16+ ","date":"2021-02-25","objectID":"/2021/02/golang_retract/:1:0","tags":["golang"],"title":"Golang 1.16版本新特性 =\u003e 撤回版本(retract)","uri":"/2021/02/golang_retract/"},{"categories":["月霜天的GO"],"content":"创建test模块 1、先在github上创建好仓库 2、拉取代码仓库 $ git clone https://github.com/betterfor/retract.git $ cd retract/ $ go mod init go: creating new go.mod: module github.com/betterfor/retract 3、在模块中新建foo.go文件 package retract func Foo() string { return \"v0.0.1\" } 4、将retract模块的改动提交git并push $ git add . $ git commit -m \"Initial commit\" $ git push -u origin master 这是模块的初始版本，我们用v0版本来表示，代表它不稳定。 $ git tag v0.1.0 $ git push origin v0.1.0 To https://github.com/betterfor/retract.git * [new tag] v0.1.0 -\u003e v0.1.0 此时retract模块第一个版本已经发布，我们在awesomeProjcet项目使用它。 5、创建awesomeProjcet本地项目，引用retract模块。 $ mkdir awesomeProjcet $ cd awesomeProjcet/ $ go mod init package main import ( \"fmt\" \"github.com/betterfor/retract\" ) func main() { fmt.Println(retract.Foo()) } $ go get github.com/betterfor/retract@v0.1.0 此时版本正常使用。 6、retract模块更新 foo.go文件修改 package retract func Foo() string { return \"v0.2.0\" } 我们提交并推送到github上，给它标记一个新的标签v0.2.0. $ git tag v0.2.0 $ git push origin v0.2.0 7、然后我们在awesomeProjcet项目中使用retract的v0.2.0版本，发现可以正常运行。 $ go get github.com/betterfor/retract@v0.2.0 go: downloading github.com/betterfor/retract v0.2.0 go get: upgraded github.com/betterfor/retract v0.1.0 =\u003e v0.2.0 $ go run main.go v0.2.0 8、撤回版本 此时我们作为retract模块的作者，发现v0.2.0版本不完善，需要撤回这个版本，应该怎么做？ 我们可以在go.mod中增加retract指令来撤回某个模块版本。 $ go mod edit -retract=v0.2.0 此时go.mod内容如下 module github.com/betterfor/retract go 1.16 // tag version error retract v0.2.0 当然你也可以不使用命令，直接在go.mod文件中修改，一般会在retract加上撤回原因.go get、go list等会显示这个原因。 提交修改内容至github，给它标记一个新的标签v0.3.0。 awesomeProjcet项目中使用retract的v0.3.0版本，发现可以正常运行。 $ go get github.com/betterfor/retract@v0.3.0 go: downloading github.com/betterfor/retract v0.3.0 go get: upgraded github.com/betterfor/retract v0.2.0 =\u003e v0.3.0 $ go get github.com/betterfor/retract@v0.2.0 go: warning: github.com/betterfor/retract@v0.2.0: retracted by module author: tag version error go: to switch to the latest unretracted version, run: go get github.com/betterfor/retract@latestgo get: downgraded github.com/betterfor/retract v0.3.0 =\u003e v0.2.0 我们发现出现warning信息，但是这个版本的包还是可用的。 我们来查看模块的版本列表 $ go list -m -versions github.com/betterfor/retract github.com/betterfor/retract v0.1.0 v0.3.0 此时我们查看模块的版本发现，没有v0.2.0版本了。 通过增加-retracted选项可以查看撤回的版本。 $ go list -m -versions -retracted github.com/betterfor/retract github.com/betterfor/retract v0.1.0 v0.2.0 v0.3.0 那么我们怎么知道我们的项目有没有依赖已撤回版本的模块呢？使用go list命令 $ go list -m -u all awesomeProjcet github.com/betterfor/retract v0.2.0 (retracted) [v0.3.0] ","date":"2021-02-25","objectID":"/2021/02/golang_retract/:2:0","tags":["golang"],"title":"Golang 1.16版本新特性 =\u003e 撤回版本(retract)","uri":"/2021/02/golang_retract/"},{"categories":["月霜天的GO"],"content":"问题 如果模块现在的版本是v0版本，不小心发布了v1版本，需要撤回v1版本，该怎么操作？ 1、按照上面的操作步骤进行，我们发现打过v1.0.0版本后,仍会显示v1.0.0 $ go list -m -versions github.com/betterfor/retract github.com/betterfor/retract v0.1.0 v0.3.0 v0.4.0 v1.0.0 这就要求我们需要使用一个比v1.0.0大的版本号v1.0.1来写入撤回信息。 module github.com/betterfor/retract go 1.16 retract ( // tag version error v0.2.0 // v1 提前发布了 [v1.0.0, v1.0.1] ) 将这次改动提交，并标记一个新的版本v1.0.1。 然后拉取模块 $ go get github.com/betterfor/retract@v1.0.0 $ go get github.com/betterfor/retract@v1.0.1 $ go get github.com/betterfor/retract@v0.4.0 go list -m -versions github.com/betterfor/retract github.com/betterfor/retract v0.1.0 v0.3.0 v0.4.0 ok! v0.4.0就是最新的版本 如果你将来发布v1版本时，应该要从v1.0.2开始，因为v1.0.0和v1.0.1已经被占用了 ","date":"2021-02-25","objectID":"/2021/02/golang_retract/:3:0","tags":["golang"],"title":"Golang 1.16版本新特性 =\u003e 撤回版本(retract)","uri":"/2021/02/golang_retract/"},{"categories":["月霜天的小笔记"],"content":" Docker是一个虚拟环境容器，可以将你的开发环境、代码、配置文件等一并打包到这个容器中，并发布和应用到任意平台中。所以你需要知道一点docker的命令。 这里是关于docker的基础命令（第一节） 版本信息：查看docker的各项基础信息 仓库管理：管理镜像存储的仓库 版本信息 ","date":"2021-02-12","objectID":"/2021/02/docker_command/:0:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"info docker info：显示Docker系统信息，包括镜像、容器数量和镜像仓库。 语法 docker info [OPTIONS] Options: -f, --format string 显示返回值的模板文件 实例 Client: Context: default Debug Mode: false Plugins: app: Docker App (Docker Inc., v0.9.1-beta3) buildx: Build with BuildKit (Docker Inc., v0.5.1-docker) Server: Containers: 1 Running: 1 Paused: 0 Stopped: 0 Images: 1 Server Version: 20.10.3 Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options: seccomp Profile: default Kernel Version: 3.10.0-1160.15.2.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 1.795GiB Name: localhost.localdomain ID: 4NYR:4KA5:NBOL:V6Y7:SE6H:B2R7:2LRD:FNIL:CK5J:4L4J:6K63:5RMO Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Live Restore Enabled: false ","date":"2021-02-12","objectID":"/2021/02/docker_command/:1:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"version docker version：显示Docker版本信息。 语法 docker version [OPTIONS] Options: -f, --format string 显示返回值指定的模板文件 --kubeconfig string k8s配置文件 实例 Client: Docker Engine - Community Version: 20.10.3 API version: 1.41 Go version: go1.13.15 Git commit: 48d30b5 Built: Fri Jan 29 14:34:14 2021 OS/Arch: linux/amd64 Context: default Experimental: true Server: Docker Engine - Community Engine: Version: 20.10.3 API version: 1.41 (minimum version 1.12) Go version: go1.13.15 Git commit: 46229ca Built: Fri Jan 29 14:32:37 2021 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.4.3 GitCommit: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc: Version: 1.0.0-rc92 GitCommit: ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init: Version: 0.19.0 GitCommit: de40ad0 通常刚安装完docker时，使用docker version来验证docker的client和server是否可用。如果server显示权限不足，可以通过sudo docker或 给docker添加sudo权限。 镜像仓库 ","date":"2021-02-12","objectID":"/2021/02/docker_command/:2:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"login docker login：登录到一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库。 语法 docker login [OPTIONS] [SERVER] Options: -p, --password string 登录的密码 --password-stdin 使用标准输入输入密码 -u, --username string 登录的用户名 实例 docker login -u 用户名 -p 密码 ","date":"2021-02-12","objectID":"/2021/02/docker_command/:3:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"logout docker logout：登出一个Docker镜像仓库，如果没有指定镜像仓库地址，默认为官方仓库。 语法 docker logout [SERVER] 实例 docker logout ","date":"2021-02-12","objectID":"/2021/02/docker_command/:4:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"pull docker pull：从镜像仓库中拉取或者更新指定镜像。 语法 docker pull [OPTIONS] NAME[:TAG|@DIGEST] Options: -a, --all-tags 下载镜像在仓库中的所有版本 --disable-content-trust 忽略镜像的校验，默认开启 --platform string 如果服务器支持多平台，设置平台 -q, --quiet 静默拉取 实例 docker pull hello-world docker pull hello-world -a docker pull hello-wprld -q ","date":"2021-02-12","objectID":"/2021/02/docker_command/:5:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"push docker push：将本地的镜像上传到镜像仓库（已经登录到镜像仓库）。 语法 docker push [OPTIONS] NAME[:TAG] Options: -a, --all-tags 推送本地所有打过tag的镜像 --disable-content-trust 忽略镜像的检验，默认开启 -q, --quiet 静默上传 实例 docker push hello-world:v1 ","date":"2021-02-12","objectID":"/2021/02/docker_command/:6:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"search docker search：从镜像仓库中查找镜像。 语法 docker search [OPTIONS] TERM Options: -f, --filter filter 根据过滤的条件输出结果 --format string 使用特定的模板输出搜索结果 --limit int 最大搜索结果，默认25 --no-trunc 显示完整的镜像描述 实例 docker search hello-world -f STARS=10 --limit=2 NAME DESCRIPTION STARS OFFICIAL AUTOMATED hello-world Hello World! (an example of minimal Dockeriz… 1380 [OK] tutum/hello-world Image to test docker deployments. Has Apache… 78 [OK] 参数说明： NAME：镜像仓库源的名称 DESCRIPTION：镜像的描述 STARS：表示点赞，关注的个数 OFFICIAL：是否是官方发布 AUTOMATED：自动构建 ","date":"2021-02-12","objectID":"/2021/02/docker_command/:7:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"images docker images：列出本地镜像 语法 docker images [OPTIONS] [REPOSITORY[:TAG]] Options: -a, --all 列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层） --digests 显示镜像的摘要信息 -f, --filter filter 显示满足条件的镜像 --format string 指定返回值的模板文件 --no-trunc 显示完整的镜像信息 -q, --quiet 只显示镜像ID 实例 docker images REPOSITORY TAG IMAGE ID CREATED SIZE registry.cn-hangzhou.aliyuncs.com/google_containers/kicbase v0.0.15-snapshot4 06db6ca72446 2 months ago 941MB hello-world latest bf756fb1ae65 13 months ago 13.3kB ","date":"2021-02-12","objectID":"/2021/02/docker_command/:8:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"rmi docker rmi：删除本地一个或多个镜像 语法 docker rmi [OPTIONS] IMAGE [IMAGE...] Options: -f, --force 强制删除 --no-prune 不移除该镜像的过程镜像，默认移除 实例 docker rmi hello-world -f Untagged: hello-world:latest Untagged: hello-world@sha256:31b9c7d48790f0d8c50ab433d9c3b7e17666d6993084c002c2ff1ca09b96391d Deleted: sha256:bf756fb1ae65adf866bd8c456593cd24beb6a0a061dedf42b26a993176745f6b Deleted: sha256:9c27e219663c25e0f28493790cc0b88bc973ba3b1686355f221c38a36978ac63 ","date":"2021-02-12","objectID":"/2021/02/docker_command/:9:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"tag docker tag：标记本地镜像，将其归入某一仓库。 语法 docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG] 用法 docker tag hello-world hello-world:v1 docker images hello-world REPOSITORY TAG IMAGE ID CREATED SIZE hello-world latest bf756fb1ae65 13 months ago 13.3kB hello-world v1 bf756fb1ae65 13 months ago 13.3kB ","date":"2021-02-12","objectID":"/2021/02/docker_command/:10:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"build docker build：使用Dockerfile创建镜像。 语法 docker build [OPTIONS] PATH | URL | - Options: --add-host list 添加(host:ip) --build-arg list 设置镜像创建时的变量 --cache-from strings 镜像缓存 --cgroup-parent string 容器可选的父cgroup --compress 压缩构建上下文使用gzip --cpu-period int 限制cpu cfs周期 --cpu-quota int 限制cpu cfs配额 -c, --cpu-shares int 设置cpu使用权重 --cpuset-cpus string 设置使用的cpu id --cpuset-mems string 设置使用的内存id --disable-content-trust 忽略校验，默认开启 -f, --file string 指定要使用的Dockerfile路径，默认是'PATH/Dockerfile' --force-rm 设置镜像过程中删除中间容器 --iidfile string 写入镜像id到文件 --isolation string 使用容器隔离技术 --label list 设置镜像使用的元数据 -m, --memory bytes 设置内存最大值 --memory-swap bytes 设置swap的最大值为内存+swap，-1表示不受限 --network string 在构建期间设置RUN指令的网络模式，默认为\"default\" --no-cache 创建镜像过程中不使用缓存 --pull 尝试去更新镜像的最新版本 -q, --quiet 安静模式，成功后只输出镜像ID --rm 设置镜像成功后删除中间容器 --security-opt strings 安全选项 --shm-size bytes 设置/dev/shm，默认值是64M -t, --tag list 镜像的名字及标签，通常为'name:tag'格式，可以在一次构建中为一个镜像设置多个标签 --target string 设置指定构建步骤 --ulimit ulimit Ulimit选项 用法 docker build -t my-image:v1 . ","date":"2021-02-12","objectID":"/2021/02/docker_command/:11:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"history docker history：展示一个镜像的历史。 语法 docker history [OPTIONS] IMAGE Options: --format string 指定模板输出 -H, --human 以可读的格式打印镜像大小和日期，默认true --no-trunc 显示完整的提交记录 -q, --quiet 仅列出提交记录的ID 实例 docker history hello-world:v1 IMAGE CREATED CREATED BY SIZE COMMENT bf756fb1ae65 13 months ago /bin/sh -c #(nop) CMD [\"/hello\"] 0B \u003cmissing\u003e 13 months ago /bin/sh -c #(nop) COPY file:7bf12aab75c3867a… 13.3kB ","date":"2021-02-12","objectID":"/2021/02/docker_command/:12:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"save docker save：保存一个或多个镜像成tar归档文件（默认标准输出）。 语法 docker save [OPTIONS] IMAGE [IMAGE...] Options: -o, --output string 输出到的文件 实例 docker save -o hello.tar hello-world:v1 ll hello.tar -rw-------. 1 golang golang 24576 2月 11 19:57 hello.tar ","date":"2021-02-12","objectID":"/2021/02/docker_command/:13:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"load docker load：导入使用docker save命令导出的镜像。 语法 docker load [OPTIONS] Options: -i, --input string 指定导入的文件，代替标准输入 -q, --quiet 精简输出信息 实例 $ docker images hello-world REPOSITORY TAG IMAGE ID CREATED SIZE $ docker load -i hello.tar 9c27e219663c: Loading layer [==================================================\u003e] 15.36kB/15.36kB Loaded image: hello-world:v1 $ docker images hello-world REPOSITORY TAG IMAGE ID CREATED SIZE hello-world v1 bf756fb1ae65 13 months ago 13.3kB ","date":"2021-02-12","objectID":"/2021/02/docker_command/:14:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"import docker import：从归档文件中创建镜像。 语法 docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] Options: -c, --change list 应用docker指令创建镜像 -m, --message string 提交时的说明文字 --platform string 设置多平台可用 实例 $ docker import hello.tar hello-world:v2 sha256:0243f312226d99ba0cd5e167e894c2910803595a8f81aec270305ae52dca41e6 $ docker images hello-world REPOSITORY TAG IMAGE ID CREATED SIZE hello-world v2 0243f312226d 7 seconds ago 18.3kB ","date":"2021-02-12","objectID":"/2021/02/docker_command/:15:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"image docker image：管理镜像 语法 docker image COMMAND Commands: build 同docker build history 同docker history import 同docker import inspect 展示镜像的详细信息 load 同docker load ls 列举镜像 prune 删除未使用的镜像 pull 同docker pull push 同docker push rm 同docker rmi save 同docker save tag 同docker tag ","date":"2021-02-12","objectID":"/2021/02/docker_command/:16:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的GO"],"content":"什么是defer？ defer是go语言提供的一种用于注册延迟调用的机制，让函数或语句可以在当前函数执行完毕后（包括通过return正常结束或panic导致的异常结束）执行。 适用场景： 打开/关闭连接 加锁/释放锁 打开/关闭文件等 defer在一些需要回收资源的场景非常有用，可以很方便在函数结束前做一些清理工作。 ","date":"2021-02-11","objectID":"/2021/02/defer/:1:0","tags":["defer","golang"],"title":"Defer的使用方法","uri":"/2021/02/defer/"},{"categories":["月霜天的GO"],"content":"为什么要用defer？ 在编程过程中，经常需要打开一些资源，比如数据库、文件、锁等，这些资源都需要用完释放，否则会造成内存泄漏。 当然在使用过程中，可以在函数结束时显式关闭资源，但是如果在打开和关闭资源之间如果发生了panic会退出函数，导致关闭资源没有被执行。因为这样一颗语法糖，减少了很多资源泄漏的情况。 ","date":"2021-02-11","objectID":"/2021/02/defer/:2:0","tags":["defer","golang"],"title":"Defer的使用方法","uri":"/2021/02/defer/"},{"categories":["月霜天的GO"],"content":"defer底层 官方对defer的解释： Each time a “defer” statement executes, the function value and parameters to the call are evaluated as usual and saved anew but the actual function is not invoked. Instead, deferred functions are invoked immediately before the surrounding function returns, in the reverse order they were deferred. If a deferred function value evaluates to nil, execution panics when the function is invoked, not when the “defer” statement is executed. 每次defer语句执行时，会把函数“压栈”，函数的参数会被拷贝下来，当外层函数退出时，defer函数按照定义的逆序执行，如果defer执行的函数为nil，那么会在最终调用函数产生panic。 这里有一道经典题： func main() { a,b := 1,2 defer cal(\"1\",a,cal(\"10\",a,b)) a = 0 defer cal(\"2\",a,cal(\"20\",a,b)) } func cal(index string, a, b int) int { ret := a + b fmt.Println(index,a,b,ret) return ret } // Output: 10 1 2 3 20 0 2 2 2 0 2 2 1 1 3 4 这是遵循先入后出的原则，同时保留当前变量的值。 看看下面这道题： func f1() (r int) { defer func() { r++ } return 0 } func f2() (r int) { t := 5 defer func() { t = t + 5 } return t } func f3() (r int) { defer func(r int) { r = r + 5 }(r) return 1 } // Output: 1 5 1 你能正确答对吗？ 关键点在于理解这条语句： return xxx 这条语句并不是一个原子命令，经过编译后，变成3条指令： 1、返回值=xxx 2、调用defer函数 3、空的return 那么我们来拆解上面3个函数。 func f1() (r int) { // 1、赋值 r = 0 // 2、闭包引用 defer func() { r++ } // 3、空的return return 0 } // defer是闭包引用，所以返回值被修改，所以f1()返回1 func f2() (r int) { t := 5 // 1、赋值 r = t // 2、闭包引用，但没有修改r defer func() { t = t + 5 } // 3、空的return return t } // 没涉及返回值r的操作，所以返回5 func f3() (r int) { // 1、赋值 r = 1 // 2、r作为参数传值，不会修改返回值的r defer func(r int) { r = r + 5 }(r) // 3、空的return return } // 第二步r是作为函数参数使用的，是一份复制，defer语句中的r和外面的r是两个变量，里面r的变化不会改变外面r，所以返回1. ","date":"2021-02-11","objectID":"/2021/02/defer/:3:0","tags":["defer","golang"],"title":"Defer的使用方法","uri":"/2021/02/defer/"},{"categories":["月霜天的GO"],"content":"iota是golang语言的常数计量器，只能在常量的表达式中使用。 iota在const关键字出现时被重置为0(const内部的第一行之前)。使用iota能简化定义。 1、iota只能在常量的表达式使用。 2、每次const出现时，都会让iota初始化为0，使后面的变量自动增长。 const ( a = iota // 0 b // 1 c // 2 ) 3、允许自定义类型 // go/src/time/time.go type Weekday int const ( Sunday Weekday = iota Monday Tuesday Wednesday Thursday Friday Saturday ) 周日对应0，周一对应1，如此类推。 4、可以跳过的值 type Weekday int const ( Sunday Weekday = iota Monday _ _ Thursday Friday Saturday ) 对应的值不变，适用场景：某些枚举值可能不需要。 5、位掩码 const ( a = 1\u003c\u003ciota // 1 b // 2 c // 4 ) 是连续的2的幂。 6、数量级 const ( B = 1 \u003c\u003c (10*iota) KB MB GB TB ) 按照这样的生成规则可以按照数量级生成值。 7、定义在一行的情况 const ( a,b = iota,iota+1 // 0,1 c,d // 1,2 e,f // 2,3 ) iota会在下一行得到增长，而不是立即获取它的应用。 8、中间插队 const ( a = iota // 0 b = 2 // 2 c // 2 d = iota // 3 ) const ( a = 2 // 2 b = iota // 1 c // 2 ) ","date":"2021-02-10","objectID":"/2021/02/itoa/:0:0","tags":["iota"],"title":"Iota的使用方法","uri":"/2021/02/itoa/"},{"categories":["月霜天的GO"],"content":"背景 在复杂的分布式系统中，往往需要对大量的数据和消息进行唯一标识。数据日益增长，对数据库需要进行切分，而水平切分数据库需要一个唯一ID来标识一条数据或消息，数据库的自增ID显然不能满足需求。那么对于分布式全局ID有什么要求呢？ 全局唯一性：不能出现重复的ID号。 趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。 单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。 信息安全：如果ID是连续的，会出现安全问题，在一些场景中，会需要ID无规则，不规则。 ","date":"2021-02-08","objectID":"/2021/02/uuid/:1:0","tags":["uuid","snowflake"],"title":"生成uuid的几种方式","uri":"/2021/02/uuid/"},{"categories":["月霜天的GO"],"content":"UUID UUID(Universally Unique Identifier)是一个128位标识符，在其规范的文本表示中，UUID 的 16 个 8 位字节表示为 32 个十六进制（基数16）数字，显示在由连字符分隔 ‘-’ 的五个组中，“8-4-4-4-12” 总共 36 个字符（32 个字母数字字符和 4 个连字符）。例如：123e4567-e89b-12d3-a456-426655440000。 优点：性能高，本地生成，没有网络消耗 缺点： 1、不易存储：UUID太长，很多场景不适用。 2、信息不安全：基于MAC地址生成的UUID算法可能造成MAC地址泄露。 3、没有排序，无法保证递增趋势。 4、不易读，存储空间大。 go两种生成UUID的第三方包： github.com/google/uuid github.com/satori/go.uuid ","date":"2021-02-08","objectID":"/2021/02/uuid/:2:0","tags":["uuid","snowflake"],"title":"生成uuid的几种方式","uri":"/2021/02/uuid/"},{"categories":["月霜天的GO"],"content":"Snowflake snowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。 1、实现原理： 1位最高位：符号位不使用，0表示正数，1表示负数。 41位时间戳：1\u003c\u003c41 = 1000*3600*24*365 = 69 年。 10位工作机器id：如果我们对IDC划分有需求可以用5位给IDC，5位给工作机器，这样就可以表示32个IDC，每个IDC下有32台机器。 12位自增ID：可以表示2^12^个ID。 理论上snowflake方案的QPS约为409.3w/s，这种分配方式可以保证在任何一个IDC的任何一台机器在任意毫秒内生成的ID都是不同的。 优点： 毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。 可以根据自身业务特性分配bit位，非常灵活。 缺点： 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。 代码实现： package main import ( \"errors\" \"fmt\" \"runtime\" \"sync\" \"time\" ) //global var var sequence int = 0 var lastTime int = -1 //every segment bit var workerIdBits = 5 var datacenterIdBits = 5 var sequenceBits = 12 //every segment max number var maxWorkerId int = -1 ^ (-1 \u003c\u003c workerIdBits) var maxDatacenterId int = -1 ^ (-1 \u003c\u003c datacenterIdBits) var maxSequence int = -1 ^ (-1 \u003c\u003c sequenceBits) //bit operation shift var workerIdShift = sequenceBits var datacenterShift = workerIdBits + sequenceBits var timestampShift = datacenterIdBits + workerIdBits + sequenceBits type Snowflake struct { datacenterId int workerId int epoch int mt *sync.Mutex } func NewSnowflake(datacenterId int, workerId int, epoch int) (*Snowflake, error) { if datacenterId \u003e maxDatacenterId || datacenterId \u003c 0 { return nil, errors.New(fmt.Sprintf(\"datacenterId cant be greater than %d or less than 0\", maxDatacenterId)) } if workerId \u003e maxWorkerId || workerId \u003c 0 { return nil, errors.New(fmt.Sprintf(\"workerId cant be greater than %d or less than 0\", maxWorkerId)) } if epoch \u003e getCurrentTime() { return nil, errors.New(fmt.Sprintf(\"epoch time cant be after now\")) } sf := Snowflake{datacenterId, workerId, epoch, new(sync.Mutex)} return \u0026sf, nil } func (sf *Snowflake) getUniqueId() int { sf.mt.Lock() defer sf.mt.Unlock() //get current time currentTime := getCurrentTime() //compute sequence if currentTime \u003c lastTime { //occur clock back //panic or wait,wait is not the best way.can be optimized. currentTime = waitUntilNextTime(lastTime) sequence = 0 } else if currentTime == lastTime { //at the same time(micro-second) sequence = (sequence + 1) \u0026 maxSequence if sequence == 0 { //overflow max num,wait next time currentTime = waitUntilNextTime(lastTime) } } else if currentTime \u003e lastTime { //next time sequence = 0 lastTime = currentTime } //generate id return (currentTime-sf.epoch)\u003c\u003ctimestampShift | sf.datacenterId\u003c\u003cdatacenterShift | sf.workerId\u003c\u003cworkerIdShift | sequence } func waitUntilNextTime(lasttime int) int { currentTime := getCurrentTime() for currentTime \u003c= lasttime { time.Sleep(1 * time.Second / 1000) //sleep micro second currentTime = getCurrentTime() } return currentTime } func getCurrentTime() int { return int(time.Now().UnixNano() / 1e6) //micro second } func main() { runtime.GOMAXPROCS(runtime.NumCPU()) datacenterId := 0 workerId := 0 epoch := 1596850974657 s, err := NewSnowflake(datacenterId, workerId, epoch) if err != nil { panic(err) } var wg sync.WaitGroup for i := 0; i \u003c 1000000; i++ { wg.Add(1) go func() { fmt.Println(s.getUniqueId()) wg.Done() }() } wg.Wait() } ","date":"2021-02-08","objectID":"/2021/02/uuid/:3:0","tags":["uuid","snowflake"],"title":"生成uuid的几种方式","uri":"/2021/02/uuid/"},{"categories":["月霜天的GO"],"content":"数据库ID 利用数据库字段设置auto_increment_increment和auto_increment_offset来保证ID自增，每次业务使用一下SQL读写MySQL得到ID。 begin;REPLACEintoTickets(id)values(null);selectLAST_INSERT_ID();commit; 优点：简单，利用数据库的功能实现，成本小；id单调递增。 缺点：强依赖数据库，当数据库不可用时，是致命问题；ID发号性能瓶颈限制在单台MySQL的读写性能上。 对于MySQL性能问题，可用如下方法解决： 在分布式系统中部署多台机器，每台机器设置不同的初始值，且步长相等。例如设置步长为2，TicketServer1的初始值为1 (1,3,5,7...), TicketServer1的初始值为2(2,4,6,8...)。 主键生成策略 缺点： 水平扩展比较困难，事先定好步长和机器后，如果后续新增机器，不容易扩容。 数据库压力还是大，只能靠堆机器来提高性能。 ","date":"2021-02-08","objectID":"/2021/02/uuid/:4:0","tags":["uuid","snowflake"],"title":"生成uuid的几种方式","uri":"/2021/02/uuid/"},{"categories":["月霜天的GO"],"content":"MongoDB ID MongoDB官方文档 ObjectID和snowflake算法类似，它设计成轻量型的，不同的机器都能用全局唯一的同种方法便利生成。通过 时间戳+机器+pid+自增id 共12个字节，通过 4+3+2+3 的方式生成24位的十六进制字符。 ","date":"2021-02-08","objectID":"/2021/02/uuid/:5:0","tags":["uuid","snowflake"],"title":"生成uuid的几种方式","uri":"/2021/02/uuid/"},{"categories":["月霜天的GO"],"content":"Zookeeper ID zookeeper主要通过其znode数据版本来生成序列号，可以生成32位和64位的数据版本号，客户端可以使用这个版本号来作为唯一的序列号。 很少会使用zookeeper来生成唯一ID。主要是由于需要依赖zookeeper，并且是多步调用API，如果在竞争较大的情况下，需要考虑使用分布式锁。因此，性能在高并发的分布式环境下，也不甚理想。 ","date":"2021-02-08","objectID":"/2021/02/uuid/:6:0","tags":["uuid","snowflake"],"title":"生成uuid的几种方式","uri":"/2021/02/uuid/"},{"categories":["月霜天的GO"],"content":"二维数组的排列顺序 数组在内存中是按行存储的，按行遍历时可以由指向数组的第一个数的指针一直向后遍历，由于二维数组的内存地址是连续的，当前行的尾和下一行的头相邻。 用代码来打印数组的地址。 func main() { var a int32 fmt.Println(unsafe.Sizeof(a)) n := 4 array := generateArray(n) for i := 0; i \u003c n; i++ { fmt.Printf(\"%p \\n\",array[i]) } } func generateArray(n int) [][]int32 { var arr = make([][]int32,n) for i := 0; i \u003c n; i++ { arr[i] = make([]int32,n) for j := 0; j \u003c n; j++ { arr[i][j] = 1 } } return arr } // Output: 4 0xc0000a0090 0xc0000a00a0 0xc0000a00b0 0xc0000a00c0 int32占用4个字节，4个int32占用16个字节，这与我们得到一个数组的地址是对应的。 我们眼中的二维数组 内存中的二维数组 那么二维数组按行遍历相当于按照内存顺序读取，而按列遍历不按内存顺序读取。 按行读取比按列读取的效率高体现在以下几个方面： CPU高速缓存：在计算机系统中，CPU高速缓存（英语：CPU Cache，在本文中简称缓存）是用于减少处理器访问内存所需平均时间的部件。在金字塔式存储体系中它位于自顶向下的第二层，仅次于CPU寄存器。其容量远小于内存，但速度却可以接近处理器的频率。当处理器发出内存访问请求时，会先查看缓存内是否有请求数据。如果存在（命中），则不经访问内存直接返回该数据；如果不存在（失效），则要先把内存中的相应数据载入缓存，再将其返回处理器。缓存之所以有效，主要是因为程序运行时对内存的访问呈现局部性（Locality）特征。这种局部性既包括空间局部性（Spatial Locality），也包括时间局部性（Temporal Locality）。有效利用这种局部性，缓存可以达到极高的命中率。 缓存从内存中抓取一般都是整个数据块，所以它的物理内存是连续的，几乎都是同行不同列的，而如果内循环以列的方式进行遍历的话，将会使整个缓存块无法被利用，而不得不从内存中读取数据，而从内存读取速度是远远小于从缓存中读取数据的。随着数组元素越来越多，按列读取速度也会越来越慢。 代码验证 func main() { arr := generateArray(2000) t0 := time.Now() readCols(arr) t1 := time.Now() readRows(arr) t2 := time.Now() fmt.Println(t1.Sub(t0),t2.Sub(t1)) } func generateArray(n int) [][]int32 { var arr = make([][]int32,n) for i := 0; i \u003c n; i++ { arr[i] = make([]int32,n) for j := 0; j \u003c n; j++ { arr[i][j] = 1 } } return arr } func readCols(arr [][]int) { for i := 0; i \u003c len(arr); i++ { for j := 0; j \u003c len(arr[0]); j++ { arr[i][j] = 1 } } } func readRows(arr [][]int) { for i := 0; i \u003c len(arr); i++ { for j := 0; j \u003c len(arr[0]); j++ { arr[j][i] = 1 } } } 可以验证按列读取的时间远远大于按行读取。 ","date":"2021-02-08","objectID":"/2021/02/%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E9%81%8D%E5%8E%86%E6%95%88%E7%8E%87/:1:0","tags":["二维数组"],"title":"二维数组按行和按列遍历的效率","uri":"/2021/02/%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E9%81%8D%E5%8E%86%E6%95%88%E7%8E%87/"},{"categories":["月霜天的小笔记"],"content":"排序算法 所谓的排序算法就是将一串记录，按照递增或递减的顺序排列起来。 通常提到的一共有十种排序：冒泡、选择、插入、快速、归并、堆、希尔、计数、桶、基数 比较类排序：通过比较来决定元素间的相对次序，通常其时间复杂度不能突破O(nlogn)，因此又称为非线性时间比较类排序。 非比较类排序：不通过比较元素间的相对次序，可以突破基于比较排序的时间下限，以线性时间运行，因此又称为线性时间非比较类排序。 时间复杂度： 排序方法 时间复杂度(平均) 时间复杂度(最坏) 时间复杂度(最好) 空间复杂度 稳定性 冒泡排序 O(n^2^) O(n^2^) O(n) O(1) 稳定 选择排序 O(n^2^) O(n^2^) O(n^2^) O(1) 不稳定 插入排序 O(n^2^) O(n^2^) O(n) O(1) 稳定 快速排序 O(nlogn) O(n^2^) O(nlogn) O(nlogn) 不稳定 归并排序 O(nlogn) O(nlogn) O(nlogn) O(n) 稳定 堆排序 O(nlogn) O(nlogn) O(nlogn) O(1) 不稳定 希尔排序 O(n^1.3^) O(n^2^) O(n) O(1) 稳定 计数排序 O(n+k) O(n+k) O(n+k) O(n+k) 稳定 桶排序 O(n+k) O(n^2^) O(n) O(n+k) 稳定 基数排序 O(n*k) O(n*k) O(n*k) O(n+k) 稳定 稳定性：如果a=b，并且a在b的前面，排序后a一定在b的前面，那么称算法是稳定的，如果不一定在前面，那么称算法是不稳定的。 ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:1:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"冒泡排序 冒泡排序(Bubble Sort)是一种简单直观的排序算法。它重复地访问要排序的数列，一次比较两个元素，如果顺序错误就调换顺序。走访数列的工作是重复地进行指导没有再需要元素交换，也就是说该数列已经排序完成。由于越小的元素会经过交换慢慢地到达顶端，就像泡泡一样会上浮，所以称为冒泡排序。 1、算法步骤 ​ 1、比较相邻的元素，如果第一个比第二个大，就交换它们。 ​ 2、对每一对相邻元素做同样的工作，从开始第一对到结尾的最后一对，这步做完后，末尾元素是最大的元素。 ​ 3、针对所有的元素重复以上步骤，除了最后一个元素 ​ 4、重复步骤1~3，直到没有任意一对元素需要比较。 2、动画演示 3、情况 最好情况：数列是正序，只需要遍历一遍，时间复杂度最好为O(n)。 最坏情况：数列是倒序，每一对都需要进行比较，时间复杂度最坏为O(n^2^)。 时间复杂度平均为O(n^2^)，空间复杂度为O(1)，是稳定排序。 4、Golang实现 func bubbleSort(arr []int) { n := len(arr) for i := 0; i \u003c n-1; i++ { for j := i + 1; j \u003c n; j++ { if arr[i] \u003e arr[j] { arr[i], arr[j] = arr[j], arr[i] } } } } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:2:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"选择排序 选择排序(Selection Sort)是一种简单直观的排序算法。它的工作原理是：首先在序列中找到最小元素，放在序列的首位，然后再从剩下的序列中寻找最小元素，放到已排序序列的末尾。 1、算法步骤 ​ 1、首先在未排序序列中找到最小元素，存放到排序序列的起始位置 ​ 2、再从剩余未排序序列中继续寻找最小元素，存放到排序序列的末尾 ​ 3、重复第2步，直到所有元素排序完毕。 2、动画演示 3、情况 时间复杂度为O(n^2^)，因为无论如何都需要遍历序列找到最小值，所以最好和最坏都是O(n^2^)。 空间复杂度为O(n^2^)，是不稳定排序。 4、Golang实现 func selectionSort(arr []int) { for i := 0; i \u003c len(arr); i++ { min := i for j := i + 1; j \u003c len(arr); j++ { if arr[j] \u003c arr[min] { min = j } } arr[min], arr[i] = arr[i], arr[min] } } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:3:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"插入排序 插入排序(Insertion Sort)是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列由后向前扫描，找到相应位置并插入。 1、算法步骤 ​ 1、把第一个元素看成一个有序序列，把第二个元素到最后一个元素看成一个未排序序列。 ​ 2、从头扫描，将扫描到的每个元素插入有序序列的适当位置。 2、动画演示 3、情况 最坏情况：每一个待插入的元素都需要插入到序列首位，即原序列是倒序序列，时间复杂度为O(n^2^)。 最好情况：每一个待插入的元素都需要插入到序列末位，即原序列是正序序列，时间复杂度为O(n) 。 时间复杂度平均为 O(n^2^)，空间复杂度为O(1) 是稳定排序。 4、Golang实现 func insertionSort(arr []int) { for i := 1; i \u003c len(arr); i++ { current := arr[i] preIndex := i - 1 for ; preIndex \u003e= 0 \u0026\u0026 current \u003c arr[preIndex]; preIndex-- { arr[preIndex+1] = arr[preIndex] } arr[preIndex+1] = current } } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:4:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"快速排序 快速排序(Quick Sort)是通过一趟排序将待排记录分隔成独立的两部分，其中一部分的关键字比另一部分的关键字小，则可分别对这两部分记录继续进行排序，直到整个序列有序。 1、算法步骤 ​ 1、从序列中挑出一个元素，作为基准。 ​ 2、重新排列数列，所有元素比基准小的放在基准前面，所有元素比基准大的放在基准后面。 ​ 3、递归地把小于基准元素的子序列和大于基准元素的子序列排序。 2、动画演示 3、情况 时间复杂度平均为O(nlogn) ，空间复杂度为O(nlogn)，是不稳定排序。 4、Golang实现 func quickSort(nums []int, left, right int) { if left \u003c right { mid := partition(nums,left,right) quickSort(nums,left,mid) quickSort(nums,mid+1,right) } } func partition(nums []int, left, right int) int { i,j := left+1,right for i\u003cj { if nums[i] \u003e nums[left] { nums[i],nums[j] = nums[j],nums[i] j-- } else { i++ } } if nums[i] \u003e= nums[left] { i-- } nums[left],nums[i] = nums[i],nums[left] return i } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:5:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"归并排序 归并排序(Merge Sort)是建立在归并操作上的一种有效排序算法，采用了分而治之的思想。 1、算法步骤 ​ 1、把长度为n的序列分为两个长度为n/2的子序列。 ​ 2、对这两个子序列分别采用归并排序。 ​ 3、将两个排序好的子序列合并成一个最终的排序序列。 2、动画演示 3、情况 时间复杂度为O(nlogn)，空间复杂度为O(n)，是稳定排序方法。 4、Golang实现 func mergeSort(nums []int, start,end int) { if start \u003c end { mid := (start+end)/2 mergeSort(nums,start,mid) // 左边排序 mergeSort(nums,mid+1,end) // 右边排序 merge(nums,start,mid,end) // 合并数组 } } func merge(nums []int, start, mid, end int) { i,j := start,mid+1 ret := []int{} for i \u003c= mid \u0026\u0026 j \u003c= end { if nums[i] \u003c= nums[j] { ret = append(ret, nums[i]) i++ } else { ret = append(ret, nums[j]) j++ } } ret = append(ret, nums[i:mid+1]...) ret = append(ret, nums[j:end+1]...) for k, v := range ret { nums[start+k] = v } } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:6:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"堆排序 堆排序(Heap Sort)是指利用堆这种数据结构所设计的一种排序算法。堆是一种近似于完全二叉树的结构，并同时满足堆积的性质：子节点的键值或索引总小于(或大于)父节点。 大根堆：每个节点的值都大于或等于其子节点的值，在堆排序算法中用于升序排列； 小根堆：每个节点的值都小于或等于其子节点的值，在堆排序算法中用于降序排列； 1、算法步骤 ​ 1、将待排序列构建成一个堆 H[0……n-1]，根据(升序降序)选择大根堆或小跟堆。 ​ 2、把堆顶和堆尾互换。 ​ 3、把堆的尺寸缩小 1，并调用 shift_down(0)，目的是把新的数组顶端数据调整到相应位置； ​ 4、重复步骤 2，直到堆的尺寸为 1。 2、动画演示 3、情况 时间复杂度平均为O(nlogn) ，空间复杂度 O(1)， 是不稳定排序。 4、Golang实现 func heapSort(arr []int) []int { arrLen := len(arr) buildMaxHeap(arr, arrLen) for i := arrLen - 1; i \u003e= 0; i-- { swap(arr, 0, i) arrLen -= 1 heapify(arr, 0, arrLen) } return arr } func buildMaxHeap(arr []int, arrLen int) { for i := arrLen / 2; i \u003e= 0; i-- { heapify(arr, i, arrLen) } } func heapify(arr []int, i, arrLen int) { left := 2*i + 1 right := 2*i + 2 largest := i if left \u003c arrLen \u0026\u0026 arr[left] \u003e arr[largest] { largest = left } if right \u003c arrLen \u0026\u0026 arr[right] \u003e arr[largest] { largest = right } if largest != i { swap(arr, i, largest) heapify(arr, largest, arrLen) } } func swap(arr []int, i, j int) { arr[i], arr[j] = arr[j], arr[i] } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:7:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"希尔排序 希尔排序是插入排序的改进版本，与插入排序不同之处在于，它会优先比较距离较远的元素，又称缩小增量排序。 基本思想是：先将整个待排序的序列分割成若干个子序列分别进行插入排序，待整个序列“基本有序”时，在依次进行插入排序。 1、算法步骤 ​ 1、选择一个增量序列 t1,t2, ……, tk，其中ti \u003e tj，tk=1; ​ 2、按增量序列个数k，对序列进行k趟排序 ​ 3、每趟排序，根据对应的增量ti，将待排序分割成若干长度为m的子序列，分别对各子表进行直接插入排序。当增量因子为1时，整个序列作为一个表来处理，表长度即为整个序列的长度。 2、动画演示 3、Golang实现 func shellSort(arr []int) { n := len(arr) for step := n / 2; step \u003e= 1; step /= 2 { for i := step; i \u003c n; i += step { for j := i - step; j \u003e= 0; j -= step { if arr[j] \u003e arr[j+step] { arr[j], arr[j+step] = arr[j+step], arr[j] continue } break } } } } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:8:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"计数排序 计数排序(Counting Sort)不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 1、算法步骤 ​ 1、找出原数组中元素最大值，记为max。 ​ 2、创建一个新数组count，其长度是max+1，其元素默认为0 。 ​ 3、遍历原数组中的元素，以原数组中的元素作为count数组的索引，以原数组中出现的元素次数作为count数组的元素值。 ​ 4、创建结果数组result，起始索引index。 ​ 5、遍历count数组，找出其中元素值大于0的元素，将其对应的索引作为元素值填充到result数组中去，每处理一次，count中的该元素值减1，直到该元素值不大于0，依次处理count中剩下的元素。 ​ 6、返回结果数组result。 2、动画演示 3、情况 时间复杂度为O(n+k)，空间复杂度为O(n+k)，是稳定排序。 4、Golang实现 func countingSort(arr []int, maxVal int) { n := maxVal+1 nums := make([]int,n) var sortedIndex int for i := 0; i \u003c len(arr); i++ { nums[arr[i]]++ } for i := 0; i \u003c n; i++ { for nums[i] \u003e 0 { arr[sortedIndex] = i sortedIndex++ nums[i]-- } } } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:9:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"桶排序 桶排序(Bucket Sort)是计数排序的升级版，利用函数的映射关系，高效与否的关键在于映射函数的确定。假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。 1、算法步骤 ​ 1、设置一个定量的数组当做空桶。 ​ 2、遍历数据，并且把数据一个个放入到对应的桶中。 ​ 3、对每个不是空桶进行排序。 ​ 4、从不是空桶里把排好序的数据拼接起来。 2、动画演示 3、情况 最好情况：当输入的数据均匀分配到每个桶中，时间复杂度为 O(n) 。 最坏情况：输入的数据被分配到同一个桶中，时间复杂度O(n^2^) 。 时间复杂度平均为O(n+k) ，空间复杂度为O(n+k)，是稳定排序算法。 4、Golang实现 func quickSort(nums []int, start, end int) []int { if start \u003c end { i, j := start, end key := nums[(start+end)/2] for i \u003c= j { for nums[i] \u003c key { i++ } for nums[j] \u003e key { j-- } if i \u003c= j { nums[i], nums[j] = nums[j], nums[i] i++ j-- } } if start \u003c j { nums = quickSort(nums, start, j) } if end \u003e i { nums = quickSort(nums, i, end) } } return nums } func bucketSort(nums []int, bucketNum int) []int { bucket := [][]int{} for i := 0; i \u003c bucketNum; i++ { tmp := make([]int, 1) bucket = append(bucket, tmp) } //将数据分配到桶中 for i := 0; i \u003c len(nums); i++ { bucket[nums[i]/bucketNum] = append(bucket[nums[i]/bucketNum], nums[i]) } //循环所有的桶进行排序 index := 0 for i := 0; i \u003c bucketNum; i++ { if len(bucket[i]) \u003e 1 { //对每个桶内部进行排序,使用快排 bucket[i] = quickSort(bucket[i], 0, len(bucket[i])-1) for j := 1; j \u003c len(bucket[i]); j++ { //去掉一开始的tmp nums[index] = bucket[i][j] index++ } } } return nums } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:10:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"基数排序 基数排序(Radix Sort)的原理是按照整数位数切割成不同的数字，然后按每个位数分别比较。 然后我们发现，计数排序、桶排序、基数排序都用到了桶的概念。 计数排序：每个桶只存单一键值 基数排序：根据键值的每位数字来分配桶 桶排序：每个桶存储一定范围的数值 1、算法步骤 ​ 1、取得数组中的最大数，并取得位数 ​ 2、arr为原始数组，从最低位开始取个位组成radix数组 ​ 3、对radix进行计数排序 2、动画演示 3、情况 时间复杂度为O(n*k)，空间复杂度为O(n+k)，是稳定排序算法。 4、Golang实现 func RadixSort(arr[] int) []int{ if len(arr)\u003c2{ return arr } maxl:=MaxLen(arr) return RadixCore(arr,0,maxl) } func RadixCore(arr []int,digit,maxl int) []int{ if digit\u003e=maxl{ return arr } radix:=10 count:=make([]int,radix) bucket:=make([]int,len(arr)) for i:=0;i\u003clen(arr);i++{ count[GetDigit(arr[i],digit)]++ } for i:=1;i\u003cradix;i++{ count[i]+=count[i-1] } for i:=len(arr)-1;i\u003e=0;i--{ d:=GetDigit(arr[i],digit) bucket[count[d]-1]=arr[i] count[d]-- } return RadixCore(bucket,digit+1,maxl) } func GetDigit(x,d int) int{ a:=[]int{1,10,100,1000,10000,100000,1000000} return (x/a[d])%10 } func MaxLen(arr []int) int{ var maxl,curl int for i:=0;i\u003clen(arr);i++{ curl=len(strconv.Itoa(arr[i])) if curl\u003emaxl{ maxl=curl } } return maxl } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:11:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小教程"],"content":"使用Navicate 15连接Oracle数据库出现如下错误 通过查询可知是oci.dll版本太低，使用的11.2版本。因为Navicate是通过Oracle客户端连接Oracle服务器，Oracle的客户端分为两种，一种是标准版，一种是简洁版，即Oracle Install Client。出现ORA-28547错误时，多数是因为Navicat本地的OCI版本与Oracle服务器服务器不符造成的。 OCI下载地址 这里看到许多文章提示不管使用的32位系统还是64位系统都应下载32为的Install Client 这里我实际操作了一下，64位的系统并不支持32位，所以一定要根据自己的系统版本下载。 打开Navicate程序，打开 “工具” -\u003e “选项” -\u003e “环境” -\u003e “OCI环境” 将刚才下载的oci.dll文件完整目录填上，确定后重启Navicate，就会发现可以成功连接了。 ","date":"2021-01-18","objectID":"/2021/01/oracle_connect/:0:0","tags":["问题","oracle"],"title":"使用Navicate连接Oracle失败 ORA-25847:connection to server failed,probable Orable Net admin error","uri":"/2021/01/oracle_connect/"},{"categories":["月霜天的小笔记"],"content":"并查集 目的: 解决元素分组问题 用途: 1、判断有向图中是否产生环 2、维护无向图的连通性，判断两个点是否在同一个连通块中 操作: 1、初始化: 每个集合的parent都是自己 2、查询: 查询集合的parent 3、合并: 把不相连的元素合并到同一个集合中 ","date":"2021-01-11","objectID":"/2021/01/%E5%B9%B6%E6%9F%A5%E9%9B%86/:0:1","tags":["golang","算法"],"title":"并查集","uri":"/2021/01/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"categories":["月霜天的小笔记"],"content":"方法 1、初始化 假如有编号为1, 2, 3, …, n的n个元素，我们用一个数组fa[]来存储每个元素的父节点（因为每个元素有且只有一个父节点，所以这是可行的）。 一开始，我们先将它们的父节点设为自己。 var fa = make([]int,n) for i := 0; i \u003c n; i++ { fa[i] = i } 2、查询 我们用递归的写法实现对代表元素的查询：一层一层访问父节点，直至根节点（根节点的标志就是父节点是本身）。 要判断两个元素是否属于同一个集合，只需要看它们的根节点是否相同即可。 find = func(x int) int { if x == fa[x] { return x } return find(fa[x]) } 路径压缩方法 find = func(x int) int { if x != fa[x] { fa[x] = find(fa[x]) } return fa[x] } 3、合并 合并操作也是很简单的，先找到两个集合的代表元素，然后将前者的父节点设为后者即可。 merge := func(i,j int) { fa[find(i)] = find(j) } 按秩合并 merge := func(i,j int) { xFa,yFa := find(i),find(j) if xFa==yFa { return } // x和y不在同一个集合中，合并它们 if xFa\u003cyFa { fa[xFa]=yFa } else if xFa \u003e yFa { fa[yFa]=xFa } else { fa[yFa]=xFa rank[x]++ } } 同时使用路径压缩、按秩（rank）合并优化的程序每个操作的平均时间仅为 O(alpha (n))， 其中 alpha (n) 是 { n=f(x)=A(x,x)} 的反函数，A 是急速增加的阿克曼函数。 因为 alpha (n) 是其反函数，故 alpha (n) 在 n 十分巨大时还是小于5。 因此，平均运行时间是一个极小的常数。 实际上，这是渐近最优算法：Fredman 和 Saks 在 1989 年解释了 Omega (alpha (n)) 的平均时间内可以获得任何并查集。 ","date":"2021-01-11","objectID":"/2021/01/%E5%B9%B6%E6%9F%A5%E9%9B%86/:0:2","tags":["golang","算法"],"title":"并查集","uri":"/2021/01/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"categories":["月霜天的小笔记"],"content":"例题 Leetcode547 班上有 N 名学生。其中有些人是朋友，有些则不是。他们的友谊具有是传递性。如果已知 A 是 B 的朋友，B 是 C 的朋友，那么我们可以认为 A 也是 C 的朋友。所谓的朋友圈，是指所有朋友的集合。 给定一个 N * N 的矩阵 M，表示班级中学生之间的朋友关系。如果M[i][j] = 1，表示已知第 i 个和 j 个学生互为朋友关系，否则为不知道。你必须输出所有学生中的已知的朋友圈总数。 示例 1: 输入: [[1,1,0], [1,1,0], [0,0,1]] 输出: 2 说明：已知学生0和学生1互为朋友，他们在一个朋友圈。 第2个学生自己在一个朋友圈。所以返回2。 示例 2: 输入: [[1,1,0], [1,1,1], [0,1,1]] 输出: 1 说明：已知学生0和学生1互为朋友，学生1和学生2互为朋友，所以学生0和学生2也是朋友，所以他们三个在一个朋友圈，返回1。 注意： N 在[1,200]的范围内。 对于所有学生，有M[i][i] = 1。 如果有M[i][j] = 1，则有M[j][i] = 1。 题解: func findCircleNum(isConnected [][]int) (ans int) { n := len(isConnected) parent := make([]int,n) for i := range parent { parent[i] = i } var find func(x int) int find = func(x int) int { if parent[x] != x { parent[x] = find(parent[x]) } return parent[x] } merge := func(from,to int) { parent[find(from)] = find(to) } for i := 0; i \u003c n; i++ { for j := i+1; j \u003c n; j++ { if isConnected[i][j] == 1 { merge(i,j) } } } for i, p := range parent { if i == p { ans++ } } return } ","date":"2021-01-11","objectID":"/2021/01/%E5%B9%B6%E6%9F%A5%E9%9B%86/:0:3","tags":["golang","算法"],"title":"并查集","uri":"/2021/01/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"categories":["月霜天的小教程"],"content":"RocketMQ 消息队列作为高并发系统的组件之一，能够帮助业务系统解构提高开发效率和系统稳定性。 优势： 削峰填谷：解决瞬时写压力导致的消息丢失、系统崩溃等问题 系统解耦：处理不同重要程度和不同能力级别系统之间的消息 提升性能：当存在一对多调用是，可以发一条消息给消息系统，让消息系统通知相关系统 蓄流压测：可以堆积一定的消息量来压测 ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:1:0","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"安装RocketMQ 官方地址 # git clone https://github.com/apache/rocketmq-docker.git # cd rocketmq-docker/ # ls CONTRIBUTING.md image-build LICENSE NOTICE product README.md stage.sh templates # cd image-build/ # ls build-image.sh Dockerfile-alpine Dockerfile-centos scripts update.sh ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:2:0","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"创建RocketMQ镜像 sh build-image.sh RMQ-VERSION BASE-IMAGE RMQ-VERSION BASE-IMAGE支持centos，alpine两种方式 我们使用 sh build-image.sh 4.7.1 alpine 构建时间有点长，需要耐心等待。 当构建完成之后会提示 Successfully built 128108c2e50d Successfully tagged apacherocketmq/rocketmq:4.7.1-alpine 那么我们就能查询到镜像 # docker images |grep mq apacherocketmq/rocketmq 4.7.1-alpine 128108c2e50d 4 9 seconds ago 145MB ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:2:1","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"生成配置 # cd .. # ls CONTRIBUTING.md image-build LICENSE NOTICE product README.md stage.sh templates # sh stage.sh 4.7.1 (这里的4.7.1对应之前的镜像版本) Stage version = 4.7.1 mkdir /root/rocketmq/rocketmq-docker/stages/4.7.1 staged templates into folder /root/rocketmq/rocketmq-docker/stages/4.7.1 # ls CONTRIBUTING.md image-build LICENSE NOTICE product README.md stages stage.sh templates 生成了stages目录，里面存放配置模板文件 # cd stages/ # ls 4.7.1 # cd 4.7.1/ # ls templates # cd templates/ # ls data kubernetes play-docker-compose.sh play-docker.sh play-kubernetes.sh ssl docker-compose play-consumer.sh play-docker-dledger.sh play-docker-tls.sh play-producer.sh 1、单机 ./play-docker.sh alpine 2、docker-compose ./play-docker-compose.sh 3、kubernetes集群 ./play-kubernetes.sh 4、Cluster of Dledger storage(RocketMQ需要4.4.0版本以上) ./play-docker-dledger.sh 5、TLS ./play-docker-tls.sh ./play-producer.sh ./play-consumer.sh 我这里选择的是单机部署，可以看到生成了两个容器 # docker ps |grep mq 5b557ea1e6be apacherocketmq/rocketmq:4.7.1-alpine \"sh mqbroker\" 25 seconds ago Up 24 seconds 0.0.0.0:10909-\u003e10909/tcp, 9876/tcp, 0.0.0.0:10911-10912-\u003e10911-10912/tcp rmqbroker 8b1318aee5d6 apacherocketmq/rocketmq:4.7.1-alpine \"sh mqnamesrv\" 26 seconds ago Up 25 seconds 10909/tcp, 0.0.0.0:9876-\u003e9876/tcp, 10911-10912/tcp rmqnamesrv 验证RocketMQ启动成功 1、使用命令 docker ps|grep rmqbroker 找到RocketMQ broker的容器id 2、使用命令 docker exec -it 5b557ea1e6be ./mqadmin clusterList -n {nameserver_ip}:9876 验证RocketMQ broker工作正常 # docker exec -it 5b557ea1e6be ./mqadmin clusterList -n {nameserver_ip}:9876 RocketMQLog:WARN No appenders could be found for logger (io.netty.util.internal.PlatformDependent0). RocketMQLog:WARN Please initialize the logger system properly. #Cluster Name #Broker Name #BID #Addr #Version #InTPS(LOAD) #OutTPS(LOAD) #PCWait(ms) #Hour #SPACE DefaultCluster 5b557ea1e6be 0 172.17.0.8:10911 V4_7_1 0.00(0,0ms) 0.00(0,0ms) 0 447225.46 -1.0000 ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:2:2","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"升级 cd image-build ./update.sh ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:2:3","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"安装GUI # docker pull apacherocketmq/rocketmq-console:2.0.0 # docker run -e \"JAVA_OPTS=-Drocketmq.namesrv.addr=192.168.150.70:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false\" -p 6881:8080 -t apacherocketmq/rocketmq-console:2.0.0 ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:3:0","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"golang client使用问题 由于使用的docker服务启动，broker的地址是内网地址，需要将地址修改为外网地址 # docker ps |grep mq 8abb966542a3 apacherocketmq/rocketmq-console:2.0.0 \"sh -c 'java $JAVA...\" 17 hours ago Up 17 hours 0.0.0.0:6881-\u003e8080/tcp dazzling_tesla 5b557ea1e6be apacherocketmq/rocketmq:4.7.1-alpine \"sh mqbroker\" 18 hours ago Up 18 hours 0.0.0.0:10909-\u003e10909/tcp, 9876/tcp, 0.0.0.0:10911-10912-\u003e10911-10912/tcp rmqbroker 8b1318aee5d6 apacherocketmq/rocketmq:4.7.1-alpine \"sh mqnamesrv\" 18 hours ago Up 18 hours 10909/tcp, 0.0.0.0:9876-\u003e9876/tcp, 10911-10912/tcp rmqnamesrv # docker exec -it 5b557ea1e6be bash // 进入到容器内部修改配置 # vi ../confbroker.conf 在文件中添加 brokerIP1=xxx.xxx.xxx.xxx 然后重启broker, docker restart 5b557ea1e6be ==这里需要去修改启动脚本 ./play-docker.sh 里的start_namesrv_broker() 函数中的docker启动命令，在mybroker后面添加-c ../conf/broker.conf== # Start Broker docker run -d -v `pwd`/data/broker/logs:/home/rocketmq/logs -v `pwd`/data/broker/store:/home/rocketmq/store --name rmqbroker --link rmqnamesrv:namesrv -e \"NAMESRV_ADDR=namesrv:9876\" -p 10909:10909 -p 10911:10911 -p 10912:10912 apacherocketmq/rocketmq:4.7.1${TAG_SUFFIX} sh mqbroker -c ../conf/broker.conf 这样查看cluster会发现Address变成外网地址。 ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:3:1","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"client-go Topic package main import ( \"context\" \"fmt\" \"github.com/apache/rocketmq-client-go/v2/admin\" \"github.com/apache/rocketmq-client-go/v2/primitive\" ) func main() { topic := \"Develop\" nameSrvAddr := []string{\"192.168.150.70:9876\"} brokerAddr := \"192.168.150.70:10911\" testAdmin, err := admin.NewAdmin(admin.WithResolver(primitive.NewPassthroughResolver(nameSrvAddr))) if err != nil { panic(err) } // 创建topic err = testAdmin.CreateTopic( context.Background(), admin.WithTopicCreate(topic), admin.WithBrokerAddrCreate(brokerAddr)) if err != nil { fmt.Println(\"Create topic error:\", err) } // 删除topic err = testAdmin.DeleteTopic( context.Background(), admin.WithTopicDelete(topic), //admin.WithBrokerAddrDelete(brokerAddr), //admin.WithNameSrvAddr(nameSrvAddr), ) err = testAdmin.Close() if err != nil { fmt.Println(\"Shutdown admin error:\", err) } } ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:3:2","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"client-go 生产者 package main import ( \"context\" \"fmt\" \"github.com/apache/rocketmq-client-go/v2\" \"github.com/apache/rocketmq-client-go/v2/primitive\" \"github.com/apache/rocketmq-client-go/v2/producer\" \"strconv\" ) func main() { addr,err := primitive.NewNamesrvAddr(\"192.168.150.70:9876\") if err != nil { panic(err) } topic := \"Develop\" p,err := rocketmq.NewProducer( producer.WithGroupName(\"my_service\"), producer.WithNameServer(addr), producer.WithCreateTopicKey(topic), producer.WithRetry(1)) if err != nil { panic(err) } err = p.Start() if err != nil { panic(err) } // 发送异步消息 res,err := p.SendSync(context.Background(),primitive.NewMessage(topic,[]byte(\"send sync message\"))) if err != nil { fmt.Printf(\"send sync message error:%s\\n\",err) } else { fmt.Printf(\"send sync message success. result=%s\\n\",res.String()) } // 发送消息后回调 err = p.SendAsync(context.Background(), func(ctx context.Context, result *primitive.SendResult, err error) { if err != nil { fmt.Printf(\"receive message error:%v\\n\",err) } else { fmt.Printf(\"send message success. result=%s\\n\",result.String()) } },primitive.NewMessage(topic,[]byte(\"send async message\"))) if err != nil { fmt.Printf(\"send async message error:%s\\n\",err) } // 批量发送消息 var msgs []*primitive.Message for i := 0; i \u003c 5; i++ { msgs = append(msgs, primitive.NewMessage(topic,[]byte(\"batch send message. num:\"+strconv.Itoa(i)))) } res,err = p.SendSync(context.Background(),msgs...) if err != nil { fmt.Printf(\"batch send sync message error:%s\\n\",err) } else { fmt.Printf(\"batch send sync message success. result=%s\\n\",res.String()) } // 发送延迟消息 msg := primitive.NewMessage(topic,[]byte(\"delay send message\")) msg.WithDelayTimeLevel(3) res,err = p.SendSync(context.Background(),msg) if err != nil { fmt.Printf(\"delay send sync message error:%s\\n\",err) } else { fmt.Printf(\"delay send sync message success. result=%s\\n\",res.String()) } // 发送带有tag的消息 msg1 := primitive.NewMessage(topic,[]byte(\"send tag message\")) msg1.WithTag(\"tagA\") res,err = p.SendSync(context.Background(),msg1) if err != nil { fmt.Printf(\"send tag sync message error:%s\\n\",err) } else { fmt.Printf(\"send tag sync message success. result=%s\\n\",res.String()) } err = p.Shutdown() if err != nil { panic(err) } } ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:3:3","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"client-go 消费者 // 在v2.1.0-rc5.0不支持，会在下一个版本中支持 func PullConsumer() { topic := \"Develop\" // 消费者主动拉取消息 // not c1,err := rocketmq.NewPullConsumer( consumer.WithGroupName(\"my_service\"), consumer.WithNsResolver(primitive.NewPassthroughResolver([]string{\"192.168.150.70:9876\"}))) if err != nil { panic(err) } err = c1.Start() if err != nil { fmt.Println(err) os.Exit(-1) } queue := primitive.MessageQueue{ Topic: topic, BrokerName: \"broker-a\", // 使用broker的名称 QueueId: 0, } err = c1.Shutdown() if err != nil { fmt.Println(\"Shutdown Pull Consumer error: \",err) } offset := int64(0) for { resp,err := c1.PullFrom(context.Background(),queue,offset,10) if err != nil { if err == rocketmq.ErrRequestTimeout { fmt.Printf(\"timeout\\n\") time.Sleep(time.Second) continue } fmt.Printf(\"unexpected error: %v\\n\",err) return } if resp.Status == primitive.PullFound { fmt.Printf(\"pull message success. nextOffset: %d\\n\",resp.NextBeginOffset) for _, ext := range resp.GetMessageExts() { fmt.Printf(\"pull msg: %s\\n\",ext) } } offset = resp.NextBeginOffset } } func PushConsumer() { topic := \"Develop\" // 消息主动推送给消费者 c2,err := rocketmq.NewPushConsumer( consumer.WithGroupName(\"my_service\"), consumer.WithNsResolver(primitive.NewPassthroughResolver([]string{\"192.168.150.70:9876\"})), consumer.WithConsumeFromWhere(consumer.ConsumeFromFirstOffset), // 选择消费时间(首次/当前/根据时间) consumer.WithConsumerModel(consumer.BroadCasting)) // 消费模式(集群消费:消费完其他人不能再读取/广播消费：所有人都能读) if err != nil { panic(err) } err = c2.Subscribe( topic,consumer.MessageSelector{ Type: consumer.TAG, Expression: \"*\", // 可以 TagA || TagB }, func(ctx context.Context, msgs ...*primitive.MessageExt) (consumer.ConsumeResult, error) { orderlyCtx,_ := primitive.GetOrderlyCtx(ctx) fmt.Printf(\"orderly context: %v\\n\",orderlyCtx) for i := range msgs { fmt.Printf(\"Subscribe callback: %v\\n\",msgs[i]) } return consumer.ConsumeSuccess,nil }) if err != nil { fmt.Printf(\"Subscribe error:%s\\n\",err) } err = c2.Start() if err != nil { fmt.Println(err) os.Exit(-1) } time.Sleep(time.Minute) err = c2.Shutdown() if err != nil { fmt.Println(\"Shutdown Consumer error: \",err) } } ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:3:4","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小笔记"],"content":"一 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:1:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"有20瓶药丸，其中19瓶装有1克/粒的药丸，余下一瓶装有1.1克/粒的药丸。给你一台称重精准的天平，怎么找出较重的那瓶药丸？天平只能使用一次。 初次看到这题，如果不限制次数，那么可以二分法，天平两边10个比较，直到找到较重的为止。 但是，现在限制只能使用一次天平。 怎么办呢？ 假设只有两瓶药丸，一瓶较重，从两瓶中各取一粒，称重为2.1克，我们无法得知是从哪一瓶多出的0.1克。 我们需要将因子不平衡，如果从1号药瓶取出1粒，从2号药瓶取出2粒，如果算出重量是3.1克，那么1号瓶较重，如果算出重量为3.2克，那么2号瓶较重。 我们将这个结论推广一下，从1号药瓶取出1粒，从2号药瓶取出2粒，以此类推，如果每粒药丸均重1克，那么得到总重量为（1+2+3+…+20=21*20/2=210）, 因此，如果称重为210.9克，那么较重的那瓶来自于9号瓶。 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:2:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"二 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:3:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"有个8*8的棋盘，其中对角的角落有两个方块被切掉了。给定31块多米诺骨牌，一块骨牌恰好可以覆盖两个格子。用31块骨牌能否盖住整个棋盘呢？ 乍一看，棋盘88=64，多米诺312=62，刚好能盖住。。其实是错觉 假设棋盘有32个黑格和32个白格交叉排列，切掉对角的方格是同种颜色的，此时只剩30个黑格和32个白格（或32个黑格和30个白格）， 而一块多米诺骨牌必须要覆盖一个白格和一个黑格，31块多米诺骨牌要覆盖31个白格和31个黑格。 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:4:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"三 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:5:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"有两个水壶，容量为5升和3升，若水量不限量，怎么用这两个水壶得到4升的水？注：水壶不规则形状，无法精确装满半壶水。 5升 3升 注释 5 0 装满5升的壶 2 3 用5升的壶装满3升的壶 0 2 将5升壶中的2升水倒入3升壶中 5 2 装满5升壶 4 3 用5升壶装满3升壶 5升 3升 注释 0 3 装满3升壶 3 3 将3升壶倒入5升壶中，同时装满3升壶 5 1 将3升壶倒入5升壶中 1 0 将3升壶中的1升水倒入5升壶中 1 3 装满3升壶 4 0 将3升壶倒入5升壶中 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:6:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"四 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:7:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"在岛上住着一群人，有一天来了一个游客，定了奇怪的规矩：所有的蓝眼睛必须尽快离开岛。 每个人都能看到别人眼睛的颜色，但不知道自己眼睛的颜色（别人不能告知）， 此外他们不知道有多少个蓝眼睛，只知道至少有一个蓝眼睛，每个人都是聪明的，那么蓝眼睛要花几天才能离开这个岛呢？ 假设有c个蓝眼睛，且c\u003e0 1、c=1：只有一个蓝眼睛 蓝眼睛的人观察之后发现没有蓝眼睛，那么一定能推导出自己是蓝眼睛，因此他会当天离开 2、c=2：两个蓝眼睛 两个蓝眼睛看到对方，不确定c=1或2，但是由于上种情况，他们知道c=1时，蓝眼睛当天会离开，如果第二天发现对方没有离开，那么一定能推导出自己也是蓝眼睛，于是，两个蓝眼睛会在第二天离开 3、c\u003e2 如果c=3，这三个人会意识到有2-3个人是蓝眼睛，如果2人蓝眼睛，会在第二天全部离开，因此，如果第二天另外两个人都在岛上，每个人都能推导出自己是蓝眼睛，于是会在第三天离开。 当逐步提高c时，发现这个逻辑是适用的。 如果有c人蓝眼睛，则所有的蓝眼睛要用c天离开这个岛 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:8:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"五 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:9:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"有个建筑高100米。若从第N层或更高的楼层扔鸡蛋，鸡蛋会破，若从N层以下的楼层扔下来不会破。 恰好你有两个鸡蛋，求出N，并要求最差情况下扔鸡蛋次数最少。 我们发现，无论我们怎么扔鸡蛋，第二个鸡蛋都必须在破掉的那一层和没有破掉的那一层逐层累加。 例如，鸡蛋1在5层没破，10层没破，15层破了，那么鸡蛋2必须从11,12,13,14尝试 具体做法 假设步长为10 鸡蛋1从10层扔下，如果破掉了，最多需要扔10次 鸡蛋1从100层扔下才破掉，最多需要扔19次。 那么我们的目的就是求这个步长，使得最好情况和最差情况类似。 也就是说，鸡蛋1每扔一次，就要减少鸡蛋2扔的次数。 例如，鸡蛋1从20层扔，然后从30层扔，鸡蛋2可能要扔9次， 若鸡蛋1再扔一次，我们要让鸡蛋2扔的次数减少，也就是说鸡蛋1要从39层开始扔。 因此 x + （x-1） + （x-2） +… + 1 = x(x+1)/2=100 -\u003e x=14 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:10:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"六 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:11:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"走廊上有100个关上的储物柜。 第一轮，将100柜子全部打开； 第二轮，每数两个柜子关上一个； 第三轮，每隔两个柜子切换柜子状态（就是将关上的柜子打开，打开的柜子关上）； 照此规律，重复100次，当结束时，有多少个柜子是打开的？ 柜子n会在每隔因子对应的那一轮切换状态，例如15的因子有1,3,5,15,因子个数为偶数，所以柜子15是关着的 那么什么样的整数因子的个数是奇数？ 我们可以将因子配对，15的因子有(1,15),(3,5)。 那么36的因子有(1,36),(2,18),(3,12),(4,9),(6,6),注意(6,6)其实是一个因子,36有奇数个因子 结论:如果是完全平方数会有奇数个因子，100以内的完全平方数有 1,4,9,16,25,36,49,64,81,100.共10个 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:12:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的GO"],"content":"介绍一下Golang channel的内部实现，包括channel的数据结构及相关操作的代码实现。 ","date":"2020-12-09","objectID":"/2020/12/chan/:0:0","tags":["golang","源码分析","channel"],"title":"常见的数据结构--chan","uri":"/2020/12/chan/"},{"categories":["月霜天的GO"],"content":"数据结构 type hchan struct { qcount uint // 队列中数据的个数 dataqsiz uint // 队列大小 buf unsafe.Pointer // 存放数据的环形数组 elemsize uint16 // channel中数据类型的大小 closed uint32 // channel是否关闭 elemtype *_type // 元素数据类型 sendx uint // send的数组索引 recvx uint // receive的数组索引 recvq waitq // \u003c-ch 阻塞在channel上的队列 sendq waitq // ch\u003c- 阻塞在channel上的队列 lock mutex } ","date":"2020-12-09","objectID":"/2020/12/chan/:1:0","tags":["golang","源码分析","channel"],"title":"常见的数据结构--chan","uri":"/2020/12/chan/"},{"categories":["月霜天的GO"],"content":"新建 func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. if elem.size \u003e= 1\u003c\u003c16 { throw(\"makechan: invalid channel element type\") } if hchanSize%maxAlign != 0 || elem.align \u003e maxAlign { throw(\"makechan: bad alignment\") } // 计算 size * elemSize，如果溢出或超过可分配内存，报错 mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u003e maxAlloc-hchanSize || size \u003c 0 { panic(plainError(\"makechan: size out of range\")) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG's are referenced from their owning thread so they can't be collected. var c *hchan switch { case mem == 0: // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = c.raceaddr() case elem.ptrdata == 0: // 元素不包含指针，预留元素缓存buf空间 c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // 元素包含指针 c = new(hchan) c.buf = mallocgc(mem, elem, true) } c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) if debugChan { print(\"makechan: chan=\", c, \"; elemsize=\", elem.size, \"; dataqsiz=\", size, \"\\n\") } return c } 总结一下，make chan的过程是在堆上进行分配，返回hchan的指针 ","date":"2020-12-09","objectID":"/2020/12/chan/:2:0","tags":["golang","源码分析","channel"],"title":"常见的数据结构--chan","uri":"/2020/12/chan/"},{"categories":["月霜天的GO"],"content":"send send是 ch\u003c-x。 func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { if c == nil { // 不能向一个nil的channel写数据 if !block { return false } // 阻塞当前g，将g和m脱离 gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\"unreachable\") } if debugChan { print(\"chansend: chan=\", c, \"\\n\") } if raceenabled { racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) } if !block \u0026\u0026 c.closed == 0 \u0026\u0026 ((c.dataqsiz == 0 \u0026\u0026 c.recvq.first == nil) || (c.dataqsiz \u003e 0 \u0026\u0026 c.qcount == c.dataqsiz)) { return false } var t0 int64 if blockprofilerate \u003e 0 { t0 = cputicks() } // 加锁 lock(\u0026c.lock) // 不能给已关闭的channel发送数据 if c.closed != 0 { unlock(\u0026c.lock) panic(plainError(\"send on closed channel\")) } if sg := c.recvq.dequeue(); sg != nil { // 如果有的话找到一个等待的receiver，直接把值传递给receiver，而绕过缓冲区 send(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true } // 如果通道缓冲区有位置，把发送的数据入队 if c.qcount \u003c c.dataqsiz { // 计算应插入buf的位置 qp := chanbuf(c, c.sendx) if raceenabled { raceacquire(qp) racerelease(qp) } // 值拷贝 typedmemmove(c.elemtype, qp, ep) c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } // 记录循环数组总个数 c.qcount++ unlock(\u0026c.lock) return true } if !block { unlock(\u0026c.lock) return false } // 阻塞channel，直到有可用的receiver gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil c.sendq.enqueue(mysg) gopark(chanparkcommit, unsafe.Pointer(\u0026c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren't considered as roots of the // stack tracer. KeepAlive(ep) // someone woke us up. if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil gp.activeStackChans = false if gp.param == nil { if c.closed == 0 { throw(\"chansend: spurious wakeup\") } panic(plainError(\"send on closed channel\")) } gp.param = nil if mysg.releasetime \u003e 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) return true } 流程： 如果有goroutine阻塞在channel上，此时hchan.buf 为空，直接将数据发送给goroutine 当前hchan.buf还有可用空间，将数据放到buffer里 如果hchan.buf已满，阻塞当前goroutine ","date":"2020-12-09","objectID":"/2020/12/chan/:3:0","tags":["golang","源码分析","channel"],"title":"常见的数据结构--chan","uri":"/2020/12/chan/"},{"categories":["月霜天的GO"],"content":"receive recv是 x\u003c-ch func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // nil channel if c == nil { if !block { return } gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\"unreachable\") } if !block \u0026\u0026 (c.dataqsiz == 0 \u0026\u0026 c.sendq.first == nil || c.dataqsiz \u003e 0 \u0026\u0026 atomic.Loaduint(\u0026c.qcount) == 0) \u0026\u0026 atomic.Load(\u0026c.closed) == 0 { return } var t0 int64 if blockprofilerate \u003e 0 { t0 = cputicks() } lock(\u0026c.lock) // 从关闭的channel中读取数据，如果channel还有数据，继续流程，如果没有数据，返回零值，如果有ok的话，ok=false if c.closed != 0 \u0026\u0026 c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } unlock(\u0026c.lock) if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } // 有发送的goroutine阻塞在channel上，如果缓冲区大小为0，直接发送放接收值，否则从队列头接受并将发送方的值添加到队列尾（因为两个值都映射到相同缓冲区，队列已满） if sg := c.sendq.dequeue(); sg != nil { recv(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true, true } // buf中有可用数据 if c.qcount \u003e 0 { // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled { raceacquire(qp) racerelease(qp) } if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(\u0026c.lock) return true, true } if !block { unlock(\u0026c.lock) return false, false } // buf为空，阻塞 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) gopark(chanparkcommit, unsafe.Pointer(\u0026c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // someone woke us up if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime \u003e 0 { blockevent(mysg.releasetime-t0, 2) } closed := gp.param == nil gp.param = nil mysg.c = nil releaseSudog(mysg) return true, !closed } ","date":"2020-12-09","objectID":"/2020/12/chan/:4:0","tags":["golang","源码分析","channel"],"title":"常见的数据结构--chan","uri":"/2020/12/chan/"},{"categories":["月霜天的GO"],"content":"close func closechan(c *hchan) { if c == nil { panic(plainError(\"close of nil channel\")) } lock(\u0026c.lock) if c.closed != 0 { unlock(\u0026c.lock) panic(plainError(\"close of closed channel\")) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) } c.closed = 1 var glist gList // release all readers for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // release all writers (they will panic) for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(\u0026c.lock) // Ready all Gs now that we've dropped the channel lock. for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } ","date":"2020-12-09","objectID":"/2020/12/chan/:5:0","tags":["golang","源码分析","channel"],"title":"常见的数据结构--chan","uri":"/2020/12/chan/"},{"categories":["月霜天的GO"],"content":"select func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) { return chansend(c, elem, false, getcallerpc()) } func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected bool) { selected, _ = chanrecv(c, elem, false) return } ","date":"2020-12-09","objectID":"/2020/12/chan/:6:0","tags":["golang","源码分析","channel"],"title":"常见的数据结构--chan","uri":"/2020/12/chan/"},{"categories":["月霜天的GO"],"content":"channel的ring buffer实现 channel中使用了ring buffer（环形缓冲区）来缓存写入的数据，适合实现FIFO的固定长度队列。 hchan中有两个与buffer相关的变量：recvx和sendx。 其中sendx表示buffer中可写的index，recvx表示buffer中可读的index。 从recvx到sendx之间的元素，表示已正常放入buffer中的数据。 ","date":"2020-12-09","objectID":"/2020/12/chan/:7:0","tags":["golang","源码分析","channel"],"title":"常见的数据结构--chan","uri":"/2020/12/chan/"},{"categories":["月霜天的GO"],"content":"很多的业务场景都会用到map，在其他语言可能成为set/集合等，主要就是key:value格式。 // A map is just a hash table. The data is arranged // into an array of buckets. Each bucket contains up to // 8 key/elem pairs. The low-order bits of the hash are // used to select a bucket. Each bucket contains a few // high-order bits of each hash to distinguish the entries // within a single bucket. // // If more than 8 keys hash to a bucket, we chain on // extra buckets. // // When the hashtable grows, we allocate a new array // of buckets twice as big. Buckets are incrementally // copied from the old bucket array to the new bucket array. map内部实现是一个哈希表，内部维护了一个buckets数组，每个buckets最多包含8个键值对， 每个key的哈希值的低位是buckets的索引，高位用来区分。 如果超过8个元素，变会使用额外的buckets链接。 当哈希表扩容时，会分配一个比当前大两倍的空间，旧buckets里的数据会递增地拷贝到新buckets中。 ","date":"2020-12-07","objectID":"/2020/12/map/:0:0","tags":["golang","源码分析","map"],"title":"常见的数据结构--map","uri":"/2020/12/map/"},{"categories":["月霜天的GO"],"content":"内部数据结构 type hmap struct { count int // 当前大小 flags uint8 B uint8 // 能容纳 2^B buckets noverflow uint16 // 溢出 buckets 的数量 hash0 uint32 // hash seed buckets unsafe.Pointer // 2^B Buckets 数组指针. may be nil if count==0. oldbuckets unsafe.Pointer // 扩容时的buckets数组 nevacuate uintptr // rehash 的进度 extra *mapextra // optional fields } map底层维护了一个hmap的结构，hmap维护了一个buckets数组，buckets数组的元素是一个bmap结构，真正的数据放到bmap中。 type bmap struct { // tophash generally contains the top byte of the hash value // for each key in this bucket. If tophash[0] \u003c minTopHash, // tophash[0] is a bucket evacuation state instead. tophash [bucketCnt]uint8 // bucketCnt = 8 } bmap是一个长度为8的数组，map的key经过hash会放到bmap中，bmap只存hash value的top byte，uint8表示hash value的高8位， 这样的好处是每次查找key时不要比较key的每个字符，从而增加查找效率。 ","date":"2020-12-07","objectID":"/2020/12/map/:1:0","tags":["golang","源码分析","map"],"title":"常见的数据结构--map","uri":"/2020/12/map/"},{"categories":["月霜天的GO"],"content":"创建map func makemap(t *maptype, hint int, h *hmap) *hmap { mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u003e maxAlloc { hint = 0 } // initialize Hmap if h == nil { h = new(hmap) } // 随机种子，使得每个key在不同的map中生成的哈希值不同 h.hash0 = fastrand() // 找到合适的B使得map的装载因子在正常范围内 B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // 初始化 hash table // 如果 B == 0, buckets 会在赋值后分配 // 如果长度比较大，分配内存的时间会变长 if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 过程： 创建hmap，并初始化 获取一个随机种子，保证同一个key在不同map中的哈希值不同（安全考量） 计算初始桶的大小 如果初始桶大小不为0，则创建桶，有必要还需创建溢出桶结构 ","date":"2020-12-07","objectID":"/2020/12/map/:2:0","tags":["golang","源码分析","map"],"title":"常见的数据结构--map","uri":"/2020/12/map/"},{"categories":["月霜天的GO"],"content":"查找map func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { if raceenabled \u0026\u0026 h != nil { callerpc := getcallerpc() pc := funcPC(mapaccess1) racereadpc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled \u0026\u0026 h != nil { msanread(key, t.key.size) } // 如果空值，返回value类型的零值 if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return unsafe.Pointer(\u0026zeroVal[0]) } // 并发读写冲突 if h.flags\u0026hashWriting != 0 { throw(\"concurrent map read and map write\") } // 计算hash值 hash := t.hasher(key, uintptr(h.hash0)) // 计算B的掩码，1\u003c\u003cB-1 m := bucketMask(h.B) // b是当前key对应的bucket的地址 b := (*bmap)(add(h.buckets, (hash\u0026m)*uintptr(t.bucketsize))) // oldbuckets不为nil，发生扩容 if c := h.oldbuckets; c != nil { if !h.sameSizeGrow() { // There used to be half as many buckets; mask down one more power of two. m \u003e\u003e= 1 } // 求出key在老map中的buckets的位置 oldb := (*bmap)(add(c, (hash\u0026m)*uintptr(t.bucketsize))) if !evacuated(oldb) { b = oldb } } // 计算高8位 top := tophash(hash) // 进入bucket的二层循环找到对应的键值对 bucketloop: // 遍历bucket及overflow链表 for ; b != nil; b = b.overflow(t) { // 遍历bucket的8个slot for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { // tophash不匹配 // 标识当前bucket剩下的slot都是empty if b.tophash[i] == emptyRest { break bucketloop } continue } // 获取bucket的key k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if t.key.equal(key, k) { // 定位到value的位置 e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } return e } } } return unsafe.Pointer(\u0026zeroVal[0]) } 过程： 读写检查 计算key的哈希值，并根据哈希值计算key所在桶的位置 计算tophash值，便于快速查找 遍历桶链上的每个桶，并依次遍历桶内元素 先比较tophash，如果tophash不同，比较下一个，如果相同，再比较key值是否相等 如果key相等，计算value的地址，并去除value，直接返回 若key不等，比较下一个元素，如果都不匹配，返回零值 假设B=5，桶的数量2^5=32. 10010111 | 000011110110110010001111001010100010010110010101010 │ 01010 用最后的5位01010作为桶的编号，然后用哈希值的高8位找到key在bucket的位置。 最开始桶内没有key，新加入的key会找到第一个空位，放入。 当两个不同的key落入同一个bucket中，发生了哈希冲突，在bucket从前向后找到第一个空位。 这样在查到某个key时，先找到对应的桶，再去遍历bucket里的值 ","date":"2020-12-07","objectID":"/2020/12/map/:3:0","tags":["golang","源码分析","map"],"title":"常见的数据结构--map","uri":"/2020/12/map/"},{"categories":["月霜天的GO"],"content":"扩容 扩容条件: 当map中内存数据/bucket数量\u003e6.5,变会触发扩容 // Maximum average load of a bucket that triggers growth is 6.5. // Represent as loadFactorNum/loadFactDen, to allow integer math. loadFactorNum = 13 loadFactorDen = 2 // 扩容条件 func overLoadFactor(count int, B uint8) bool { return count \u003e bucketCnt \u0026\u0026 uintptr(count) \u003e loadFactorNum*(bucketShift(B)/loadFactorDen) } // 扩容操作 func hashGrow(t *maptype, h *hmap) { bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } // commit the grow (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } } 过程：扩容会分配一个当前2倍大的空间，并将之前的buckets置位到现在的oldBuckets。 但分配完的数据并不会马上复制到buckets，而通过惰性加载的方式，当访问到的时候才会进行。 注意：扩容的时候B*2，所计算key的哈希值时看低B+1位，所以桶的序号会发生变化，称为 搬迁rehash ","date":"2020-12-07","objectID":"/2020/12/map/:4:0","tags":["golang","源码分析","map"],"title":"常见的数据结构--map","uri":"/2020/12/map/"},{"categories":["月霜天的GO"],"content":"搬迁 // 搬迁操作 func growWork(t *maptype, h *hmap, bucket uintptr) { // 确认搬迁老的bucket对应正在使用的bucket evacuate(t, h, bucket\u0026h.oldbucketmask()) // 再搬迁一个bucket if h.growing() { evacuate(t, h, h.nevacuate) } } // oldbuckets不为空，没有搬迁完 func (h *hmap) growing() bool { return h.oldbuckets != nil } func evacuate(t *maptype, h *hmap, oldbucket uintptr) { // oldbucket的地址 b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() if !evacuated(b) { // xy表示2倍扩容时对应的前半部分和后半部分 var xy [2]evacDst x := \u0026xy[0] // 默认等size扩容，前后的bucket序号不变 x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) if !h.sameSizeGrow() { // 如果不是等size扩容，前后的bucket序号变化，使用y来搬迁 y := \u0026xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } // 遍历所有的bucket，包括overflow buckets，b是oldbucket地址 for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) for i := 0; i \u003c bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { // 当前cell的top hash值 top := b.tophash[i] // 如果cell为空，即没有key if isEmpty(top) { b.tophash[i] = evacuatedEmpty continue } if top \u003c minTopHash { throw(\"bad map state\") } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 if !h.sameSizeGrow() { // Compute hash to make our evacuation decision (whether we need // to send this key/elem to bucket x or bucket y). hash := t.hasher(k2, uintptr(h.hash0)) // 如果有协程正在遍历map且出现相同的key，算出来的hash值可能不同 if h.flags\u0026iterator != 0 \u0026\u0026 !t.reflexivekey() \u0026\u0026 !t.key.equal(k2, k2) { useY = top \u0026 1 top = tophash(hash) } else { if hash\u0026newbit != 0 { useY = 1 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\"bad evacuatedN\") } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY dst := \u0026xy[useY] // evacuation destination if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check // 执行复制操作 if t.indirectkey() { *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.key, dst.k, k) // copy elem } if t.indirectelem() { *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.elem, dst.e, e) } // 定位到下一个cell dst.i++ dst.k = add(dst.k, uintptr(t.keysize)) dst.e = add(dst.e, uintptr(t.elemsize)) } } // 如果没有协程使用oldbuckets，就清除老的oldbuckets，帮助gc if h.flags\u0026oldIterator == 0 \u0026\u0026 t.bucket.ptrdata != 0 { b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)) // Preserve b.tophash because the evacuation // state is maintained there. ptr := add(b, dataOffset) n := uintptr(t.bucketsize) - dataOffset memclrHasPointers(ptr, n) } } if oldbucket == h.nevacuate { advanceEvacuationMark(h, t, newbit) } } 为什么遍历map是无序的？ map发生扩容后，会发生key的搬迁，原来落到同一个bucket中的key中，搬迁后有些key值的序号发生变化。 而遍历的过程，是按顺序遍历bucket，同时顺序遍历bucket中的key。搬迁后，有的key位置发生了变化，遍历map就不可能按照原来的顺序了。 同时，每次遍历时，并不是固定的从0号bucket开始，而是随机序号的bucket开始遍历，并且是随机一个序号的cell开始。 1个bucket有两个key的哈希低3位为010,110.原来的B=2，所以他们落在2号桶，现在B=3,010落在2号桶，110落在6号桶。 ","date":"2020-12-07","objectID":"/2020/12/map/:5:0","tags":["golang","源码分析","map"],"title":"常见的数据结构--map","uri":"/2020/12/map/"},{"categories":["月霜天的GO"],"content":"插入数据 func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { if h == nil { panic(plainError(\"assignment to entry in nil map\")) } if raceenabled { callerpc := getcallerpc() pc := funcPC(mapassign) racewritepc(unsafe.Pointer(h), callerpc, pc) raceReadObjectPC(t.key, key, callerpc, pc) } if msanenabled { msanread(key, t.key.size) } if h.flags\u0026hashWriting != 0 { // 检测是否竞态读写 throw(\"concurrent map writes\") } // 计算key的哈希值 hash := t.hasher(key, uintptr(h.hash0)) // 置标记位，表示正在写操作 h.flags ^= hashWriting if h.buckets == nil { h.buckets = newobject(t.bucket) // newarray(t.bucket, 1) } again: // 触发rehash，重试 bucket := hash \u0026 bucketMask(h.B) if h.growing() { growWork(t, h, bucket) } b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize))) top := tophash(hash) var inserti *uint8 var insertk unsafe.Pointer var elem unsafe.Pointer bucketloop: for { for i := uintptr(0); i \u003c bucketCnt; i++ { // 遍历单个bucket if b.tophash[i] != top { if isEmpty(b.tophash[i]) \u0026\u0026 inserti == nil { // 找到空位，插入数据 inserti = \u0026b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) } if b.tophash[i] == emptyRest { break bucketloop } continue } // k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if !t.key.equal(key, k) { continue } // 找到相同的key，覆盖value if t.needkeyupdate() { typedmemmove(t.key, k, key) } elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) goto done } ovf := b.overflow(t) if ovf == nil { break } b = ovf } // 如果增加元素触发扩容，重复 if !h.growing() \u0026\u0026 (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } if inserti == nil { // 如果所有的buckets满了，重新分配 newb := h.newoverflow(t, b) inserti = \u0026newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) elem = add(insertk, bucketCnt*uintptr(t.keysize)) } // store new key/elem at insert position if t.indirectkey() { kmem := newobject(t.key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem } if t.indirectelem() { vmem := newobject(t.elem) *(*unsafe.Pointer)(elem) = vmem } typedmemmove(t.key, insertk, key) *inserti = top h.count++ done: if h.flags\u0026hashWriting == 0 { throw(\"concurrent map writes\") } h.flags \u0026^= hashWriting if t.indirectelem() { elem = *((*unsafe.Pointer)(elem)) } return elem } 过程： 并发读写检查 设置写标识 计算key的哈希值 如果哈希桶是空的，则创建哈希桶，大小为1 计算桶链首地址和tophash 找到桶链下的所有桶的元素，看key是否存在，如果存在，直接把value写入对应位置 在查找过程中，会记录下桶里面第一个空元素的位置 如果没有空位置，申请一个溢出桶，并把溢出桶挂载该桶链下 把k/v插入空余位置 map元素总数+1 清除写标识 ","date":"2020-12-07","objectID":"/2020/12/map/:6:0","tags":["golang","源码分析","map"],"title":"常见的数据结构--map","uri":"/2020/12/map/"},{"categories":["月霜天的GO"],"content":"删除元素 func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) { if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return } if h.flags\u0026hashWriting != 0 { // 检测是否竞态读写 throw(\"concurrent map writes\") } // key的哈希值 hash := t.hasher(key, uintptr(h.hash0)) // 置位写操作 h.flags ^= hashWriting bucket := hash \u0026 bucketMask(h.B) if h.growing() { growWork(t, h, bucket) } // 类似于start+index*bucketLen，获取头结点指针 b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize))) bOrig := b top := tophash(hash) search: // 外层循环buckets和溢出buckets for ; b != nil; b = b.overflow(t) { // 内层循环bucket for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { // 如果当前tophash是emptyRest表明所有当前bucket里的tophash都是空切溢出bucket也是空 if b.tophash[i] == emptyRest { break search } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } if !t.key.equal(key, k2) { continue } // 如果key是指针类型，只把指针置为nil if t.indirectkey() { *(*unsafe.Pointer)(k) = nil } else if t.key.ptrdata != 0 { // 非指针key，清除数据 memclrHasPointers(k, t.key.size) } e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { *(*unsafe.Pointer)(e) = nil } else if t.elem.ptrdata != 0 { memclrHasPointers(e, t.elem.size) } else { memclrNoHeapPointers(e, t.elem.size) } b.tophash[i] = emptyOne // 如果当前bucket以多个emptyOne状态结尾，把emptyOne改成emptyRest // 如果在当前bucket的tophash最后一个位置 if i == bucketCnt-1 { // 当前bucket有溢出且溢出的bucket的tophash下标不是emptyRest if b.overflow(t) != nil \u0026\u0026 b.overflow(t).tophash[0] != emptyRest { goto notLast } } else { if b.tophash[i+1] != emptyRest { goto notLast } } // 把连续的emptyOne置为emptyRest for { b.tophash[i] = emptyRest if i == 0 { if b == bOrig { break // beginning of initial bucket, we're done. } // Find previous bucket, continue at its last entry. c := b for b = bOrig; b.overflow(t) != c; b = b.overflow(t) { } i = bucketCnt - 1 } else { i-- } if b.tophash[i] != emptyOne { break } } notLast: h.count-- break search } } if h.flags\u0026hashWriting == 0 { throw(\"concurrent map writes\") } h.flags \u0026^= hashWriting } 过程： 并发读写检查 设置写标识 计算key的哈希值 计算桶链首地址和tophash 找到桶链下所有桶元素，如果找到key，处理 map总元素-1 清除写标识 ","date":"2020-12-07","objectID":"/2020/12/map/:7:0","tags":["golang","源码分析","map"],"title":"常见的数据结构--map","uri":"/2020/12/map/"},{"categories":["月霜天的GO"],"content":"查找元素 查找有多个实现，对应 v:=m[k]; v,ok:=m[k]; k,v:=range m; k:=range m func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // 如果map为nil，返回零值 if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return unsafe.Pointer(\u0026zeroVal[0]) } if h.flags\u0026hashWriting != 0 { //检测竞态读写 throw(\"concurrent map read and map write\") } // key的哈希 hash := t.hasher(key, uintptr(h.hash0)) m := bucketMask(h.B) b := (*bmap)(add(h.buckets, (hash\u0026m)*uintptr(t.bucketsize))) if c := h.oldbuckets; c != nil { if !h.sameSizeGrow() { // There used to be half as many buckets; mask down one more power of two. m \u003e\u003e= 1 } oldb := (*bmap)(add(c, (hash\u0026m)*uintptr(t.bucketsize))) if !evacuated(oldb) { b = oldb } } top := tophash(hash) bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if t.key.equal(key, k) { e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } return e } } } return unsafe.Pointer(\u0026zeroVal[0]) } 如果oldbucket存在，会在oldbucket里寻找，如果已经搬迁了，就到新的bucket里查找。 通过阅读map的源码可以看到，如果同时对一个map进行读写操作，会panic，所以需要在用户层进行锁控制。 key经过哈希后，低位用来定位buckets，高位用来对bucket寻址，大大缩小了key的查找范围。 在搬迁过程中，oldbucket到newbucket是值拷贝的话开销会很大，如果是指针的话开销会减小。 ","date":"2020-12-07","objectID":"/2020/12/map/:8:0","tags":["golang","源码分析","map"],"title":"常见的数据结构--map","uri":"/2020/12/map/"},{"categories":["月霜天的GO"],"content":"在使用过程中，我们经常会用到数组这一数据结构，而在golang中，提供了数组和切片两种，数组是固定长度的且长度为定值，而切片是可以扩张的数组。 本章内容参考 runtime/slice.go ","date":"2020-12-07","objectID":"/2020/12/slice/:0:0","tags":["golang","源码分析","slice"],"title":"常见的数据结构--切片","uri":"/2020/12/slice/"},{"categories":["月霜天的GO"],"content":"内部数据结构 type slice struct { array unsafe.Pointer// 数据 len int // 长度 cap int // 容量 } 我们可以通过下面的代码输出slice： package main import ( \"fmt\" \"unsafe\" ) func main() { data := make([]int,0,3) fmt.Println(unsafe.Sizeof(data),len(data),cap(data)) // Output: 24,0,3 // 通过指针方式拿到切片内部的值 ptr := unsafe.Pointer(\u0026data) opt := (*[3]int)(ptr) fmt.Println(opt[0],opt[1],opt[2]) // Output: addr,0,3 data = append(data, 4) fmt.Println(unsafe.Sizeof(data)) // Output: 24 shallowCopy := data[:1] ptr1 := unsafe.Pointer(\u0026shallowCopy) opt1 := (*[3]int)(ptr1) fmt.Println(opt1[0]) // Output: addr } ","date":"2020-12-07","objectID":"/2020/12/slice/:1:0","tags":["golang","源码分析","slice"],"title":"常见的数据结构--切片","uri":"/2020/12/slice/"},{"categories":["月霜天的GO"],"content":"创建 创建一个slice，实质上是在分配内存。 func makeslice(et *_type, len, cap int) unsafe.Pointer { // 获取需要申请的内存大小 mem, overflow := math.MulUintptr(et.size, uintptr(cap)) if overflow || mem \u003e maxAlloc || len \u003c 0 || len \u003e cap { mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u003e maxAlloc || len \u003c 0 { panicmakeslicelen() // 超过内存限制|超过最大分配量|长度小于0 } panicmakeslicecap() // 长度大于容量 } // 分配内存 // runtime/malloc.go return mallocgc(mem, et, true) } ","date":"2020-12-07","objectID":"/2020/12/slice/:2:0","tags":["golang","源码分析","slice"],"title":"常见的数据结构--切片","uri":"/2020/12/slice/"},{"categories":["月霜天的GO"],"content":"扩容机制 golang中内置了copy函数，可以用来拷贝切片。 func growslice(et *_type, old slice, cap int) slice { // 静态分析 if raceenabled { callerpc := getcallerpc() racereadrangepc(old.array, uintptr(old.len*int(et.size)), callerpc, funcPC(growslice)) } if msanenabled { msanread(old.array, uintptr(old.len*int(et.size))) } if cap \u003c old.cap { panic(errorString(\"growslice: cap out of range\")) } // 如果新切片的长度为0，返回空数据，长度为旧切片的长度 if et.size == 0 { return slice{unsafe.Pointer(\u0026zerobase), old.len, cap} } newcap := old.cap doublecap := newcap + newcap if cap \u003e doublecap { // 如果容量大于原有容量的2倍，则按新增容量申请 newcap = cap } else { if old.len \u003c 1024 { // 如果原有容量小于1024，新容量是原有容量的2倍 newcap = doublecap } else { // 原有容量大于1024，按原有容量的1.25倍递增，直到满足需求 for 0 \u003c newcap \u0026\u0026 newcap \u003c cap { newcap += newcap / 4 } if newcap \u003c= 0 { // 校验容量是否溢出 newcap = cap } } } var overflow bool var lenmem, newlenmem, capmem uintptr // 为加速计算（不用乘除法） // 对于2的幂，使用变位处理 switch { case et.size == 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) \u003e maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) \u003e maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) case isPowerOfTwo(et.size): // 2的幂 var shift uintptr if sys.PtrSize == 8 { // Mask shift for better code generation. shift = uintptr(sys.Ctz64(uint64(et.size))) \u0026 63 } else { shift = uintptr(sys.Ctz32(uint32(et.size))) \u0026 31 } lenmem = uintptr(old.len) \u003c\u003c shift newlenmem = uintptr(cap) \u003c\u003c shift capmem = roundupsize(uintptr(newcap) \u003c\u003c shift) overflow = uintptr(newcap) \u003e (maxAlloc \u003e\u003e shift) newcap = int(capmem \u003e\u003e shift) default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) } // 判断是否会溢出 if overflow || capmem \u003e maxAlloc { panic(errorString(\"growslice: cap out of range\")) } // 内存分配 var p unsafe.Pointer if et.ptrdata == 0 { p = mallocgc(capmem, nil, false) // 回收内存 memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) } else { // Note: can't use rawmem (which avoids zeroing of memory), because then GC can scan uninitialized memory. p = mallocgc(capmem, et, true) if lenmem \u003e 0 \u0026\u0026 writeBarrier.enabled { // gc // Only shade the pointers in old.array since we know the destination slice p // only contains nil pointers because it has been cleared during alloc. bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(old.array), lenmem) } } // 数据拷贝 memmove(p, old.array, lenmem) return slice{p, old.len, newcap} } ","date":"2020-12-07","objectID":"/2020/12/slice/:3:0","tags":["golang","源码分析","slice"],"title":"常见的数据结构--切片","uri":"/2020/12/slice/"},{"categories":["月霜天的GO"],"content":"深拷贝 func slicecopy(to, fm slice, width uintptr) int { if fm.len == 0 || to.len == 0 { return 0 } n := fm.len if to.len \u003c n { n = to.len } // 元素长度为0，直接返回 if width == 0 { return n } // 竞态分析和内存扫描 if raceenabled { callerpc := getcallerpc() pc := funcPC(slicecopy) racewriterangepc(to.array, uintptr(n*int(width)), callerpc, pc) racereadrangepc(fm.array, uintptr(n*int(width)), callerpc, pc) } if msanenabled { msanwrite(to.array, uintptr(n*int(width))) msanread(fm.array, uintptr(n*int(width))) } size := uintptr(n) * width // 拷贝内存 if size == 1 { // common case worth about 2x to do here // TODO: is this still worth it with new memmove impl? *(*byte)(to.array) = *(*byte)(fm.array) // known to be a byte pointer } else { memmove(to.array, fm.array, size) } return n } // 字符串slice拷贝 func slicestringcopy(to []byte, fm string) int { if len(fm) == 0 || len(to) == 0 { return 0 } n := len(fm) if len(to) \u003c n { n = len(to) } if raceenabled { callerpc := getcallerpc() pc := funcPC(slicestringcopy) racewriterangepc(unsafe.Pointer(\u0026to[0]), uintptr(n), callerpc, pc) } if msanenabled { msanwrite(unsafe.Pointer(\u0026to[0]), uintptr(n)) } memmove(unsafe.Pointer(\u0026to[0]), stringStructOf(\u0026fm).str, uintptr(n)) return n } ","date":"2020-12-07","objectID":"/2020/12/slice/:3:1","tags":["golang","源码分析","slice"],"title":"常见的数据结构--切片","uri":"/2020/12/slice/"},{"categories":["月霜天的GO"],"content":"提到数据结构，第一个就是链表。通过一组任意的存储单元来存储线性表中的数据元素。 链表 链表：线性表的链式存储 最简单的链表如下： package main import \"fmt\" type LinkNode struct { data int next *LinkNode } func main() { // 第一个节点 node1 := new(LinkNode) node1.data = 1 // 第二个节点 node2 := new(LinkNode) node2.data = 2 node1.next = node2 // node2 链接到 node1 节点上 // 第三个节点 node3 := new(LinkNode) node3.data = 3 node2.next = node3 // node3 链接到 node2 节点上 // 按照顺序打印链表 newNode := node1 for newNode != nil { fmt.Println(newNode.data) newNode = newNode.next } // Output： // 1 // 2 // 3 } 结构体 LinkNode 有两个字段，一个是存放数据的data，另一个是指向下一个节点next。这种从一个节点指向下一个节点的结构，都称为链表。 然后链表又被分为以下几类： 单链表：链表是单向的，只有一个方向，不能往会找。元素离散的分布在存储空间中，所以单链表是非随机存取的存储结构。 双链表：仅仅是在单链表的节点中增加了一个指向其前驱的指针。 循环链表：表中最后一个节点的指向不是null，而改为指向头节点，从而整个链表形成一个环。 ","date":"2020-12-06","objectID":"/2020/12/list/:0:0","tags":["golang","数据结构"],"title":"常见的数据结构--链表","uri":"/2020/12/list/"},{"categories":["月霜天的GO"],"content":"实现循环链表 参考标准库 container/ring.go type Ring struct { next, prev *Ring // 前驱节点和后驱节点 Value interface{} // 数据 } 该结构有三个字段，next表示后驱节点，prev表示前驱节点，Value表示值。 ","date":"2020-12-06","objectID":"/2020/12/list/:1:0","tags":["golang","数据结构"],"title":"常见的数据结构--链表","uri":"/2020/12/list/"},{"categories":["月霜天的GO"],"content":"初始化循环链表 初始化一个空的循环链表： package main type Ring struct { next, prev *Ring // 前驱节点和后驱节点 Value interface{} // 数据 } // 初始化空的循环链表，前驱节点和后驱节点都指向自己 func (r *Ring) init() *Ring { r.next = r r.prev = r return r } func main() { r := new(Ring) r.init() } 因为绑定前驱节点和后驱节点为自己，没有循环，时间复杂度：O(1)。 创建一个指定大小N的循环链表，值为空： func New(n int) *Ring { if n \u003c= 0 { return nil } r := new(Ring) p := r for i := 1; i \u003c n; i++ { p.next = \u0026Ring{prev: p} p = p.next } p.next = r r.prev = p return r } 时间复杂度：O(n)。 ","date":"2020-12-06","objectID":"/2020/12/list/:1:1","tags":["golang","数据结构"],"title":"常见的数据结构--链表","uri":"/2020/12/list/"},{"categories":["月霜天的GO"],"content":"获取上一个或下一个节点 // 获取下一个节点 func (r *Ring) Next() *Ring { if r.next == nil { return r.init() } return r.next } // 获取上一个基点 func (r *Ring) Prev() *Ring { if r.next == nil { return r.init() } return r.prev } 时间复杂度：O(1)。 ","date":"2020-12-06","objectID":"/2020/12/list/:1:2","tags":["golang","数据结构"],"title":"常见的数据结构--链表","uri":"/2020/12/list/"},{"categories":["月霜天的GO"],"content":"获取第n个节点 因为链表是循环的，当n\u003c0向前遍历，n\u003e0向后遍历。 func (r *Ring) Move(n int) *Ring { if r.next == nil { return r.init() } switch { case n \u003c 0: for ; n \u003c 0; n++ { r = r.prev } case n \u003e 0: for ; n \u003e 0; n-- { r = r.next } } return r } 时间复杂度：O(n)。 ","date":"2020-12-06","objectID":"/2020/12/list/:1:3","tags":["golang","数据结构"],"title":"常见的数据结构--链表","uri":"/2020/12/list/"},{"categories":["月霜天的GO"],"content":"添加节点 // 往节点r链接一个新的节点，并返回节点r的后驱节点 func (r *Ring) Link(s *Ring) *Ring { n := r.Next() if s != nil { p := s.Prev() r.next = s s.prev = r n.prev = p p.next = n } return n } 假定s是一个新的节点，在r节点后插一个新的节点s，而r节点之前的后驱节点，将会链接到新节点后面，并返回r节点之前的第一个后驱节点n func main() { r := \u0026Ring{Value: 1} r.Link(\u0026Ring{Value: 2}) r.Link(\u0026Ring{Value: 3}) r.Link(\u0026Ring{Value: 4}) r.Link(\u0026Ring{Value: 5}) node := r for { fmt.Println(node.Value) node = node.Next() if node == r { return } } } // Output 1 5 4 3 2 时间复杂度O(1) ","date":"2020-12-06","objectID":"/2020/12/list/:1:4","tags":["golang","数据结构"],"title":"常见的数据结构--链表","uri":"/2020/12/list/"},{"categories":["月霜天的GO"],"content":"删除节点 func main() { r := \u0026Ring{Value: 1} r.Link(\u0026Ring{Value: 2}) r.Link(\u0026Ring{Value: 3}) r.Link(\u0026Ring{Value: 4}) r.Link(\u0026Ring{Value: 5}) r.Unlink(2) node := r for { fmt.Println(node.Value) node = node.Next() if node == r { return } } } // Output: 1 3 2 时间复杂度O(n)。 ","date":"2020-12-06","objectID":"/2020/12/list/:1:5","tags":["golang","数据结构"],"title":"常见的数据结构--链表","uri":"/2020/12/list/"},{"categories":["月霜天的GO"],"content":"链表长度 func (r *Ring) Len() int { n := 0 if r != nil { for p := r.Next(); p != r; p = p.next { n++ } } return n } 时间复杂度: O(n)。 ","date":"2020-12-06","objectID":"/2020/12/list/:1:6","tags":["golang","数据结构"],"title":"常见的数据结构--链表","uri":"/2020/12/list/"},{"categories":["月霜天的小教程"],"content":"安装材料 raspberry pi 4b 4G *1 128G 三星TF卡 *1 micro接口转HDMI转接线 *1 电源适配器 5V 3A *1 ","date":"2020-11-27","objectID":"/2020/11/install_os/:1:0","tags":["raspberry"],"title":"树莓派安装ubuntu系统","uri":"/2020/11/install_os/"},{"categories":["月霜天的小教程"],"content":"安装系统 ","date":"2020-11-27","objectID":"/2020/11/install_os/:2:0","tags":["raspberry"],"title":"树莓派安装ubuntu系统","uri":"/2020/11/install_os/"},{"categories":["月霜天的小教程"],"content":"1、下载 在windows上下载 raspberry pi imager 用来安装系统 由于我们已经在 已经下载好了 OS，所以我们直接烧录系统。 ","date":"2020-11-27","objectID":"/2020/11/install_os/:2:1","tags":["raspberry"],"title":"树莓派安装ubuntu系统","uri":"/2020/11/install_os/"},{"categories":["月霜天的小教程"],"content":"2、进入系统 输入账号密码，默认ubuntu：ubuntu，需要重新设置密码。 此时需要连接网线、显示器、键盘。 更新软件源，由于树莓派，使用ubuntu-ports，然后更新 # cp /etc/apt/sources.list /etc/apt/sources.list.bak # 然后替换软件源 # apt update 安装软件 # apt install net-tools wireless-tools wpasupplicant udhcpc 查看网卡 # iwconfig lo no wireless extensions. eth0 no wireless extensions. wlan0 no wireless extensions. 启动网卡 # ifconfig wlan0 up # ifconfig 此时就能看到网卡信息了。 配置wifi信息 # vi wpa_supplicant.conf country=GB ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 # wpa_passphrase wifi名称 wifi密码 \u003e\u003e wpa_supplicant.conf 此时再启动wpa_cli后台wpa_supplicant # wpa_supplicant -iwlan0 -c wpa_supplicant.conf -B 查看wifi连接状态 # wpa_cli -iwlan0 status 扫描可用wifi # wpa_cli -i wlan0 scan 查看扫描结果 # wpa_cli -i wlan0 scan_results 新增wifi编码 # wpa_cli -iwlan0 add_network 配置wifi名称 # wpa_cli -iwlan0 set network 编码 ssid \"wifi名称\" 配置wifi密码 # wpa_cli -iwlan0 set network 编码 psk \"wifi密码\" 查看wifi列表 # wpa_cli -iwlan0 list_network 选择wifi # wpa_cli -iwlan0 select_network 使用wifi # wpa_cli -iwlan0 enable_network 断开wifi # wpa_cli -iwlan0 disconnect 重连wifi # wpa_cli -iwlan0 reconnect 停止使用wifi # wpa_cli -iwlan0 disable_network 编码 保存wifi # wpa_cli -iwlan0 save_config 此时wifi已经连接成功，但是还没有分配ip地址 udhcpc -iwlan0 -q 此时成功连接wifi。 ","date":"2020-11-27","objectID":"/2020/11/install_os/:2:2","tags":["raspberry"],"title":"树莓派安装ubuntu系统","uri":"/2020/11/install_os/"},{"categories":["月霜天的小教程"],"content":"添加DNS # vi /etc/resolv.conf nameserver 114.114.114.114 ","date":"2020-11-27","objectID":"/2020/11/install_os/:2:3","tags":["raspberry"],"title":"树莓派安装ubuntu系统","uri":"/2020/11/install_os/"},{"categories":["月霜天的小教程"],"content":"下载安装docker docker官网 1、卸载旧版本 # apt-get remove docker docker-engine docker.io containerd runc 2、添加repository # apt-get update # apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common # curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # apt-key fingerprint 0EBFCD88 # add-apt-repository \\ \"deb [arch=armhf] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" 3、安装docker # apt-get update # apt-get install docker-ce docker-ce-cli containerd.io 第三步一直提示 Unable to locate package docker-ce-cli 那就只能使用脚本的方式安装 # curl -sSL https://get.docker.com | sh # docker version Client: Version: 18.01.0-ce API version: 1.35 Go version: go1.9.2 Git commit: 03596f5 Built: Wed Jan 10 20:05:35 2018 OS/Arch: linux/arm64 Experimental: false Orchestrator: swarm Server: Engine: Version: 18.01.0-ce API version: 1.35 (minimum version 1.12) Go version: go1.9.2 Git commit: 03596f5 Built: Wed Jan 10 20:03:37 2018 OS/Arch: linux/arm64 Experimental: false 执行hello-world # docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world 256ab8fe8778: Already exists Digest: sha256:e7c70bb24b462baa86c102610182e3efcb12a04854e8c582838d92970a09f323 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (arm64v8) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 添加镜像源 # cat /etc/docker/daemon.json { \"registry-mirrors\": [\"https://c2Zra3lhZDYK.mirror.aliyuncs.com\"] } # systemctl daemon-reload # systemctl restart docker ","date":"2020-11-27","objectID":"/2020/11/install_os/:3:0","tags":["raspberry"],"title":"树莓派安装ubuntu系统","uri":"/2020/11/install_os/"},{"categories":["月霜天的GO"],"content":"简介 先来看一下 json.Unmarshal 的注释 大意是 json 解析的时候会调用 Unmarshaler 的接口。那么我们就可以自定义解析数据了。 先看一个例子 package main import ( \"encoding/json\" \"fmt\" \"time\" ) const textJson = `{\"name\":\"xiaoming\",\"duration\":\"5s\"}` func main() { var o Object json.Unmarshal([]byte(textJson),\u0026o) fmt.Printf(\"%+v\\n\",o) } type Object struct { Name string Time time.Duration } func (o *Object) UnmarshalJSON(data []byte) error { tmp := struct { Name string `json:\"name\"` Duration string `json:\"duration\"` }{} err := json.Unmarshal(data,\u0026tmp) if err != nil { return err } dur,err := time.ParseDuration(tmp.Duration) if err != nil { return err } o.Name = tmp.Name o.Time = dur return nil } 你可能觉得打印的数据和textJson没什么区别。 但是实际上打印的o.Time是个时间类型的数据了，从string转到time.Duration类型，这个可以很轻松的转换。 但是这里还会有一个坑，来看另一个例子 package main import ( \"encoding/json\" \"fmt\" \"time\" ) var testJSON = `{\"num\":5,\"duration\":\"5s\"}` type Nested struct { Dur time.Duration `json:\"duration\"` } func (n *Nested) UnmarshalJSON(data []byte) error { *n = Nested{} tmp := struct { Dur string `json:\"duration\"` }{} fmt.Printf(\"parsing nested json %s \\n\", string(data)) if err := json.Unmarshal(data, \u0026tmp); err != nil { fmt.Printf(\"failed to parse nested: %v\", err) return err } tmpDur, err := time.ParseDuration(tmp.Dur) if err != nil { fmt.Printf(\"failed to parse duration: %v\", err) return err } (*n).Dur = tmpDur return nil } type Object struct { Nested Num int `json:\"num\"` } //uncommenting this method still doesnt help. //tmp is parsed with the completed json at Nested //which doesnt take care of Num field, so Num is zero value. func (o *Object) UnmarshalJSON(data []byte) error { *o = Object{} tmp := struct { Nested Num int `json:\"num\"` }{} fmt.Printf(\"parsing object json %s \\n\", string(data)) if err := json.Unmarshal(data, \u0026tmp); err != nil { fmt.Printf(\"failed to parse object: %v\", err) return err } fmt.Printf(\"tmp object: %+v \\n\", tmp) (*o).Num = tmp.Num (*o).Nested = tmp.Nested return nil } func main() { obj := Object{} if err := json.Unmarshal([]byte(testJSON), \u0026obj); err != nil { fmt.Printf(\"failed to parse result: %v\", err) return } fmt.Printf(\"result: %+v \\n\", obj) } 最终输出的结果是 parsing object json {\"num\":5,\"duration\":\"5s\"} parsing nested json {\"num\":5,\"duration\":\"5s\"} tmp object: {Nested:{Dur:5s} Num:0} result: {Nested:{Dur:5s} Num:0} 这里你可能要疑问了，为什么数据丢失了，num从5变成了0？ 那么为什么会出现这种情况呢？ 用一个简单的例子说明一下 package main import \"fmt\" type Funer interface{ Name()string PrintName() } type A struct { } func (a *A) Name() string { return \"a\" } func (a *A) PrintName() { fmt.Println(a.Name()) } type B struct { A } func (b *B) Name() string { return \"b\" } func getBer() Funer { return \u0026B{} } func main() { b := getBer() b.PrintName() } 这是一个类似继承的实现，它最终会打印 a 。 这是因为golang没有继承方法，它只会调用自己的指针的数据，如果是C/C++，它会实现多态，打印 b 。 这样就会导致 json 数据的接口调用是从外部到内部的接口调用，谁的指针方法就实现谁的指针方法。 那么上面那种情况证明解决呢？ package main import ( \"encoding/json\" \"fmt\" \"time\" ) var testJSON = `{\"num\":5,\"duration\":\"5s\"}` type Nested struct { Dur time.Duration `json:\"duration\"` } func (obj *Object) UnmarshalJSON(data []byte) error { tmp := struct { Dur string `json:\"duration\"` Num int `json:\"num\"` }{} if err := json.Unmarshal(data, \u0026tmp); err != nil { return err } dur, err := time.ParseDuration(tmp.Dur) if err != nil { return err } obj.Dur = dur obj.Num = tmp.Num return nil } type Object struct { Nested Num int `json:\"num\"` } var _ json.Unmarshaler = (*Object)(nil) func main() { obj := Object{} _ = json.Unmarshal([]byte(testJSON), \u0026obj) fmt.Printf(\"result: %+v \\n\", obj) } 在内部不使用继承，通过的结构来解析数据就可以了。 ","date":"2020-11-25","objectID":"/2020/11/json_example/:1:0","tags":["json"],"title":"如何自定义让json解析出自定义值","uri":"/2020/11/json_example/"},{"categories":["月霜天的小教程"],"content":"前言 在开始监控你的服务之前，你需要通过添加prometheus客户端来添加监控。 可以找 第三方exporter 监控你的服务，也可以自己编写exporter。 目前已经有很多不同的语言编写的客户端库，包括官方提供的Go，Java，Python，Ruby。 已有客户端库 在了解编写exporter之前，可以先5分钟学会搭建prometheus ","date":"2020-11-20","objectID":"/2020/11/exporter/:1:0","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"简单的exporter服务 先写一个简单的http服务，在9095端口启动了一个能够为prometheus提供监控指标的HTTP服务。你可以在 http://localhost:9095/metrics 看到这些指标。 package main import ( \"github.com/prometheus/client_golang/prometheus/promhttp\" \"net/http\" ) func main() { http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) }) http.Handle(\"/metrics\",promhttp.Handler()) http.ListenAndServe(\":9095\",nil) } 虽然偶尔会手动访问/metrics页面查看指标数据，但是将指标数据导入prometheus才方便。 global:scrape_interval:15s# 默认抓取间隔，15s向目标抓取一次数据external_labels:monitor:'prometheus-monitor'# 抓取对象scrape_configs:- job_name:'exporter'# 名称，会在每一条metrics添加标签{job_name:\"prometheus\"}scrape_interval:5s# 抓取时间static_configs:# 抓取对象- targets:['localhost:9095'] 那么在 http://localhost:9090/ 浏览器输入 PromQL 表达式 go_info,就会看到如图的结果 ","date":"2020-11-20","objectID":"/2020/11/exporter/:2:0","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"监控指标 ","date":"2020-11-20","objectID":"/2020/11/exporter/:3:0","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"Counter(计数器类型) Counter记录的是事件的数量或大小，只增不减，除非发生重置。 Counter主要有两个方法 # 将counter加1 Inc() # 增加指定值，如果\u003c0会panic Add(float64) package main import ( \"github.com/prometheus/client_golang/prometheus\" \"github.com/prometheus/client_golang/prometheus/promauto\" \"github.com/prometheus/client_golang/prometheus/promhttp\" \"net/http\" \"time\" ) var ( failures = prometheus.NewCounterVec(prometheus.CounterOpts{ Name: \"hq_failture_total\", Help: \"failure counts\", },[]string{\"device\"}) // 可以使用promauto自动注册 success = promauto.NewCounterVec(prometheus.CounterOpts{ Name: \"hq_failture_total\", Help: \"failure counts\", },[]string{\"device\"}) ) func init() { prometheus.MustRegister(failures) } func main() { go func() { failures.WithLabelValues(\"/dev/sda\").Add(3.2) time.Sleep(time.Second) failures.WithLabelValues(\"/dev/sda\").Inc() time.Sleep(time.Second) failures.WithLabelValues(\"/dev/sdb\").Inc() time.Sleep(time.Second) failures.WithLabelValues(\"/dev/sdb\").Add(1.5) }() http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) }) http.Handle(\"/metrics\",promhttp.Handler()) http.ListenAndServe(\":9095\",nil) } ","date":"2020-11-20","objectID":"/2020/11/exporter/:3:1","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"Gauge(仪表盘类型) Gauge是可增可减的指标类，更关注于数值本身。 Gauge主要有几种方法 # 设置任意值 Set(float64) # 加1 Inc() # 减1 Dec() # 加任意数，如果是负数，那么就会减去 Add(float64) # 和当前值的差值 Sub(float64) # 设置值为当前时间戳 SetToCurrentTime() package main import ( \"github.com/prometheus/client_golang/prometheus\" \"github.com/prometheus/client_golang/prometheus/promhttp\" \"net/http\" \"time\" ) var ( failures = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Name: \"hq_failture_total\", Help: \"failure counts\", },[]string{\"device\"}) ) func init() { prometheus.MustRegister(failures) } func main() { go func() { failures.WithLabelValues(\"/dev/sda\").Add(5) failures.WithLabelValues(\"/dev/sdb\").Set(10) time.Sleep(time.Second * 5) failures.WithLabelValues(\"/dev/sda\").Inc() failures.WithLabelValues(\"/dev/sdb\").Add(3) time.Sleep(time.Second * 5) failures.WithLabelValues(\"/dev/sda\").Dec() failures.WithLabelValues(\"/dev/sdb\").SetToCurrentTime() time.Sleep(time.Second* 5) failures.WithLabelValues(\"/dev/sda\").Sub(1) failures.WithLabelValues(\"/dev/sdb\").Dec() time.Sleep(time.Second* 5) time.Sleep(time.Second) }() http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) }) http.Handle(\"/metrics\",promhttp.Handler()) http.ListenAndServe(\":9095\",nil) } ","date":"2020-11-20","objectID":"/2020/11/exporter/:3:2","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"Summary(摘要类型) 表示一段时间数据采样结果，由_count,_sum构成 Summary只有一种方法 Observe(float64) 你可以访问 /metrics 可以看到hq_failture_total_sum和hq_failture_total_count hq_failture_total_sum代表观察值的总和 hq_failture_total_count代表观察到的条数 package main import ( \"github.com/prometheus/client_golang/prometheus\" \"github.com/prometheus/client_golang/prometheus/promhttp\" \"net/http\" \"time\" ) var ( failures = prometheus.NewSummaryVec(prometheus.SummaryOpts{ Name: \"hq_failture_total\", Help: \"failure counts\", },[]string{\"device\"}) ) func init() { prometheus.MustRegister(failures) } func main() { var count float64 go func() { t := time.NewTicker(time.Second) for { count++ failures.WithLabelValues(\"/dev/sdc\").Observe(count) \u003c-t.C } }() http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) }) http.Handle(\"/metrics\",promhttp.Handler()) http.ListenAndServe(\":9095\",nil) } ","date":"2020-11-20","objectID":"/2020/11/exporter/:3:3","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"Histogram(直方图类型) summary可以提供平均延迟数据，但是如果你想要分位数呢？ 那么就可以使用Histogram分位数. Histogram只有一种方法 Observe(float64) 你可以访问 /metrics 可以看到hq_failture_total_sum和hq_failture_total_count、hq_failture_total_bucket package main import ( \"github.com/prometheus/client_golang/prometheus\" \"github.com/prometheus/client_golang/prometheus/promhttp\" \"math/rand\" \"net/http\" \"time\" ) var ( failures = prometheus.NewHistogramVec(prometheus.HistogramOpts{ Name: \"hq_failture_total\", Help: \"failure counts\", },[]string{\"device\"}) ) func init() { prometheus.MustRegister(failures) } func main() { go func() { t := time.NewTicker(time.Second) for { failures.WithLabelValues(\"/dev/sdc\").Observe(rand.Float64()) \u003c-t.C } }() http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) }) http.Handle(\"/metrics\",promhttp.Handler()) http.ListenAndServe(\":9095\",nil) } 那么什么是bucket(桶)？桶记录小于监控指标的数量 默认的buckets范围为{0.005，0.01，0.025，0.05，0.075，0.1，0.25，0.5，0.75，1，2.5，5，7.5，10} PromQL函数histogram_quantile可以用来统计桶中的分位数。例如，0.95分位数的表达式为 histogram_quantile(0.95,rate(hq_failture_total_bucket[1m])) ","date":"2020-11-20","objectID":"/2020/11/exporter/:3:4","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"如何给指标命名？ Prometheus 指标需要以字母开头，后面可以跟着任意数量的字母，数字，下划线。 命名的整体结构是 library_name_unit_suffix 虽然 [a-zA-Z_:][a-zA-Z0-9_:]* 是Prometheus中有效的命名规则的正则表达式，但你要避免是有某些有效值。 你不应该在测控指标使用冒号，因为它是为记录规则中使用而保留的。以下划线开头的名称是为prometheus内部使用而保留的。 _total,_count,_sum和_bucket这些后缀是留给counter，summary和histogram指标使用的。 除了在counter类型的指标上始终具有_total后缀外，不要将其他后缀放在指标名称的末尾。 ","date":"2020-11-20","objectID":"/2020/11/exporter/:4:0","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"简介 prometheus是一个开源的系统监控和警报工具包，最初由SoundCloud开发。自2012年始，许多公司和组织已经采用了prometheus，该项目拥有活跃的开发人员和用户社区。 它现在是一个独立的开源项目，独立于任何公司进行维护。着重于此，prometheus在2016年加入CNCF，是继kubernetes之后第二个托管的项目。 官网地址： Prometheus github地址： github 架构图 ","date":"2020-11-19","objectID":"/2020/11/prometheus/:1:0","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"下载与安装 安装方式有很多种，如果你是windows用户，那么只需要在本地起个二进制服务就可以。如果你是linux用户，可以通过docker等更加灵活方式部署。 ","date":"2020-11-19","objectID":"/2020/11/prometheus/:2:0","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"二进制 二进制下载地址 tar xvfz prometheus-*.tar.gz cd prometheus-* ./prometheus --config.file=prometheus.yml 当然你可以下载最新的源码进行编译获取最新的二进制文件。 mkdir -p $GOPATH/src/github.com/prometheus cd $GOPATH/src/github.com/prometheus git clone https://github.com/prometheus/prometheus.git cd prometheus make build ./prometheus -config.file=your_config.yml ","date":"2020-11-19","objectID":"/2020/11/prometheus/:2:1","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"docker # 使用 /opt/prometheus/prometheus.yml 的配置 docker run --name prometheus -d -p 127.0.0.1:9090:9090 -v /opt/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus ","date":"2020-11-19","objectID":"/2020/11/prometheus/:2:2","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"helm helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo add stable https://charts.helm.sh/stable helm repo update # Helm 3 $ helm install [RELEASE_NAME] prometheus-community/prometheus # Helm 2 $ helm install --name [RELEASE_NAME] prometheus-community/prometheus ","date":"2020-11-19","objectID":"/2020/11/prometheus/:2:3","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"配置文件 prometheus已经能够起来了，我们也需要对服务做一些个性化的配置，让prometheus能够获取到数据。 global:scrape_interval:15s# 默认抓取间隔，15s向目标抓取一次数据external_labels:monitor:'prometheus-monitor'# 抓取对象scrape_configs:- job_name:'prometheus'# 名称，会在每一条metrics添加标签{job_name:\"prometheus\"}scrape_interval:5s# 抓取时间static_configs:# 抓取对象- targets:['localhost:9090'] 重启完毕后，我们可以看到这两个界面。 ","date":"2020-11-19","objectID":"/2020/11/prometheus/:2:4","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"安装exporter 如何获取数据源？从下面的链接你可以挑选一些官方或非官方的exporter来监控你的服务。 exporters and integrations 例如：Node Exporter 暴露了如linux等UNIX系统的内核和机器级别的指标(windows用户应用wmi_exporter)。它提供了很多标准的指标如CPU、内存、磁盘空间、硬盘I/O和网络带宽。此外，它还提供了从负载率平均值到主板温度等很多内核暴露的问题。 下载运行之后，我们需要更新prometheus.yml，然后 重启 prometheus加载新的配置 global:scrape_interval:15s# 默认抓取间隔，15s向目标抓取一次数据external_labels:monitor:'codelab-monitor'# 抓取对象scrape_configs:- job_name:'prometheus'# 名称，会在每一条metrics添加标签{job_name:\"prometheus\"}scrape_interval:5s# 抓取时间static_configs:# 抓取对象- targets:['localhost:9090']- job_name:'node'scrape_interval:5sstatic_configs:- targets:['localhost:9100'] ","date":"2020-11-19","objectID":"/2020/11/prometheus/:3:0","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"告警通知 如果你需要设定特定的规则，例如cpu/内存超过了设定值，需要将告警数据发送到你的邮件、微信、钉钉等，那么你就需要Alertmanager。 告警分为两个部分。首先需要在prometheus中添加告警规则，定义告警产生的逻辑，其次Altermanager将触发的警报转化为通知，例如邮件，呼叫和聊天消息。 global:scrape_interval:15s# 默认抓取间隔，15s向目标抓取一次数据evaluation_interval:10sexternal_labels:monitor:'codelab-monitor'# 规则文件rule_files:- rules.ymlalerting:alertmanagers:- static_configs:- targets:- localhost:9093# 抓取对象scrape_configs:- job_name:'prometheus'# 名称，会在每一条metrics添加标签{job_name:\"prometheus\"}scrape_interval:5s# 抓取时间static_configs:# 抓取对象- targets:['localhost:9090']- job_name:'node'scrape_interval:5sstatic_configs:- targets:['localhost:9100'] # 规则文件rules.ymlgroups:- name:examplerules:- alert:InstanceDownexpr:up == 0for:1m 按照 evaluation_interval 的配置，InstanceDown告警每10s将被执行1次。如果持续1m收到数据，那么这个告警就会被触发。在达到设定的时间长度前，这个告警处于 pending 状态，在 Alerts 页面可以单击警告查看包括它的标签在内的更多详细信息。 注：通常建议至少5min以减少噪声从而减轻固有监控的各种情况。 既然有一个被触发的告警，需要 Alertmanager 针对它做一些事。 ","date":"2020-11-19","objectID":"/2020/11/prometheus/:4:0","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"Alertmanager 如何管理告警通知？ 比如我只想工作时间收到告警，那么可以设置告警事件为09:00-21:00。 比如我某个服务不想收到通知，那么可以暂时关闭通知。 下载地址 现在需要为 Alertmanager 创建一个配置文件。这里有很多中方式让Alertmanager 通知到你。这里使用SMTP。 global:smtp_smarthost:'localhost:25'smtp_from:'youraddress@example.org'route:receiver:example-emailreceivers:- name:'example-email'email_configs:- to:'youraddress@example.org' 启动Alertmanager，现在可以在浏览器输入 http://localhost:9093 来访问 Alertmanager，在这个页面你将看到触发的告警，如果所有的配置正确并正常启动，一两分钟后就会收到邮件告警通知。 ","date":"2020-11-19","objectID":"/2020/11/prometheus/:5:0","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"总结 这个prometheus由exporter、prometheus server、Alertmanager构成。 exporter收集数据，prometheus server 拉取exporter数据，然后根据告警规则，将告警推送到Alertmanager处理。 中间还衍生了许多其他组件，例如pushgateway(客户端将数据push到pushgateway，由prometheus定期拉取)，grafana图标页面等。 ","date":"2020-11-19","objectID":"/2020/11/prometheus/:6:0","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":null,"content":" 希望成为一个有趣味儿的人。 A golang developer ","date":"2020-11-19","objectID":"/about/:0:0","tags":null,"title":"About me","uri":"/about/"}]