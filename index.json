[{"categories":["月霜天的小随笔"],"content":"一个程序占用的内存分为以下几个部分： 栈区（stack）：由编译器自动分配，存放函数的参数，局部变量等 堆区（heap）：由程序员分配释放 全局静态区：全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域， 未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。 程序结束后由系统释放。 文字常量区：常量字符串就是放在这里的。 程序结束后由系统释放。 程序代码区：存放函数体的二进制代码。 OS给一个进程分配的内存空间大致可以分为：代码区、全局数据区、栈(stack)、堆(heap)、环境变量区域以及中间空白的缓冲区六个部分。其中，数据的增长路径除栈(stack)是由高到低之外，其余的均是由低到高。 那么在写go的时候，变量到底分配在栈中还是在堆中，这个就不是程序员来决定的，而是go自行处理。可能你new出来的变量在堆上，也有可能在栈上。 那么我们是否有办法知道我们写的变量位置在哪呢？ ","date":"2022-03-07","objectID":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:0:0","tags":["内存"],"title":"逃逸分析","uri":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["月霜天的小随笔"],"content":"一、逃逸分析 go向开发者提供了变量逃逸分析的工具 $ go run -gcflags \"-m -l\" main.go package main import \"fmt\" func main() { a,b := 1,2 ans := add(a,b) fmt.Println(ans) } func add(a, b int) int { return a + b } 打印出来如下内容 .\\main.go:8:13: ans escapes to heap .\\main.go:8:13: main ... argument does not escape 3 这就表明了变量ans逃逸到了堆中。 ","date":"2022-03-07","objectID":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:1:0","tags":["内存"],"title":"逃逸分析","uri":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["月霜天的小随笔"],"content":"二、逃逸原理 逃逸分析(escape anslysis)就是在程序编译阶段根据程序中的数据流，对代码中哪些变量需要在栈上分配，哪些变量需要在堆上分配进行静态分析的方法。 在栈上效率肯定要比在堆上高。一个理想的逃逸分析算法自然是将能分配在栈上的变量尽可能保留在栈上，尽可能少“逃逸”到堆上。 在[cmd/compile/internal/gc/escape.go]文件中，提到了逃逸分析的设计原理。 两个不变性： 指向栈对象的指针不能存在堆中 指向栈对象的指针不能存活超过这个栈对象（因为声明函数返回并销毁了对象的堆栈，或在循环迭代中使用局部变量） 逃逸分析的输入是go编译器解析了源文件后获取的整个程序的抽象语法树AST： 1、首先，构建一个有向加权图，其中顶点(locations)表示语句和表达式分配的变量，边表示变量之间的赋值（权重表示寻址/取址次数） 2、接下来，遍历该有向加权图，在图中寻找可能违反上述两个不变性的赋值路径。如果一个变量v的地址是存储在堆上或可能超过存活期，那么v就会被标记需要在堆上分配。 3、为了支持函数间分析，算法还记录了从每个函数的参数到堆的数据流及其结果的数据流。这被称为“参数标签”，用来静态调用，以改进函数参数间的逃逸分析。 源码解析后得到的抽象语法树AST的Node切片为xtop： var xtop []*Node 在MAIN函数中，注册了逃逸分析 func Main(archInit func(*Arch)) { ... // Phase 6: Escape analysis. // Required for moving heap allocations onto stack, // which in turn is required by the closure implementation, // which stores the addresses of stack variables into the closure. // If the closure does not escape, it needs to be on the stack // or else the stack copier will not update it. // Large values are also moved off stack in escape analysis; // because large values may contain pointers, it must happen early. timings.Start(\"fe\", \"escapes\") escapes(xtop) } ","date":"2022-03-07","objectID":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:2:0","tags":["内存"],"title":"逃逸分析","uri":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["月霜天的小随笔"],"content":"三、如何逃逸 func escapes(all []*Node) { visitBottomUp(all, escapeFuncs) } 这个visitBottomUp其实就是遍历有向加权图 func visitBottomUp(list []*Node, analyze func(list []*Node, recursive bool)) { var v bottomUpVisitor v.analyze = analyze v.nodeID = make(map[*Node]uint32) for _, n := range list { if n.Op == ODCLFUNC \u0026\u0026 !n.Func.IsHiddenClosure() { v.visit(n) } } } 真正分析逃逸分析的是escapeFuncs，它是对最小批的函数执行逃逸分析 func escapeFuncs(fns []*Node, recursive bool) { // 如果不是函数类型，报错 for _, fn := range fns { if fn.Op != ODCLFUNC { Fatalf(\"unexpected node: %v\", fn) } } var e Escape e.heapLoc.escapes = true // Construct data-flow graph from syntax trees. for _, fn := range fns { e.initFunc(fn) } for _, fn := range fns { e.walkFunc(fn) } e.curfn = nil e.walkAll() e.finish(fns) } 具体逃逸分析逻辑还是比较复杂的，我们只需要知道逃逸分析是根据有向加权图根据两个不变性进行的分析。 ","date":"2022-03-07","objectID":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:3:0","tags":["内存"],"title":"逃逸分析","uri":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["月霜天的小随笔"],"content":"四、实战 既然知道了这两个不变性，那我们可以对这两个不变性做一下文章。 ","date":"2022-03-07","objectID":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:4:0","tags":["内存"],"title":"逃逸分析","uri":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["月霜天的小随笔"],"content":"1、简单逃逸 func main() { foo() e,f := boo() println(\"out e: \",\u0026e) println(\"out f: \",\u0026f) } func foo() { a,b := 11, new(int) println(\"a: \", \u0026a) println(\"b: \",\u0026b) } func boo() (*int, *int) { c,d := 11,12 println(\"c: \",\u0026c) println(\"d: \",\u0026d) return \u0026c,\u0026d } 变量c和d因为在外部被使用了，所以会逃逸，其他变量只是在函数内部使用，所以不会逃逸。 $ go run -gcflags=\"-m -l\" main.go .\\main.go:11:16: new(int) does not escape .\\main.go:17:2: moved to heap: c .\\main.go:17:4: moved to heap: d 这个与我们分析结果一致。 ","date":"2022-03-07","objectID":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:4:1","tags":["内存"],"title":"逃逸分析","uri":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["月霜天的小随笔"],"content":"2、切片逃逸 func main() { noEscapesliceInHeap() noEscapesliceInStack() escapeslice() } func noEscapesliceInHeap() { var s1 []int println(\"s1: \",\u0026s1) s1 = append(s1, 1,2,3) println(\"s1: \",\u0026s1) } func noEscapesliceInStack() { var s2 = make([]int,0,4) println(\"s2: \",\u0026s2) s2 = append(s2, 1,2,3) println(\"s2: \",\u0026s2) } func escapeslice() *[]int { var s3 = make([]int, 0, 4) println(\"s3: \",\u0026s3) return \u0026s3 } 我们在slice时分析过，当slice发生扩容时会重新分配内存，这一步是在堆上操作的。 noEscapesliceInHeap声明空slice，并添加元素，slice本身分配在栈上，但在运行过程中动态扩容，将元素分配在堆上。 noEscapesliceInStack初始化了包含4个元素存储空间的切片，slice没有逃逸，当添加元素小于4个，使用栈空间，当使用超过4个，那么会发生扩容，在堆上分配更大的空间将栈上的元素拷贝过去。 escapeslice切片及元素都分配在堆上。 $ go run -gcflags=\"-m -l\" main.go .\\main.go:17:15: make([]int, 0, 4) does not escape .\\main.go:24:6: moved to heap: s3 .\\main.go:24:15: make([]int, 0, 4) escapes to heap ","date":"2022-03-07","objectID":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:4:2","tags":["内存"],"title":"逃逸分析","uri":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["月霜天的小随笔"],"content":"3、fmt逃逸 func main() { foo() } func foo() { a,b := 11,12 println(\"a: \",\u0026a) println(\"b: \",\u0026b) fmt.Printf(\"a:%d \",\u0026a) } $ go run -gcflags=\"-m -l\" main.go .\\main.go:10:2: moved to heap: a .\\main.go:13:12: ... argument does not escape 此时变量a还没有逃逸 func foo() { a,b := 11,12 println(\"a: \",\u0026a) println(\"b: \",\u0026b) fmt.Printf(\"a:%d \",a) } $ go run -gcflags=\"-m -l\" main.go .\\main.go:13:12: ... argument does not escape .\\main.go:13:13: a escapes to heap 此时变量a已经逃逸 ","date":"2022-03-07","objectID":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:4:3","tags":["内存"],"title":"逃逸分析","uri":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["月霜天的小随笔"],"content":"4、手动避免逃逸 在源码中，有这么一个函数 func noescape(p unsafe.Pointer) unsafe.Pointer { x := uintptr(p) return unsafe.Pointer(x ^ 0) // 任何数值与0的异或都是原数 } 实现逻辑使得我们传入的指针值与其返回的指针值一样，只是通过uintptr做了一次转换，而这次转换将指针转换成数值，“切断”了逃逸分析的数据流，导致传入的指针避免逃逸。 那么我们也可以使用这个函数 func noescape(p unsafe.Pointer) unsafe.Pointer { x := uintptr(p) return unsafe.Pointer(x ^ 0) // 任何数值与0的异或都是原数 } func foo() { a := 11 b := 12 fmt.Printf(\"a=%d\\n\",noescape(unsafe.Pointer(\u0026a))) println(\"addr of a: \",\u0026a) println(\"addr of b: \",\u0026b) } func main() { foo() } $ go run -gcflags=\"-m -l\" main.go .\\main.go:7:15: p does not escape .\\main.go:13:2: moved to heap: a .\\main.go:14:2: moved to heap: b 这样就变量a就不会逃逸了 ","date":"2022-03-07","objectID":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/:4:4","tags":["内存"],"title":"逃逸分析","uri":"/2022/03/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/"},{"categories":["月霜天的小随笔"],"content":"golang里有个重要的类型就是结构体，虽然不能像C++一样有类的功能和特性，但也有自己独特的魅力。 这里着重介绍一下经常遇到的空结构体，我们经常在一些源码中看到struct{}这样的定义，在channel，map中经常出现，那么这到底是为什么？ ","date":"2022-03-07","objectID":"/2022/03/struct/:0:0","tags":["struct"],"title":"Struct的使用场景","uri":"/2022/03/struct/"},{"categories":["月霜天的小随笔"],"content":"一、空结构体 type emptyStruct struct{} func main() { a := new(emptyStruct) b := new(emptyStruct) println(a, b, a == b) c := new(emptyStruct) d := new(emptyStruct) fmt.Println(c, d, c == d) println(c, d, c == d) } 输出结果为： 0xc00011df47 0xc00011df47 false \u0026{} \u0026{} true 0xecbde0 0xecbde0 true 可以看到new了两个结构体，第一次比较是false，第二次比较是true。 我们猜测这里可能发生了逃逸，使用命令 $ go run -gcflags \"-m -l\" main.go .\\main.go:8:10: new(emptyStruct) does not escape .\\main.go:9:10: new(emptyStruct) does not escape .\\main.go:13:10: new(emptyStruct) escapes to heap .\\main.go:14:10: new(emptyStruct) escapes to heap .\\main.go:16:13: ... argument does not escape .\\main.go:16:22: c == d escapes to heap 我们发现确实发生了逃逸现象，未逃逸的变量分配在栈上，逃逸的变量分配在堆上。 在堆上分配的变量通过mallocgc函数分配到了zerobase这个地址。 ","date":"2022-03-07","objectID":"/2022/03/struct/:1:0","tags":["struct"],"title":"Struct的使用场景","uri":"/2022/03/struct/"},{"categories":["月霜天的小随笔"],"content":"二、zerobase是什么 zerobase是一个uintptr的全局变量，占用8个字节。当在任何地方定义零值内存分配时(channel，slice，map)，都是zerobase。 func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer { if size == 0 { return unsafe.Pointer(\u0026zerobase) } ... } 因为定义的零值使用zerobase，所以不占用内存空间。 ","date":"2022-03-07","objectID":"/2022/03/struct/:2:0","tags":["struct"],"title":"Struct的使用场景","uri":"/2022/03/struct/"},{"categories":["月霜天的小随笔"],"content":"三、定义空结构体的方法 ","date":"2022-03-07","objectID":"/2022/03/struct/:3:0","tags":["struct"],"title":"Struct的使用场景","uri":"/2022/03/struct/"},{"categories":["月霜天的小随笔"],"content":"1、原生定义 a := struct{}{} ","date":"2022-03-07","objectID":"/2022/03/struct/:3:1","tags":["struct"],"title":"Struct的使用场景","uri":"/2022/03/struct/"},{"categories":["月霜天的小随笔"],"content":"2、重定义 type emptyStruct struct{} ","date":"2022-03-07","objectID":"/2022/03/struct/:3:2","tags":["struct"],"title":"Struct的使用场景","uri":"/2022/03/struct/"},{"categories":["月霜天的小随笔"],"content":"3、组合 type emptyStruct struct{} type object1 struct { emptyStruct } type object2 struct { _ struct{} } ","date":"2022-03-07","objectID":"/2022/03/struct/:3:3","tags":["struct"],"title":"Struct的使用场景","uri":"/2022/03/struct/"},{"categories":["月霜天的小随笔"],"content":"4、内置字段 空结构体不占用内存 地址偏移，用作内存对齐 整体类型长度要和最长字段类型长度对齐 type object1 struct { s struct{} b byte } type object2 struct { s struct{} n int64 } type object3 struct { b byte s struct{} n int64 } type object4 struct { b byte s struct{} } type object5 struct { n int64 s struct{} } func main() { println(unsafe.Sizeof(object1{})) println(unsafe.Sizeof(object2{})) println(unsafe.Sizeof(object3{})) println(unsafe.Sizeof(object4{})) println(unsafe.Sizeof(object5{})) } 输出： 1 8 16 2 16 ","date":"2022-03-07","objectID":"/2022/03/struct/:3:4","tags":["struct"],"title":"Struct的使用场景","uri":"/2022/03/struct/"},{"categories":["月霜天的小随笔"],"content":"5、指针接受者 type emptyStruct1 struct{} func (e *emptyStruct1) Func() { println(e) } type emptyStruct2 struct {} func (e *emptyStruct2) Func() { println(e) } func main() { s := emptyStruct1{} s.Func() s2 := emptyStruct2{} s2.Func() } // Output： 0xc00004df78 0xc00004df78 receiver 作为第一个参数传入函数 空结构体作为receiver，实际上不需要传入，因为空结构体没有值 receiver为一个指针的场景，地址作为第一个参数传入函数，函数调用时，编译器传入zerobase ","date":"2022-03-07","objectID":"/2022/03/struct/:3:5","tags":["struct"],"title":"Struct的使用场景","uri":"/2022/03/struct/"},{"categories":["月霜天的小随笔"],"content":"httprouter是非常高效的http路由框架，gin框架的路由也是基于此库 ","date":"2022-03-07","objectID":"/2022/03/httprouter/:0:0","tags":["gin","router"],"title":"Httprouter","uri":"/2022/03/httprouter/"},{"categories":["月霜天的小随笔"],"content":"一、使用方法 使用方法也比较简单，如下： package main import ( \"fmt\" \"net/http\" \"log\" \"github.com/julienschmidt/httprouter\" ) func Index(w http.ResponseWriter, r *http.Request, _ httprouter.Params) { fmt.Fprint(w, \"Welcome!\\n\") } func Hello(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { fmt.Fprintf(w, \"hello, %s!\\n\", ps.ByName(\"name\")) } func main() { router := httprouter.New() router.GET(\"/\", Index) router.GET(\"/hello/:name\", Hello) log.Fatal(http.ListenAndServe(\":8080\", router)) } ","date":"2022-03-07","objectID":"/2022/03/httprouter/:1:0","tags":["gin","router"],"title":"Httprouter","uri":"/2022/03/httprouter/"},{"categories":["月霜天的小随笔"],"content":"二、前缀树 这里在前文已经描述了，详情看这里 ","date":"2022-03-07","objectID":"/2022/03/httprouter/:2:0","tags":["gin","router"],"title":"Httprouter","uri":"/2022/03/httprouter/"},{"categories":["月霜天的小随笔"],"content":"三、具体实现 ","date":"2022-03-07","objectID":"/2022/03/httprouter/:3:0","tags":["gin","router"],"title":"Httprouter","uri":"/2022/03/httprouter/"},{"categories":["月霜天的小随笔"],"content":"1、Router type Router struct { trees map[string]*node // 存储了http不同方法的根节点 paramsPool sync.Pool maxParams uint16 SaveMatchedRoutePath bool // 是否通过重定向，给路径自添加/ RedirectTrailingSlash bool // 是否通过重定向，自动修复路径，比如双斜杠等自动修复为单斜杠 RedirectFixedPath bool // 是否检测当前请求的方法被允许 HandleMethodNotAllowed bool // 是否自定答复OPTION请求 HandleOPTIONS bool GlobalOPTIONS http.Handler globalAllowed string // 404处理 NotFound http.Handler // 不被允许的方法处理 MethodNotAllowed http.Handler // 异常处理 PanicHandler func(http.ResponseWriter, *http.Request, interface{}) } 这里的trees同样是存储了方法树，每一个不同的方法都有一个前缀树。 这里的httproute性能比beego高的一个原因是它使用的sync.Pool来优化内存的使用。 ","date":"2022-03-07","objectID":"/2022/03/httprouter/:3:1","tags":["gin","router"],"title":"Httprouter","uri":"/2022/03/httprouter/"},{"categories":["月霜天的小随笔"],"content":"2、路由注册 在调用Handle方法的时候插入路由到路由树中。 func (r *Router) Handle(method, path string, handle Handle) { varsCount := uint16(0) if method == \"\" { panic(\"method must not be empty\") } if len(path) \u003c 1 || path[0] != '/' { panic(\"path must begin with '/' in path '\" + path + \"'\") } if handle == nil { panic(\"handle must not be nil\") } if r.trees == nil { r.trees = make(map[string]*node) } root := r.trees[method] if root == nil { root = new(node) r.trees[method] = root r.globalAllowed = r.allowed(\"*\", \"\") } // 添加路由到前缀树中 root.addRoute(path, handle) // Lazy-init paramsPool alloc func // 初始化pool if r.paramsPool.New == nil \u0026\u0026 r.maxParams \u003e 0 { r.paramsPool.New = func() interface{} { ps := make(Params, 0, r.maxParams) return \u0026ps } } } ","date":"2022-03-07","objectID":"/2022/03/httprouter/:3:2","tags":["gin","router"],"title":"Httprouter","uri":"/2022/03/httprouter/"},{"categories":["月霜天的小随笔"],"content":"3、插入算法 这里插入路由树的方式和beego不同，beego是按照路由/来分割的，比如/user和/userinfo这是对应的两个子树，而httprouter将相同前缀合并，/user是父节点。 下面给个例子 Priority Path Handle 9 \\ *\u003c1\u003e 3 ├s nil 2 |├earch\\ *\u003c2\u003e 1 |└upport\\ *\u003c3\u003e 2 ├blog\\ *\u003c4\u003e 1 | └:post nil 1 | └\\ *\u003c5\u003e 2 ├about-us\\ *\u003c6\u003e 1 | └team\\ *\u003c7\u003e 1 └contact\\ *\u003c8\u003e 同样，节点被区分了几种类型 type nodeType uint8 const ( static nodeType = iota // default 普通节点 root // 根节点 param // 参数节点 catchAll // 通配符 ) 而节点的数据结构为 type node struct { path string // 节点对应的路径 indices string wildChild bool // 是否是通配符 nType nodeType // 节点类型 priority uint32 children []*node // 子节点 handle Handle } ","date":"2022-03-07","objectID":"/2022/03/httprouter/:3:3","tags":["gin","router"],"title":"Httprouter","uri":"/2022/03/httprouter/"},{"categories":["月霜天的小随笔"],"content":"4、查找路由 httprouter是实现了net/http的ServeHTTP方法 func (r *Router) ServeHTTP(w http.ResponseWriter, req *http.Request) { if r.PanicHandler != nil { defer r.recv(w, req) } path := req.URL.Path if root := r.trees[req.Method]; root != nil { if handle, ps, tsr := root.getValue(path, r.getParams); handle != nil { if ps != nil { handle(w, req, *ps) r.putParams(ps) } else { handle(w, req, nil) } return } // 重定向逻辑 } // 异常处理逻辑 } 这里接受到http请求，根据请求的方法和路由信息，查找路由树。 然后根据路由和路由树进行对比，获取到执行的方法。 这一部分比beego的处理稍显简洁。 ","date":"2022-03-07","objectID":"/2022/03/httprouter/:3:4","tags":["gin","router"],"title":"Httprouter","uri":"/2022/03/httprouter/"},{"categories":["月霜天的小随笔"],"content":"四、总结 httprouter使用的路由树比beego的路由树更加高效 1、对前缀树再优化，减少了重复的前缀。 2、对路由上的参数获取使用sync.Pool方式接受，减少了内存的分配。 ","date":"2022-03-07","objectID":"/2022/03/httprouter/:4:0","tags":["gin","router"],"title":"Httprouter","uri":"/2022/03/httprouter/"},{"categories":["月霜天的小随笔"],"content":"在日常Golang使用中，你有没有这样的疑惑？ nil是什么？哪些可以用nil？哪些不能用nil？ 接下来，我将对这些内容进行总结。 ","date":"2022-03-07","objectID":"/2022/03/nil/:0:0","tags":["nil"],"title":"Nil的使用场景","uri":"/2022/03/nil/"},{"categories":["月霜天的小随笔"],"content":"一、什么是nil 首先nil是一个变量，我们可以在源码包中找到这样的描述： // nil is a predeclared identifier representing the zero value for a // pointer, channel, func, interface, map, or slice type. var nil Type // Type must be a pointer, channel, func, interface, map, or slice type // Type is here for the purposes of documentation only. It is a stand-in // for any Go type, but represents the same type for any given function // invocation. type Type int 从类型定义上可以得到以下关键点： nil本质上是一个Type类型的变量 Type类型仅仅是基于int定义出来的新类型 nil适用于指针、channel、函数、interface、map、slice六种类型 ","date":"2022-03-07","objectID":"/2022/03/nil/:1:0","tags":["nil"],"title":"Nil的使用场景","uri":"/2022/03/nil/"},{"categories":["月霜天的小随笔"],"content":"二、六大类型 ","date":"2022-03-07","objectID":"/2022/03/nil/:2:0","tags":["nil"],"title":"Nil的使用场景","uri":"/2022/03/nil/"},{"categories":["月霜天的小随笔"],"content":"1、指针 1.1、变量定义 var ptr *int 1.2、变量本身 变量本身是8字节的内存块 1.3、nil赋值 这8个字节指针置0 1.4、nil判断 判断这8个字节是否为0 ","date":"2022-03-07","objectID":"/2022/03/nil/:2:1","tags":["nil"],"title":"Nil的使用场景","uri":"/2022/03/nil/"},{"categories":["月霜天的小随笔"],"content":"2、channel 2.1、变量定义 // 变量本身定义 var c1 chan struct{} // 变量定义和初始化 var c2 = make(chan struct{}) 第一种方式仅仅定义了c1变量本身 第二种方式则分配了c2的内存，调用了runtime下的makechan函数来创建结构 2.2、变量本身 一个 8 字节的指针而已，指向一个 channel 管理结构，也就是 struct hchan 的指针。 2.3、nil赋值 赋值 nil 之后，仅仅是把这 8 字节的指针置 0 。 2.4、nil判断 判断这指针是否为0 ","date":"2022-03-07","objectID":"/2022/03/nil/:2:2","tags":["nil"],"title":"Nil的使用场景","uri":"/2022/03/nil/"},{"categories":["月霜天的小随笔"],"content":"3、map 3.1、变量定义 // 变量定义 var m1 map[int]int // 变量定义和初始化 var m2 = make(map[int]int) 第一种方式仅仅定义了m1变量本身 第二种方式则分配了m2的内存，调用了runtime下的makemap函数来创建结构 3.2、变量本身 变量本身是个指针 // A header for a Go map. type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler's definition. // 键值对的数量 count int // # live cells == size of map. Must be first (used by len() builtin) // 标识状态 flags uint8 // 2^B = len(buckets) B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) // 溢出桶里bmap大致数量 noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details // hash因子 hash0 uint32 // hash seed // 指向一个数组（连续内存空间），数组类型为[]bmap，bmap类型就是存在键值对的结构 buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. // 扩容时，存放之前的buckets oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing // 分流次数，成倍扩容分流操作计数的字段 nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) // 溢出桶结构，正常桶里面某个bmap存满了，会使用这里面的内存空间存放键值对 extra *mapextra // optional fields } 初始化了map结构后，才能分配map所使用的内存。 3.3、nil赋值 赋值 nil 之后，仅仅是把这 8 字节的指针置 0 。 3.4、nil判断 判断这指针是否为0 ","date":"2022-03-07","objectID":"/2022/03/nil/:2:3","tags":["nil"],"title":"Nil的使用场景","uri":"/2022/03/nil/"},{"categories":["月霜天的小随笔"],"content":"4、interface 4.1、变量定义 // 定义一个接口 type Reader interface { Read(p []byte) (n int, err error) } // 定义一个接口变量 var reader Reader // 空接口 var empty interface{} 4.2、变量本身 type iface struct { tab *itab data unsafe.Pointer } type eface struct { _type *_type data unsafe.Pointer } 其中iface是通常定义的interface类型，eface是空接口对应的数据结构，这两个结构体占用内存都是16字节。 4.3、nil赋值 赋值 nil 之后，把这 16 字节的内存块置 0 。 4.4、nil判断 需要判断类型和值 ","date":"2022-03-07","objectID":"/2022/03/nil/:2:4","tags":["nil"],"title":"Nil的使用场景","uri":"/2022/03/nil/"},{"categories":["月霜天的小随笔"],"content":"5、函数 5.1、变量定义 var f func(int) error 5.2、变量本身 变量本身是8字节的指针 5.3、nil赋值 本身就是指针，只不过指向的是函数而已，所以赋值也是将这 8 字节置 0 。 5.4、nil判断 判断这8个字节是否为0 ","date":"2022-03-07","objectID":"/2022/03/nil/:2:5","tags":["nil"],"title":"Nil的使用场景","uri":"/2022/03/nil/"},{"categories":["月霜天的小随笔"],"content":"6、slice 6.1、变量定义 // 定义 var slice1 []int var slice2 []int = []byte{1,2,3} // 定义及初始化 var slice3 = make([]int, 3) var和make这两种方式有什么区别？ 第一种var的方式定义变量，如果逃逸分析之后，可以确认分配在栈上，那么就在栈上分配24个字节，如果逃逸到堆上，那么调用newobject函数进行类型分析。 第二种make方式略有不同，如果逃逸分析之后，确认分配在栈上，那么直接在栈上分配24字节，如果逃逸到堆上，会调用makeslice来分配变量。 6.2、变量本身 type slice struct { array unsafe.Pointer // 管理的内存块首地址 len int // 动态数组实际使用大小 cap int // 动态数据内存大小 } 变量本身占用24字节。 我们看到无论是var声明定义的slice变量，还是make创建的slice变量，slice管理结构是已经分配出来的，也就是struct slice结构 6.3、nil赋值 本身的 24 字节的内存块被置 0。 6.4、nil判断 那么什么样的slice被认为是nil？ 指针为0，也就是这个动态数组没有实际数据的时候。 问题：仅判断指针？对len和cap两个字段不做判断吗？ package main import \"unsafe\" type sliceType struct { pdata unsafe.Pointer len int cap int } func main() { var slice []byte ((*sliceType)(unsafe.Pointer(\u0026slice))).len = 0x3 ((*sliceType)(unsafe.Pointer(\u0026slice))).cap = 0x4 if slice != nil { println(\"not nil\") } else { println(\"nil\") } } // Output: nil ","date":"2022-03-07","objectID":"/2022/03/nil/:2:6","tags":["nil"],"title":"Nil的使用场景","uri":"/2022/03/nil/"},{"categories":["月霜天的小随笔"],"content":"三、总结 1、变量就是绑定到某个内存块上的名称 2、变量定义分配的内存是置零分配的 3、不是所有的类型能够赋值 nil，并且和 nil 进行对比判断。只有 指针、channel、函数、interface、map、slice 这 6 种类型 4、channel、map类型的变量需要make才能使用 5、slice在声明后可以使用，是因为struct slice核心结构在定义的时候就已经分配出来了。 6、slice是24字节，interface是16字节，其他的都是8字节 7、这 6 种类型和 nil 进行比较判断本质上都是和变量本身做判断，slice 是判断管理结构的第一个指针字段，map，channel 本身就是指针 ","date":"2022-03-07","objectID":"/2022/03/nil/:3:0","tags":["nil"],"title":"Nil的使用场景","uri":"/2022/03/nil/"},{"categories":["月霜天的小随笔"],"content":"一、goroutine 进程：可并发执行的程序在某个数据集合上的一次计算活动，也是操作系统进行资源分配和调度的基本单位。每个进程都有自己的独立空间，不同进程通过进程间通信来通信。 线程：从属于进程，是程序的实际执行者，一个进程可以有多个线程，每个线程会共享父进程的资源。 协程：用户态的轻量级线程，协程的调度完全由用户控制。 很明显，在并发编程中，为每个任务创建一个线程会消耗大量的资源，如高内存占用，高cpu调度。 在Go中，使用goroutine让一组可复用的函数运行在一组线程上，即使协程阻塞，该线程的其他协程也会被runtime调度。goroutine非常轻量，一个goroutine只占用几KB，这就能运行大量的goroutine，支持高并发。 ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:1:0","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"二、GPM模型 在Go中，设计了GPM模型 G：goroutine协程 P：processor处理器 M：thread线程 1、全局队列（Global queue）：全局存放等待运行的G 2、P的本地队列：存放等待运行的G，不超过256。新建G时，G优先加入本地队列，如果队列满了，把本地队列中的一半移动到全局队列中 3、P列表：所有的P都在程序启动时创建，并保存在数组中，最多有GOMAXPROCS个 4、M：线程运行任务需要获取P，从P的本地队列中获取G，P队列为空时，会尝试从全局队列中拿一批G放到P的本地队列，或从其他P的本地队列偷一半放到自己的本地队列。 goroutine调度器和OS调度器通过M结合起来，每一个M代表一个内核线程，OS调度器负责把内核线程放到CPU上执行。 ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:2:0","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"2.1、P和M的数量 1、P的数量 启动时由环境变量GOMAXPROCS或者通过runtime.GOMAXPROCS()确定。这就代表程序执行时最多有GOMAXPROCS个goroutine在同时运行。 2、M的数量 go本身限制：程序启动时，会设置M的最大数量，默认是10000。sched.maxmcount = 10000 runtime/debug包中SetMaxThreads函数可以设置M的最大数量 一个M阻塞了，会创建新的M 3、P数量和M数量的关系 P与M的没有数量关系，一个M阻塞了，P就会去创建或切换另一个M，所以即使P=1，也有可能创建多个M ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:2:1","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"2.2、何时创建P和M 1、P何时创建 在确定P的最大数量后，运行时程序会根据数量创建P 2、M何时创建 没有足够的M来关联P并运行G。比如所有的M都被阻塞了，而P中有很多就绪任务，就会去寻找空闲的M，如果没有空闲的，就会去新建M ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:2:2","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"2.3、调度器设计策略 1、复用线程 避免频繁的创建、销毁线程 work stealing机制 当线程M没有可以执行的G时，尝试从其他线程绑定的P中偷取G，而不是销毁线程 hand off机制 当线程M因为G进行系统调用阻塞时，线程M释放绑定的P，把P移交给其他空闲的线程执行 2、抢占 一个goroutine最多占用cpu 10ms，防止其他goroutine被饿死 ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:2:3","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"2.4、go func() 调度过程 1、通过go func()创建一个goroutine 2、新创建的G会先保存在P的本地队列，如果P的本地队列满了，就会存放在全局队列中 3、G只能在M中运行，一个M只能有一个P。M会从P的本地队列读取一个可执行的G来执行，如果本地队列为空，就会想其他的MP中偷取一个可执行的G来执行。 4、一个M调度G的过程是循环过程 5、当M执行某个G发生syscall或其他阻塞操作，M会阻塞，如果当前有一些G在执行，runtime会把这个线程M从P中摘除(detach)，然后再创建一个新的线程 6、当M系统调用结束，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程M就会进入休眠状态，加入到空闲线程中，这个G会被放入全局队列中。 M0：程序启动后的编号为0的主线程，这个M对应的实例会在全局变量runtime.m0中，不需要在堆中分配，M0负责执行初始化操作和启动第一个G，在之后就和其他M一样 G0：启动每个M都会创建的第一个goroutine，G0仅用于负责调度的G，G0不指向任何可执行的函数。每个M都有自己的G0。在调度或系统调用时会使用G0的栈空间, 全局变量的G0是M0的G0。 ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:2:4","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"三、调度机制 Go0.x：基于单线程的调度 Go1.0：基于多线程的调度 Go1.1：基于任务窃取的调度 Go1.2-Go1.13：基于协作的抢占式调度 Go1.14：基于信号的抢占式调度 ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:3:0","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"3.1、基于协作的抢占式调度 goroutine有个字段stackguard0，当该字段被设置成StackPreempt，意味着当前goroutine发出了抢占请求，同时触发调度器抢占让出线程。 编译器会在调用函数前插入runtime.morestack，可能会调用runtime.newstack进行抢占 Go语言运行时会在垃圾回收暂停、系统监控发现goroutine运行超过10ms发出抢占请求 当发生函数调用时，调用runtime.newstack检查goroutine的stackguard0字段 如果stackguard0是StackPreempt，触发抢占让出线程 ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:3:1","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"3.2、基于信号的抢占式调度 Go程序启动时，会在runtime.sighandler方法注册并绑定SIGURG信号 func mstartm0() { initsig(false) } func initsig(preinit bool) { for i := uint32(0); i \u003c _NSIG; i++ { ... setsig(i, funcPC(sighandler)) } } 绑定相应的runtime.doSigPreempt抢占方法 func sighandler(sig uint32, info *siginfo, ctxt unsafe.Pointer, gp *g) { ... if sig == sigPreempt { doSigPreempt(gp, c) } } 同时在调度的系统监控runtime.sysmon调用retake方法处理： 抢占阻塞在系统调用的P 抢占运行时间过长的G 当符合条件时，会发送信号给M。M收到信号将会睡眠正在阻塞的G，调用绑定信号方法，并重新调度。 ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:3:2","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"3.3、为什么要抢占P package main import ( \"fmt\" \"runtime\" ) func main() { runtime.GOMAXPROCS(1) // 协程1 go func() { for {} }() // 协程2 go func() { fmt.Println(\"hello world\") }() select { } } 在Go1.13版本，是没有输出的。 在Go1.14版本，是能打印\"hello world\"的。 因为不抢占会被一直挂起(hang)。 ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:3:3","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"3.4、如何抢占 在runtime.retake方法，处理一下两种场景： 抢占阻塞在系统调用上的P 抢占运行时间过长的G func retake(now int64) uint32 { n := 0 lock(\u0026allpLock) for i := 0; i \u003c len(allp); i++ { _p_ := allp[i] if _p_ == nil { continue } pd := \u0026_p_.sysmontick s := _p_.status sysretake := false } unlock(\u0026allpLock) return uint32(n) } 首先会对allpLock加锁，可以防止发生变更。 然后对所有的P开始循环处理。 场景1 t := int64(_p_.syscalltick) if !sysretake \u0026\u0026 int64(pd.syscalltick) != t { pd.syscalltick = uint32(t) pd.syscallwhen = now continue } 如果在系统调用中超过sysmon ticj周期（至少20us），则会从系统调用中抢占P 场景2 if runqempty(_p_) \u0026\u0026 atomic.Load(\u0026sched.nmspinning)+atomic.Load(\u0026sched.npidle) \u003e 0 \u0026\u0026 pd.syscallwhen+10*1000*1000 \u003e now { continue } runqempty(_p_)判断p的任务队列是否为空，以此来检测有没有其他任务需要执行。 atomic.Load(\u0026sched.nmspinning)+atomic.Load(\u0026sched.npidle) \u003e 0判断是否存在空闲的P和正在进行调度窃取的P pd.syscallwhen+10*1000*1000 \u003e now会判断系统调用是否超过了10ms 完成条件判断后，就进入了抢占步骤 unlock(\u0026allpLock) incidlelocked(-1) if atomic.Cas(\u0026_p_.status, s, _Pidle) { n++ _p_.syscalltick++ handoffp(_p_) } incidlelocked(1) lock(\u0026allpLock) 解锁 减少闲置 M：需要在原子操作（CAS）之前减少闲置 M 的数量（假设有一个正在运行）。否则在发生抢夺 M 时可能会退出系统调用，递增 nmidle 并报告死锁事件。 修改P的状态为idle，以便交给其他M使用 抢占P和调度M：调用handoffp方法从系统调用或锁定的M中强占P，会由新的M接管这个P ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:3:4","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"四、实例 1、P上存在G1，M1获取P后执行G1，G1使用go func()创建了G2，G2会优先加入到P的本地队列 2、G1运行完后，M上运行的goroutine切换为G0，G0赋值调度协程的切换。从P的本地队列取G2，从G0切换到G2，开始运行G2。 3、假设P的本地队列能存储4个G，G2要创建6个G，前4个G（G3，G4，G5，G6）已经加入到P的本地队列中，P的本地队列满了 4、G2在创建G7时，发现本地队列满了，会把本地队列的前一半的G（G3，G4），还有新创建的G转移到全局队列 5、G2在创建G8时，P的本地队列没有满，会加入到本地队列中 6、M2绑定的P2的本地队列为空，会去从全局队列中拿一批G放到P2的本地队列。取的个数为 n=min(len(global queue))/GOMAXPROCS+1,cap(local queue)/2 7、加入G2一直在M1上运行，而M2运行完本地队列和全局队列的G，就会从M1的P中偷取一半的G放到自己的本地队列中执行 8、此时M1正在运行G2，M2正在运行G8。G8创建了G9后，发生了阻塞的系统调用，M2和P2会发生解绑，P2会执行如下判断：如果P2本地队列有G，全局队列有G或有空闲的M，P2都会唤醒一个M和它绑定，否则P2会加入到空闲P列表，等待M来获取可用的G 9、假如G8创建了G9，发生了非阻塞系统调用，M2和P2会解绑，但M2会记住P2，然后G8和M2进入系统调用状态，当G8和M2退出系统调用时，会尝试获取P2，如果无法获取，则获取空闲的P，如果没有，G8被标记为可运行状态，加入到全局队列，M2因没有P的绑定进入休眠状态。 ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:4:0","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"五、总结 Go调度本质是把大量的goroutine分配到少量线程上去执行，并利用多核并行，实现更强大的并发。 ","date":"2022-03-07","objectID":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/:5:0","tags":["golang","csp并发模型"],"title":"CSP并发模型","uri":"/2022/03/csp%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"},{"categories":["月霜天的小随笔"],"content":"在并发程序中，由于超时、取消操作或其他一些异常情况，往往需要通知其他goroutine，虽然可以使用channel来处理这些问题，但是会变得非常繁琐，而且不利于多级管理。 go使用Context来做解决方案。 ","date":"2022-03-07","objectID":"/2022/03/context/:0:0","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"1、Context接口 type Context interface { Deadline() (deadline time.Time, ok bool) Done() \u003c-chan struct{} Err() error Value(key interface{}) interface{} } Context接口包含4个方法 Deadline：返回绑定当前Context的任务被取消的截止时间，如果没有设置时间，ok=false Done：context任务被取消，返回一个信号struct{}，如果不被取消，返回nil Err：如果Done已经关闭，将返回非空的值表明任务结束的原因 Value：存储的键值对中当前key对应的值 ","date":"2022-03-07","objectID":"/2022/03/context/:1:0","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"2、emptyCtx emptyCtx其实就是一个int类型的变量，实现了Context接口。 如其名，就是一个没有设置超时时间，不能取消，也不能存储键值对的Context。 emptyCtx用来作为context的根结点。 type emptyCtx int func (*emptyCtx) Deadline() (deadline time.Time, ok bool) { return } func (*emptyCtx) Done() \u003c-chan struct{} { return nil } func (*emptyCtx) Err() error { return nil } func (*emptyCtx) Value(key interface{}) interface{} { return nil } 而我们通常不会直接使用emptyCtx，而是使用emptyCtx实例化的两个变量 var ( background = new(emptyCtx) todo = new(emptyCtx) ) func Background() Context { return background } func TODO() Context { return todo } Background：通常被用作主函数，初始化以及测试中，作为顶级的context TODO：不确定使用什么context时 ","date":"2022-03-07","objectID":"/2022/03/context/:2:0","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"3、valueCtx ","date":"2022-03-07","objectID":"/2022/03/context/:3:0","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"3.1、基础类型 type valueCtx struct { Context key, val interface{} } func (c *valueCtx) Value(key interface{}) interface{} { if c.key == key { return c.val } return c.Context.Value(key) } valueCtx利用了context类型的变量来表示父节点context，继承了父context的所有信息。 valueCtx携带了一个键值对，实现了Value方法，所以可以在context上获取key对应的值，如果context不存在，会沿着父context向上查找 ","date":"2022-03-07","objectID":"/2022/03/context/:3:1","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"3.2、实现方法 func WithValue(parent Context, key, val interface{}) Context { if key == nil { panic(\"nil key\") } if !reflectlite.TypeOf(key).Comparable() { panic(\"key is not comparable\") } return \u0026valueCtx{parent, key, val} } 向context中添加键值对，并不是直接在原context上直接添加，而是创建一个新的valueCtx，将键值对添加在子节点上。 ","date":"2022-03-07","objectID":"/2022/03/context/:3:2","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"4、cancelCtx ","date":"2022-03-07","objectID":"/2022/03/context/:4:0","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"4.1、基础类型 type canceler interface { cancel(removeFromParent bool, err error) Done() \u003c-chan struct{} } type cancelCtx struct { Context mu sync.Mutex done chan struct{} children map[canceler]struct{} err error } 和valueCtx类似，也有父context， 通道done用来传递关闭信号。 children存储了context节点下的子节点， err用于存储取消原因 func (c *cancelCtx) Value(key interface{}) interface{} { if key == \u0026cancelCtxKey { return c } return c.Context.Value(key) } func (c *cancelCtx) Done() \u003c-chan struct{} { c.mu.Lock() if c.done == nil { c.done = make(chan struct{}) } d := c.done c.mu.Unlock() return d } func (c *cancelCtx) Err() error { c.mu.Lock() err := c.err c.mu.Unlock() return err } ","date":"2022-03-07","objectID":"/2022/03/context/:4:1","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"4.2、实现方法 func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { c := newCancelCtx(parent) propagateCancel(parent, \u0026c) return \u0026c, func() { c.cancel(true, Canceled) } } newCancelCtx只是初始化了cancelCtx func newCancelCtx(parent Context) cancelCtx { return cancelCtx{Context: parent} } propagateCancel建立当前节点与父节点的取消逻辑 func propagateCancel(parent Context, child canceler) { done := parent.Done() if done == nil { return } select { case \u003c-done: child.cancel(false, parent.Err()) return default: } if p, ok := parentCancelCtx(parent); ok { p.mu.Lock() if p.err != nil { child.cancel(false, p.err) } else { if p.children == nil { p.children = make(map[canceler]struct{}) } p.children[child] = struct{}{} } p.mu.Unlock() } else { atomic.AddInt32(\u0026goroutines, +1) go func() { select { case \u003c-parent.Done(): child.cancel(false, parent.Err()) case \u003c-child.Done(): } }() } } 1、如果父context已经取消了，就直接返回，因为父节点不可能再被取消了 2、监听信号done，如果接收到了就通知子context取消 3、如果找到父context，就挂在父context上 4、如果没有找到父context，也就是自身是根context，就启动一个goroutine监听信号 而调用的cancel方法，其实就是关闭通道及设置原因 func (c *cancelCtx) cancel(removeFromParent bool, err error) { if err == nil { panic(\"context: internal error: missing cancel error\") } c.mu.Lock() if c.err != nil { c.mu.Unlock() return // already canceled } c.err = err if c.done == nil { c.done = closedchan } else { close(c.done) } for child := range c.children { child.cancel(false, err) } c.children = nil c.mu.Unlock() if removeFromParent { removeChild(c.Context, c) } } ","date":"2022-03-07","objectID":"/2022/03/context/:4:2","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"5、timerCtx ","date":"2022-03-07","objectID":"/2022/03/context/:5:0","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"5.1、基础类型 type timerCtx struct { cancelCtx timer *time.Timer deadline time.Time } func (c *timerCtx) Deadline() (deadline time.Time, ok bool) { return c.deadline, true } timer声明了一个定时器，用于发送截止时间 ","date":"2022-03-07","objectID":"/2022/03/context/:5:1","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"5.2、实现方法 func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) { if cur, ok := parent.Deadline(); ok \u0026\u0026 cur.Before(d) { return WithCancel(parent) } c := \u0026timerCtx{ cancelCtx: newCancelCtx(parent), deadline: d, } propagateCancel(parent, c) dur := time.Until(d) if dur \u003c= 0 { c.cancel(true, DeadlineExceeded) return c, func() { c.cancel(false, Canceled) } } c.mu.Lock() defer c.mu.Unlock() if c.err == nil { c.timer = time.AfterFunc(dur, func() { c.cancel(true, DeadlineExceeded) }) } return c, func() { c.cancel(true, Canceled) } } 大致和cancelCtx差不多，多了声明的定时器，用于发送截止时间。 而timerCtx.cancel有些不一样，是关闭定时器的。 func (c *timerCtx) cancel(removeFromParent bool, err error) { c.cancelCtx.cancel(false, err) if removeFromParent { removeChild(c.cancelCtx.Context, c) } c.mu.Lock() if c.timer != nil { c.timer.Stop() c.timer = nil } c.mu.Unlock() } 关于timerCtx还有一个方法 func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) } 与WithDeadline类似，只不过是创建了一个过期时间的context ","date":"2022-03-07","objectID":"/2022/03/context/:5:2","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"6、总结 context主要用于父子之间同步信号，本质上是一种协程调度方式 context是线程安全的，因为context本身不变 父context通知子context取消，但是不会干涉子任务的执行，也就是说context的取消机制是无侵入的 子context的取消是不会影响父context的 ","date":"2022-03-07","objectID":"/2022/03/context/:6:0","tags":["context"],"title":"Context控制goroutine并发运行","uri":"/2022/03/context/"},{"categories":["月霜天的小随笔"],"content":"beego 是一个快速开发 Go 应用的 HTTP 框架，可以用来快速开发 API、Web 及后端服务等各种应用，是一个 RESTful 的框架。 那么这种RESTfule路由到底是怎么实现的？带着这个疑问，我们来了解一下实现过程。 ","date":"2022-03-07","objectID":"/2022/03/beego_router/:0:0","tags":["beego","router"],"title":"Beego路由---前缀树","uri":"/2022/03/beego_router/"},{"categories":["月霜天的小随笔"],"content":"一、使用方法 package main import ( beego \"github.com/beego/beego/v2/server/web\" ) type MainController struct { beego.Controller } func (this *MainController) Get() { this.Ctx.WriteString(\"Hello world\") } func main() { beego.Router(\"/\", \u0026MainController{}) beego.Run() } 这个就是beego框架的简单使用。当然还有一些RESTful的使用，这里就不一一赘述了。 ","date":"2022-03-07","objectID":"/2022/03/beego_router/:1:0","tags":["beego","router"],"title":"Beego路由---前缀树","uri":"/2022/03/beego_router/"},{"categories":["月霜天的小随笔"],"content":"二、前缀树 Tire树，即字典树，又称单词查找树或键树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计和排序大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。 它的优点是：最大限度地减少无谓的字符串比较，查询效率比哈希表高。 Trie的核心思想是空间换时间。利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。 那么在字典树中搜索添加过的单词的步骤如下： 1、从根节点开始搜索 2、取得要查找单词的第一个字母，并根据该字母对应的字符路径向下搜索 3、字符路径指向的第二层节点上，根据第二个字母选择对应的字符路径向下继续搜索 4、一直向下搜索，如果单词搜索完成，找到的最后一个节点是叶子节点，说明字典树中存在这个单词，如果找到的不是叶子节点，说明单词不是字典树中添加过的单词。 ","date":"2022-03-07","objectID":"/2022/03/beego_router/:2:0","tags":["beego","router"],"title":"Beego路由---前缀树","uri":"/2022/03/beego_router/"},{"categories":["月霜天的小随笔"],"content":"三、beego的前缀树 ","date":"2022-03-07","objectID":"/2022/03/beego_router/:3:0","tags":["beego","router"],"title":"Beego路由---前缀树","uri":"/2022/03/beego_router/"},{"categories":["月霜天的小随笔"],"content":"1、数据结构 // 路由树 type ControllerRegister struct { routers map[string]*Tree } // 树节点结构 type Tree struct { // 路由前缀 prefix string // 完全路由信息 fixrouters []*Tree // if set, failure to match fixrouters search then search wildcard wildcard *Tree // if set, failure to match wildcard search leaves []*leafInfo } // 叶子节点结构 type leafInfo struct { // names of wildcards that lead to this leaf. eg, [\"id\" \"name\"] for the wildcard \":id\" and \":name\" wildcards []string // if the leaf is regexp regexps *regexp.Regexp runObject interface{} } ControllerRegister是所有路由的集合，里面的routers是方法的集合，key是http的方法：GET,POST,PUT等，Tree就是路由的前缀树了。 只不过这个路由前缀树和前缀树并不完全相同，还存在通配符/user/:id和/user/*这种情况，所以添加了wildcard用于匹配这两种情况。 ","date":"2022-03-07","objectID":"/2022/03/beego_router/:3:1","tags":["beego","router"],"title":"Beego路由---前缀树","uri":"/2022/03/beego_router/"},{"categories":["月霜天的小随笔"],"content":"2、路由注册 我们的路由由以下几种情况： 1、全匹配路由 /user/list 2、正则路由 /user/:id /user/:id()[0-9]+) /user/* 添加路由的时候，实际是调用了 func (p *ControllerRegister) addToRouter(method, pattern string, r *ControllerInfo) { if !p.cfg.RouterCaseSensitive { pattern = strings.ToLower(pattern) } if t, ok := p.routers[method]; ok { t.AddRouter(pattern, r) } else { t := NewTree() t.AddRouter(pattern, r) p.routers[method] = t } } 这个代码也简单明了，查找这个路由的方法树，如果存在就添加这个方法，如果不存在就新建方法树，然后再添加。 而调用的是AddRouter这个函数。 // 在路由树上添加路由，pattern是路由信息，runObject是执行方法 func (t *Tree) AddRouter(pattern string, runObject interface{}) { t.addseg(splitPath(pattern), runObject, nil, \"\") } 这个splitPath函数就是将路由以/分割。 而添加的过程当然是全匹配路由在fixrouters，正则路由在wildcard。 func (t *Tree) addseg(segments []string, route interface{}, wildcards []string, reg string) { if len(segments) == 0 { // 在叶子节点上添加方法 if reg != \"\" { t.leaves = append(t.leaves, \u0026leafInfo{runObject: route, wildcards: wildcards, regexps: regexp.MustCompile(\"^\" + reg + \"$\")}) } else { t.leaves = append(t.leaves, \u0026leafInfo{runObject: route, wildcards: wildcards}) } } else { seg := segments[0] // splitSegment起到的作用是分析seg // \"admin\" -\u003e false, nil, \"\" // \":id\" -\u003e true, [:id], \"\" // \"?:id\" -\u003e true, [: :id], \"\" : meaning can empty // \"🆔int\" -\u003e true, [:id], ([0-9]+) // \":name:string\" -\u003e true, [:name], ([\\w]+) // \":id([0-9]+)\" -\u003e true, [:id], ([0-9]+) // \":id([0-9]+)_:name\" -\u003e true, [:id :name], ([0-9]+)_(.+) // \"cms_:id_:page.html\" -\u003e true, [:id_ :page], cms_(.+)(.+).html // \"cms_:id(.+)_:page.html\" -\u003e true, [:id :page], cms_(.+)_(.+).html // \"*\" -\u003e true, [:splat], \"\" // \"*.*\" -\u003e true,[. :path :ext], \"\" . meaning separator iswild, params, regexpStr := splitSegment(seg) // if it's ? meaning can igone this, so add one more rule for it if len(params) \u003e 0 \u0026\u0026 params[0] == \":\" { t.addseg(segments[1:], route, wildcards, reg) params = params[1:] } // Rule: /login/*/access match /login/2009/11/access // if already has *, and when loop the access, should as a regexpStr if !iswild \u0026\u0026 utils.InSlice(\":splat\", wildcards) { iswild = true regexpStr = seg } // Rule: /user/:id/* if seg == \"*\" \u0026\u0026 len(wildcards) \u003e 0 \u0026\u0026 reg == \"\" { regexpStr = \"(.+)\" } if iswild { // ... 省略代码 // 主要是通配符判断逻辑 t.wildcard.addseg(segments[1:], route, append(wildcards, params...), reg+regexpStr) } else { var subTree *Tree // 这里添加的是全匹配路由 for _, sub := range t.fixrouters { if sub.prefix == seg { subTree = sub break } } if subTree == nil { subTree = NewTree() subTree.prefix = seg t.fixrouters = append(t.fixrouters, subTree) } subTree.addseg(segments[1:], route, wildcards, reg) } } } 主要就是判断给的路由数据是否存在通配符，然后分情况讨论。 最简单的就是普通路由了，直接添加到fixrouters里。 而正则路由根据各种情况，添加到wildcards里。 ","date":"2022-03-07","objectID":"/2022/03/beego_router/:3:2","tags":["beego","router"],"title":"Beego路由---前缀树","uri":"/2022/03/beego_router/"},{"categories":["月霜天的小随笔"],"content":"3、路由查找 很显然，是要先匹配fixrouters，如果没有对应的路由，再到wildcards中查找路由，返回对应的leaves里的方法。 查找路由的方法和插入的差不多，这里就不贴代码了。 ","date":"2022-03-07","objectID":"/2022/03/beego_router/:3:3","tags":["beego","router"],"title":"Beego路由---前缀树","uri":"/2022/03/beego_router/"},{"categories":["月霜天的小随笔"],"content":"四、总结 beego的路由对前缀树做了一点优化，按照/分割路由，把这部分放到前缀树的值中，减少了前缀树的深度，毕竟如果按照字符切分的话，前缀树会很深，而且对正则表现也不会友好。 ","date":"2022-03-07","objectID":"/2022/03/beego_router/:4:0","tags":["beego","router"],"title":"Beego路由---前缀树","uri":"/2022/03/beego_router/"},{"categories":["月霜天的小笔记"],"content":"在日常工作中，我们经常会用关键字go起一个goroutine。 但是在跑一段时间后，可能会遇到一些问题：当goroutine内的任务运行的太久，内存泄露，或一直阻塞，变成goroutine泄露等一些问题。 那么如何停止goroutine，就需要我们来了解了。 通常会有三种方法： 信号量 context 信号量+context ","date":"2021-07-27","objectID":"/2021/07/%E5%81%9C%E6%AD%A2goroutine%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/:0:0","tags":["goroutine","golang"],"title":"停止goroutine的几种方法","uri":"/2021/07/%E5%81%9C%E6%AD%A2goroutine%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"信号量 1、借助于channel的close方法关闭通道来关闭协程 func main() { ch := make(chan int, 1) go func() { for { v,ok := \u003c- ch if !ok { fmt.Println(\"结束goroutine\") return } fmt.Println(v) } }() ch \u003c- 1 ch \u003c- 2 close(ch) time.Sleep(time.Second) } 当然，也可以使用for range的特性 go func() { for v := range ch { fmt.Println(v) } }() 2、使用信号量进行通知 func main() { ch := make(chan int, 1) done := make(chan struct{}) go func() { for { select { case \u003c-ch: case \u003c-done: close(ch) fmt.Println(\"关闭channel\") return } } }() ch \u003c- 1 ch \u003c- 2 done \u003c- struct{}{} time.Sleep(time.Second) } 在上述代码中，声明变量done，类型是channel，作为信号量处理goroutine的关闭。 利用for-loop结合select关键字来监听，处理相关的逻辑后，再调用close来真正关闭channel。 ","date":"2021-07-27","objectID":"/2021/07/%E5%81%9C%E6%AD%A2goroutine%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/:1:0","tags":["goroutine","golang"],"title":"停止goroutine的几种方法","uri":"/2021/07/%E5%81%9C%E6%AD%A2goroutine%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"context 可以借助上下文Context来做goroutine的控制和关闭。 func main() { ch := make(chan int, 1) ctx,cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() go func() { for { select { case \u003c-ch: case \u003c-ctx.Done(): close(ch) fmt.Println(\"关闭channel\") return } } }() ch \u003c- 1 ch \u003c- 2 time.Sleep(time.Second * 2) } 在context中，使用ctx.Done获取一个只读的channel，标识当前的channel是否关闭，可能是到期，也可能是被取消。 ","date":"2021-07-27","objectID":"/2021/07/%E5%81%9C%E6%AD%A2goroutine%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/:2:0","tags":["goroutine","golang"],"title":"停止goroutine的几种方法","uri":"/2021/07/%E5%81%9C%E6%AD%A2goroutine%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"关闭其他goroutine 我想在 goroutineA 里去停止 goroutineB，有办法吗？ 答案是不能，因为在 Go 语言中，goroutine 只能自己主动退出，一般通过 channel 来控制，不能被外界的其他 goroutine 关闭或干掉，也没有 goroutine 句柄的显式概念。 question: is it possible to a goroutine immediately stop another goroutine? 在 Go issues 中也有人提过类似问题，Dave Cheney 给出了一些思考： 如果一个 goroutine 被强行停止了，它所拥有的资源会发生什么？堆栈被解开了吗？defer 是否被执行？ 如果执行 defer，该 goroutine 可能可以继续无限期地生存下去。 如果不执行 defer，该 goroutine 原本的应用程序系统设计逻辑将会被破坏，这肯定不合理。 如果允许强制停止 goroutine，是要释放所有东西，还是直接把它从调度器中踢出去，你想通过此解决什么问题？ 这都是值得深思的，另外一旦放开这种限制。作为程序员，你维护代码。很有可能就不知道 goroutine 的句柄被传到了哪里，又是在何时何地被人莫名其妙关闭，非常糟糕… ","date":"2021-07-27","objectID":"/2021/07/%E5%81%9C%E6%AD%A2goroutine%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/:3:0","tags":["goroutine","golang"],"title":"停止goroutine的几种方法","uri":"/2021/07/%E5%81%9C%E6%AD%A2goroutine%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"其他方法 main函数退出，goroutine也会退出 runtime.Goexit()方法可以使goroutine退出 ","date":"2021-07-27","objectID":"/2021/07/%E5%81%9C%E6%AD%A2goroutine%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/:4:0","tags":["goroutine","golang"],"title":"停止goroutine的几种方法","uri":"/2021/07/%E5%81%9C%E6%AD%A2goroutine%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"总结 goroutine 的设计就是这样的，包括像 goroutine+panic+recover 的设计也是遵循这个原理，因此也有的 Go 开发者总是会误以为跨 goroutine 能有 recover 接住… 记住，在 Go 语言中每一个 goroutine 都需要自己承担自己的任何责任，这是基本原则。 ","date":"2021-07-27","objectID":"/2021/07/%E5%81%9C%E6%AD%A2goroutine%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/:5:0","tags":["goroutine","golang"],"title":"停止goroutine的几种方法","uri":"/2021/07/%E5%81%9C%E6%AD%A2goroutine%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/"},{"categories":["月霜天的GO"],"content":"在sync包下面经常出现\"XXX must not be copied after first use.\"，然后下面就有一个noCopy。 ","date":"2021-07-19","objectID":"/2021/07/nocopy%E6%9C%BA%E5%88%B6/:0:0","tags":["源码解析","golang"],"title":"no copy机制","uri":"/2021/07/nocopy%E6%9C%BA%E5%88%B6/"},{"categories":["月霜天的GO"],"content":"什么是noCopy ? 如果结构体对象包含指针字段，当该对象被拷贝时，会使得两个对象中的指针字段变得不再安全。 type S struct { f1 int f2 *s } type s struct { name string } func main() { mOld := S{ f1: 0, f2: \u0026s{name: \"mike\"}, } mNew := mOld //拷贝 mNew.f1 = 1 mNew.f2.name = \"jane\" fmt.Println(mOld.f1, mOld.f2) //输出：0 \u0026{jane} } 修改nNew字段的值会把mOld字段的值修改掉，这就会引发安全问题。 ","date":"2021-07-19","objectID":"/2021/07/nocopy%E6%9C%BA%E5%88%B6/:1:0","tags":["源码解析","golang"],"title":"no copy机制","uri":"/2021/07/nocopy%E6%9C%BA%E5%88%B6/"},{"categories":["月霜天的GO"],"content":"如果保证noCopy ","date":"2021-07-19","objectID":"/2021/07/nocopy%E6%9C%BA%E5%88%B6/:2:0","tags":["源码解析","golang"],"title":"no copy机制","uri":"/2021/07/nocopy%E6%9C%BA%E5%88%B6/"},{"categories":["月霜天的GO"],"content":"runtime checking copy检查 func main() { var a strings.Builder a.Write([]byte(\"a\")) b := a b.Write([]byte(\"b\")) } // 运行报错： panic: strings: illegal use of non-zero Builder copied by value 报错信息来自于strings.Builder的copyCheck // Do not copy a non-zero Builder. type Builder struct { addr *Builder // of receiver, to detect copies by value buf []byte } func (b *Builder) Write(p []byte) (int, error) { b.copyCheck() b.buf = append(b.buf, p...) return len(p), nil } func (b *Builder) copyCheck() { if b.addr == nil { // This hack works around a failing of Go's escape analysis // that was causing b to escape and be heap allocated. // See issue 23382. // TODO: once issue 7921 is fixed, this should be reverted to // just \"b.addr = b\". b.addr = (*Builder)(noescape(unsafe.Pointer(b))) } else if b.addr != b { panic(\"strings: illegal use of non-zero Builder copied by value\") } } 在Builder中，addr是一个指向自身的指针。如果a复制给b，那么a和b本身是不同的对象。因此b.addr实际上是指向a，就会导致panic. sync.Cond中的copy检查 type copyChecker uintptr func (c *copyChecker) check() { if uintptr(*c) != uintptr(unsafe.Pointer(c)) \u0026\u0026 !atomic.CompareAndSwapUintptr((*uintptr)(c), 0, uintptr(unsafe.Pointer(c))) \u0026\u0026 uintptr(*c) != uintptr(unsafe.Pointer(c)) { panic(\"sync.Cond is copied\") } } 当被拷贝后，uintptr(*c)和uintptr(unsafe.Pointer(c))的值是不同的，通过uint对象的原子比较方法CompareAndSwapUintptr将返回false，它证明了对象a被copy过，从而调用panic保护sync.Cond不被复制。 ","date":"2021-07-19","objectID":"/2021/07/nocopy%E6%9C%BA%E5%88%B6/:2:1","tags":["源码解析","golang"],"title":"no copy机制","uri":"/2021/07/nocopy%E6%9C%BA%E5%88%B6/"},{"categories":["月霜天的GO"],"content":"go vet checking 上面的两个都是在程序编译时，runtime进行检查的。 // noCopy may be embedded into structs which must not be copied // after the first use. // // See https://golang.org/issues/8005#issuecomment-190753527 // for details. type noCopy struct{} // Lock is a no-op used by -copylocks checker from `go vet`. func (*noCopy) Lock() {} func (*noCopy) Unlock() {} sync包下的其他的对象如Pool、WaitGroup、Mutex、Map等，它们都存在copy检查机制。 通过go vet进行copy检查。 那么我们可以参考Go源码的noCopy，实现调用不能拷贝 type noCopy struct{} func (*noCopy) Lock() {} func (*noCopy) Unlock() {} type MyType struct { noCopy noCopy ... } ","date":"2021-07-19","objectID":"/2021/07/nocopy%E6%9C%BA%E5%88%B6/:2:2","tags":["源码解析","golang"],"title":"no copy机制","uri":"/2021/07/nocopy%E6%9C%BA%E5%88%B6/"},{"categories":["月霜天的GO"],"content":"我们通常用golang来构建高并发场景下的应用，但是由于golang内建的GC机制会影响应用的性能，为了减少GC，golang提供了对象重用的机制，也就是sync.Pool对象池。sync.Pool是可伸缩的，并发安全的。其大小仅受限于内存的大小，可以被看作是一个存放可重用对象的值的容器。 设计的目的是存放已经分配的但是暂时不用的对象，在需要用到的时候直接从pool中取。 任何存放区其中的值可以在任何时候被删除而不通知，在高负载下可以动态的扩容，在不活跃时对象池会收缩。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/:0:0","tags":["源码解析","sync"],"title":"并发编程之sync.Pool","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/"},{"categories":["月霜天的GO"],"content":"使用方法 func main() { // 初始化Pool实例New // New方法声明Pool元素创建的方法 bufferpool := \u0026sync.Pool{ New: func() interface{} { println(\"Create new instance\") return struct{}{} }, } // 申请对象 // Get方法会返回Pool已经存在的对象，如果没有，就走慢路径，也就是调用初始化的时候定义的New方法来初始化一个对象 buffer := bufferpool.Get() // 释放对象 // 使用对象后，调用Put方法声明把对象放回池子。 // 这个调用之后仅仅是把这个对象放回池子，池子里的对象什么时候真正释放外界不清楚，不受外界控制。 bufferpool.Put(buffer) } ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/:1:0","tags":["源码解析","sync"],"title":"并发编程之sync.Pool","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/"},{"categories":["月霜天的GO"],"content":"Pool结构体 // A Pool must not be copied after first use. type Pool struct { noCopy noCopy // 数组，对应每个P，数量和P的数量保持一致 local unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal localSize uintptr // size of the local array // GC到时，victim和victimSize分别接管local和localSize // victim 的目的是为了减少GC后冷启动导致的性能抖动，让分配对象更加平滑 victim unsafe.Pointer // local from previous cycle victimSize uintptr // size of victims array // New optionally specifies a function to generate // a value when Get would otherwise return nil. // It may not be changed concurrently with calls to Get. New func() interface{} } // poolLocal管理Pool池里cache元素的关键结构，Pool.local指向这个类型的数组， type poolLocal struct { poolLocalInternal // Prevents false sharing on widespread platforms with // 128 mod (cache line size) = 0 . // 把poolLocal填充至128字节对齐，避免false sharing引起的性能问题 pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte } // 管理cache的内部结构，跟每个P对应，操作无须加锁 type poolLocalInternal struct { // 每个P的私有，使用时无需加锁 private interface{} // Can be used only by the respective P. // 双链表结构，用于挂接cache元素 shared poolChain // Local P can pushHead/popHead; any P can popTail. } 这里的poolChain是一个双链表结构，里面包含了头插、头出、尾出的方法。 我们注意到Pool里是没有锁的，但是却实现了并发安全，这里我们详细看一下实现 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/:2:0","tags":["源码解析","sync"],"title":"并发编程之sync.Pool","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/"},{"categories":["月霜天的GO"],"content":"pin func (p *Pool) pin() (*poolLocal, int) { // 把G锁住在当前M（声明当前M不能被抢占），返回M绑定的P的ID pid := runtime_procPin() // In pinSlow we store to local and then to localSize, here we load in opposite order. // Since we've disabled preemption, GC cannot happen in between. // Thus here we must observe local at least as large localSize. // We can observe a newer/larger local, it is fine (we must observe its zero-initialized-ness). s := atomic.LoadUintptr(\u0026p.localSize) // load-acquire l := p.local // load-consume if uintptr(pid) \u003c s { return indexLocal(l, pid), pid } return p.pinSlow() } // 一般是Pool第一次调用Get的时候才会走进来（每个 P 的第一次调用） // 把Pool注册进allPools数组； // Pool.local 数组按照P的个数(cpu的个数)进行分配 func (p *Pool) pinSlow() (*poolLocal, int) { // Retry under the mutex. // Can not lock the mutex while pinned. // G-M先解锁 runtime_procUnpin() // 以下逻辑在全局锁allPoolsMu内 allPoolsMu.Lock() defer allPoolsMu.Unlock() // 获取当前G-M-P，P的id pid := runtime_procPin() // poolCleanup won't be called while we are pinned. s := p.localSize l := p.local if uintptr(pid) \u003c s { return indexLocal(l, pid), pid } if p.local == nil { // 把自己注册进allPools数组 allPools = append(allPools, p) } // If GOMAXPROCS changes between GCs, we re-allocate the array and lose the old one. // P的个数 size := runtime.GOMAXPROCS(0) // local数组的大小等于P的个数 local := make([]poolLocal, size) atomic.StorePointer(\u0026p.local, unsafe.Pointer(\u0026local[0])) // store-release atomic.StoreUintptr(\u0026p.localSize, uintptr(size)) // store-release return \u0026local[pid], pid } func indexLocal(l unsafe.Pointer, i int) *poolLocal { lp := unsafe.Pointer(uintptr(l) + uintptr(i)*unsafe.Sizeof(poolLocal{})) return (*poolLocal)(lp) } runtime_procPin是procPin的一层封装 func procPin() int { _g_ := getg() mp := _g_.m mp.locks++ return int(mp.p.ptr().id) } procPin函数目的是为了当前G被抢占了执行权限（也就是说，当前G就在当前M上不走了）， 这里的核心实现是mp.locks++操作，在newstack里会对此条件进行判断 if preempt { // 已经打了抢占标识，但还需要判断条件满足才能出让执行权 if !canPreemptM(thisg.m) { // Let the goroutine keep running for now. // gp-\u003epreempt is set, so it will be preempted next time. gp.stackguard0 = gp.stack.lo + _StackGuard gogo(\u0026gp.sched) // never return } } func canPreemptM(mp *m) bool { return mp.locks == 0 \u0026\u0026 mp.mallocing == 0 \u0026\u0026 mp.preemptoff == \"\" \u0026\u0026 mp.p.ptr().status == _Prunning } 这里的流程：禁止抢占GC-\u003e寻找偏移量-\u003e越界检查-\u003e返回poolLocal或加锁重建pool，并添加到allPool中。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/:3:0","tags":["源码解析","sync"],"title":"并发编程之sync.Pool","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/"},{"categories":["月霜天的GO"],"content":"放回Put // Put adds x to the pool. func (p *Pool) Put(x interface{}) { if x == nil { return } // G-M锁定 l, _ := p.pin() if l.private == nil { // Fast path：放回x到private l.private = x x = nil } if x != nil { // 放到双向链表 l.shared.pushHead(x) } runtime_procUnpin() } 放入流程 1、如果x为空，直接返回 2、获取localPool 3、如果private为空，把x放回private，并且把x置nil 4、如果x不为nil，将x放到pool的shared双向链表中 总结来说，优先放入private，后面再放入shared空间 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/:4:0","tags":["源码解析","sync"],"title":"并发编程之sync.Pool","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/"},{"categories":["月霜天的GO"],"content":"取出Get func (p *Pool) Get() interface{} { l, pid := p.pin() // fast path：从private去除缓存元素 x := l.private l.private = nil if x == nil { // Try to pop the head of the local shard. We prefer // the head over the tail for temporal locality of // reuse. // 从shared队列中获取，share的度量在Get获取，在Put投递 x, _ = l.shared.popHead() if x == nil { // 尝试从其他P的队列中获取元素，或尝试从victim cache取元素 x = p.getSlow(pid) } } // 解除锁定 runtime_procUnpin() // slow path：初始化对象 if x == nil \u0026\u0026 p.New != nil { x = p.New() } return x } func (p *Pool) getSlow(pid int) interface{} { // See the comment in pin regarding ordering of the loads. size := atomic.LoadUintptr(\u0026p.localSize) // load-acquire locals := p.local // load-consume // Try to steal one element from other procs. // 从其他P中获取local for i := 0; i \u003c int(size); i++ { l := indexLocal(locals, (pid+i+1)%int(size)) if x, _ := l.shared.popTail(); x != nil { return x } } // 从victim中取出对象 // Try the victim cache. We do this after attempting to steal // from all primary caches because we want objects in the // victim cache to age out if at all possible. size = atomic.LoadUintptr(\u0026p.victimSize) if uintptr(pid) \u003e= size { return nil } locals = p.victim l := indexLocal(locals, pid) if x := l.private; x != nil { l.private = nil return x } for i := 0; i \u003c int(size); i++ { l := indexLocal(locals, (pid+i)%int(size)) if x, _ := l.shared.popTail(); x != nil { return x } } // Mark the victim cache as empty for future gets don't bother // with it. atomic.StoreUintptr(\u0026p.victimSize, 0) return nil } 取出流程 1、获取poolLocal 2、从private中取出缓存元素 3、如果取出的元素为nil，则从shared中获取缓存元素 4、如果还为空，则从其他P的队列中取出元素 5、如果都取不到，则调用New方法初始化一个新的元素。 总结来说，优先从private空间拿，再从shared空间拿，还没有就从其他的poolLocal的shared空间拿，如果还没有就New一个返回。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/:5:0","tags":["源码解析","sync"],"title":"并发编程之sync.Pool","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/"},{"categories":["月霜天的GO"],"content":"定时清理 func init() { // 在GC开始时，gcStart调用clearpools函数，也就是说每一轮GC都会对所有的Pool做清理工作 runtime_registerPoolCleanup(poolCleanup) } func poolCleanup() { // 清理oldPools上的victim的元素 for _, p := range oldPools { p.victim = nil p.victimSize = 0 } // Move primary cache to victim cache. // 把local cache迁移到victim上 // 这样就不至于让GC把所有的Pool都清空了，可以防止抖动 for _, p := range allPools { p.victim = p.local p.victimSize = p.localSize p.local = nil p.localSize = 0 } // The pools with non-empty primary caches now have non-empty // victim caches and no pools have primary caches. oldPools, allPools = allPools, nil } 在每次GC时，把local移到victim中。 而runtime_registerPoolCleanup函数的具体实现在runtime/mgc.go中 func sync_runtime_registerPoolCleanup(f func()) { poolcleanup = f } func clearpools() { // clear sync.Pools if poolcleanup != nil { poolcleanup() } ... } ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/:6:0","tags":["源码解析","sync"],"title":"并发编程之sync.Pool","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/"},{"categories":["月霜天的GO"],"content":"问题 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/:7:0","tags":["源码解析","sync"],"title":"并发编程之sync.Pool","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/"},{"categories":["月霜天的GO"],"content":"1、为什么用Pool，而不是在运行时直接实例化对象？ 原因：Go的内存释放是由runtime来自动处理，有GC过程 举个栗子 package main import ( \"fmt\" \"sync\" \"sync/atomic\" ) // 用来统计实例真正创建的次数 var numCalcsCreated int32 // 创建实例的函数 func createBuffer() interface{} { // 这里要注意下，非常重要的一点。这里必须使用原子加，不然有并发问题； atomic.AddInt32(\u0026numCalcsCreated, 1) buffer := make([]byte, 1024) return \u0026buffer } func main() { // 创建实例 bufferPool := \u0026sync.Pool{ New: createBuffer, } // 多 goroutine 并发测试 numWorkers := 1024 * 1024 var wg sync.WaitGroup wg.Add(numWorkers) for i := 0; i \u003c numWorkers; i++ { go func() { defer wg.Done() // 申请一个 buffer 实例 buffer := bufferPool.Get() // buffer := createBuffer() _ = buffer.(*[]byte) // 释放一个 buffer 实例 defer bufferPool.Put(buffer) }() } wg.Wait() fmt.Printf(\"%d buffer objects were created.\\n\", numCalcsCreated) } // Output: 7 buffer objects were created. 8 buffer objects were created. 多次运行会出现不同的结果。 创建Pool实例的时候，只要求填充了New函数，而没有声明或限制Pool的大小。 如果不用pool来申请，而是直接变量声明的方式,会有1024*1024个对象生成。 这就是复用对象。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/:7:1","tags":["源码解析","sync"],"title":"并发编程之sync.Pool","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/"},{"categories":["月霜天的GO"],"content":"2、sync.Pool是并发安全吗？ A Pool is safe for use by multiple goroutines simultaneously. 当然并发安全。 因为sync.Pool只是本身的Pool数据结构并发安全，并不是说Pool.New函数一定线程安全。 Pool.New函数可能会被并发调用。 如果把atomic.AddInt32(\u0026numCalcsCreated, 1)改成numCalcsCreated++，然后用go run -race main.go命令检查一下，会报出告警。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/:7:2","tags":["源码解析","sync"],"title":"并发编程之sync.Pool","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/"},{"categories":["月霜天的GO"],"content":"3、为什么sync.Pool不适合用于像socket长连接或数据库连接池？ Pool池里的元素随时可能释放掉，释放策略完全由runtime内部管理 Get获取到的对象元素可能是刚创建的，也可能是之前创建好cache住的，使用者无法区分 Pool池里面的元素个数无法知道 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/:7:3","tags":["源码解析","sync"],"title":"并发编程之sync.Pool","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/"},{"categories":["月霜天的GO"],"content":"总结 sync.Pool本质用途是增加临时对象的重用率，减少GC负担。 1、如果不是Pool.Get申请的对象，调用了Put，会如何？ Pool池中里的就不是单一的对象元素，取出的对象类型需要业务自己判断 2、为什么Get出的对象还要Put放回去？ 通常是defer Put这种形式保证释放元素放回池子。 Get出的对象如果不Put放回去，会被GC释放，就不能复用临时对象了 3、Pool本身允许复制后使用吗？ 不允许，因为有noCopy，但是可以编译通过。 因为copy之后，对于同一个Pool里面的cache对象，就有了2个对象来源。 Pool里面的无锁设计的基础是多个goroutine不会操作到同一个数据结构，Pool拷贝后就不能保证这一点了。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/:8:0","tags":["源码解析","sync"],"title":"并发编程之sync.Pool","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.pool/"},{"categories":["月霜天的GO"],"content":"golang原生的map是不支持并发，而在sync/map是线程安全的，可以并发读写，适用于读多写少的场景。 sync.Map是Go map[interface{}]interface{}，它对两种常用的场景进行了优化： 1、entry只写一次，但读很多次，比如在只增长的缓存中 2、多个goroutine读写、更新entry互不干扰 在这两种情况下，使用sync.Map比map加互斥锁性能要更好。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/:0:0","tags":["源码解析","sync"],"title":"并发编程之Map","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/"},{"categories":["月霜天的GO"],"content":"基本的数据结构 type Map struct { // 当涉及到脏数据（dirty）操作时，需要用锁 mu Mutex read atomic.Value // readOnly // dirty 包含部分map键值对，如果需要操作需要mutex获取锁 // 最后 dirty 中的元素会被全部提升到read里的map去 dirty map[interface{}]*entry // 计数器，用于记录read中没有的而在dirty中有的数据的数量。 // 也就是说如果read不包含这个数据，会从dirty中读取，misses+1 // 当misses的数量等于dirty的长度，就会将dirty中的数据迁移到read中 misses int } read包含了map内容中对并发访问是安全的部分（不管有没有mu）。读取字段本身总是安全的，但必须和mu一起存储。存储在read中的Entries可以在没有锁的情况下并发更新，但是更新之前删除的entry需要将entry复制到dirty，并且保证不被删除 dirty 包含部分map键值对，如果需要操作需要mutex获取锁，最后 dirty 中的元素会被全部提升到read里的map去 misses计数器，用于记录read中没有的而在dirty中有的数据的数量。也就是说如果read不包含这个数据，会从dirty中读取，misses+1，当misses的数量等于dirty的长度，就会将dirty中的数据迁移到read中 来看看dirty，是一个map类型的数据，键类型是interface{}，而值的类型是entry，其结构如下： type entry struct { p unsafe.Pointer // *interface{} } p指针指向entry的interface{}值 nil:entry已经被删除，并且m.dirty为空 expunged:entry已经被删除，但m.dirty不为空，也不在m.dirty 其他:entry是有效的，是个正常值，并记录在m.read.m[key],并且m.dirty != nil, 在 m.dirty[key]. 而read实际上指向readonly结构，相比于dirty多了个amended属性，用来表示是否存在key不存在于readonly，而存在于dirty。 type readOnly struct { m map[interface{}]*entry amended bool // true if the dirty map contains some key not in m. } 而操作这个sync.Map的方法有Load，Store，LoadOrStore，Delete，Range这几个方法。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/:1:0","tags":["源码解析","sync"],"title":"并发编程之Map","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/"},{"categories":["月霜天的GO"],"content":"查找Load func (m *Map) Load(key interface{}) (value interface{}, ok bool) { // 从read的map中查找 read, _ := m.read.Load().(readOnly) e, ok := read.m[key] // 如果没有找到，并且read.amended=true，说明dirty中有新数据，从dirty中查找，需要加锁 if !ok \u0026\u0026 read.amended { m.mu.Lock() // 在read中再检查一遍，防止加锁的时候dirty已经迁移到read中（二次检查） read, _ = m.read.Load().(readOnly) e, ok = read.m[key] if !ok \u0026\u0026 read.amended { e, ok = m.dirty[key] // 不管是否存在，记录misses+1，满足条件后将dirty中数据迁移到read中 m.missLocked() } m.mu.Unlock() } if !ok { return nil, false } return e.load() } func (e *entry) load() (value interface{}, ok bool) { p := atomic.LoadPointer(\u0026e.p) if p == nil || p == expunged { return nil, false } return *(*interface{})(p), true } func (m *Map) missLocked() { m.misses++ if m.misses \u003c len(m.dirty) { // misses小于dirty的长度，就不迁移数据 return } m.read.Store(readOnly{m: m.dirty}) m.dirty = nil m.misses = 0 } 读取的时候先从read中读取，如果read中不存在，则加锁从dirty中读取，并且使用missLocked使得misses+1。 如果计数器misses的数量大于dirty的长度，则把dirty的数据更新到read中。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/:2:0","tags":["源码解析","sync"],"title":"并发编程之Map","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/"},{"categories":["月霜天的GO"],"content":"新增和更新Store func (m *Map) Store(key, value interface{}) { // 从read map中如果能找到key，update read, _ := m.read.Load().(readOnly) if e, ok := read.m[key]; ok \u0026\u0026 e.tryStore(\u0026value) { return } // 上锁之后重新check一下read map的内容(二次读写) m.mu.Lock() read, _ = m.read.Load().(readOnly) // 场景一：如果在read中，而key对应的value标识是已删除（需要先在dirty中添加），更新这个值 if e, ok := read.m[key]; ok { if e.unexpungeLocked() { // The entry was previously expunged, which implies that there is a // non-nil dirty map and this entry is not in it. m.dirty[key] = e } e.storeLocked(\u0026value) // 场景二：如果不在read中，在dirty中，直接更新值 } else if e, ok := m.dirty[key]; ok { e.storeLocked(\u0026value) // 场景三：都不存在，那么把数据存在dirty中，并且修改read中的标识 } else { if !read.amended { // dirty没有新数据 // We're adding the first new key to the dirty map. // Make sure it is allocated and mark the read-only map as incomplete. // 从read中复制未删除的数据 m.dirtyLocked() // 更改状态 m.read.Store(readOnly{m: read.m, amended: true}) } m.dirty[key] = newEntry(value) // 加入dirty中 } m.mu.Unlock() } map的并发读写容易出问题，是因为存值、删除、取值的过程中存在扩容的过程。如果不对map进行修改就能提高执行效率。 所以read和dirty使用的map类型就是map[interface{}]*entry，值是一个指针，通过对指针的操作来改变值的状态，而不是直接删除或赋值。 而Stroe第一步，如果key在read中存在，那么通过tryStore方法来修改值 func (e *entry) tryStore(i *interface{}) bool { for { p := atomic.LoadPointer(\u0026e.p) if p == expunged { return false } if atomic.CompareAndSwapPointer(\u0026e.p, p, unsafe.Pointer(i)) { return true } } } 这里使用了CAS，乐观锁。相当于对map中每个已经存在的值的修改使用乐观锁，相比于对整个map使用锁来说，提高了效率。 Store第二步，如果没有更新成功或不在read中，则按照逻辑继续往下走。 在read中，没有更新成功，是因为值类型被标记为已删除，那么就在dirty中添加这个键值对 如果不在dirty，那么在dirty中更新值 如果不在dirty中，那么在dirty中存储键值对，如果dirty相比于read没有新的数据，那么dirtyLocked方法将read中的数据保存进dirty中，并且修改read中的状态amended 由于map[interface{}]*entry是一个指针，对read里的值修改时，dirty中的值也会被修改，因为两个指向的是同一个对象。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/:3:0","tags":["源码解析","sync"],"title":"并发编程之Map","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/"},{"categories":["月霜天的GO"],"content":"删除Delete func (m *Map) Delete(key interface{}) { read, _ := m.read.Load().(readOnly) e, ok := read.m[key] if !ok \u0026\u0026 read.amended { // 不存在read中，并且dirty有新数据 m.mu.Lock() read, _ = m.read.Load().(readOnly) e, ok = read.m[key] if !ok \u0026\u0026 read.amended { delete(m.dirty, key) // 加锁删除dirty的数据 } m.mu.Unlock() } if ok { // 在read中存在key e.delete() } } 删除操作比较简单 如果在read中，直接删除 如果不在read中，并且dirty没有新数据，直接返回 如果不在read中，并且dirty有新数据，那么就去dirty中删除 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/:4:0","tags":["源码解析","sync"],"title":"并发编程之Map","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/"},{"categories":["月霜天的GO"],"content":"其他 LoadOrStore和Range这两个方法的逻辑大体和Load和Stroe类似。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/:5:0","tags":["源码解析","sync"],"title":"并发编程之Map","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/"},{"categories":["月霜天的GO"],"content":"总结 1、空间换时间：通过两个冗余的数据结构（read、write），减小锁对性能的影响。 2、读操作使用read，写操作使用dirty，避免读写冲突。 3、动态调整：通过misses值，避免dirty数据过多。 4、双检查机制：避免在非原子操作时产生数据错误。 5、延迟删除机制：删除一个键值只是先打标记，只有等提升dirty（复制到read中，并清空自身）时才清理删除的数据。 6、优先从read中读、改和删除，因为对read的操作不用加锁，大大提升性能。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/:6:0","tags":["源码解析","sync"],"title":"并发编程之Map","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.map/"},{"categories":["月霜天的GO"],"content":"读写锁是基于互斥锁Mutex实现的读写互斥锁，一个goroutine可以持有多个读锁或一个写锁，同一时刻只能同时持有读锁或写锁。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/:0:0","tags":["源码解析","sync"],"title":"并发编程之读写锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["月霜天的GO"],"content":"RWMutex结构体 type RWMutex struct { w Mutex // held if there are pending writers // 互斥锁 // 写和读锁信号 writerSem uint32 // semaphore for writers to wait for completing readers readerSem uint32 // semaphore for readers to wait for completing writers // 读锁计数器 readerCount int32 // number of pending readers // 获取写锁是需要等待的读锁释放数量 readerWait int32 // number of departing readers } const rwmutexMaxReaders = 1 \u003c\u003c 30 // 最多支持2^30个锁 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/:1:0","tags":["源码解析","sync"],"title":"并发编程之读写锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["月霜天的GO"],"content":"读加锁RLock // 读加锁，不应该用于递归读锁定 func (rw *RWMutex) RLock() { // 每次goroutine获取读锁时，readerCount+1 // 如果写锁已经被获取，那么readerCount在[-rwmutexMaxReaders,0)，这时挂起读锁的goroutine // 如果写锁没有被获取，那么readerCount\u003e=0,获取读锁，不阻塞 if atomic.AddInt32(\u0026rw.readerCount, 1) \u003c 0 { // 将goroutine排到队列尾部，挂起goroutine，监听readerSem信号量 runtime_SemacquireMutex(\u0026rw.readerSem, false, 0) } } 读加锁时并没有用到互斥锁，而是readerCount+1，而小于0的情况是因为写加锁了 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/:2:0","tags":["源码解析","sync"],"title":"并发编程之读写锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["月霜天的GO"],"content":"读解锁RUnlock // 读解锁，只会撤销对应的RLock调用，不会影响其他读锁 func (rw *RWMutex) RUnlock() { // 读计数器readerCount-1 // 场景一：有读锁，没有写锁被挂起 r=readerCount-1\u003e=0 // 场景二：有读锁，有写锁被挂起 r\u003c0 // 场景三：没有读锁，没有写锁被挂起 r=-1 // 场景四：没有读锁，有写锁被挂起 r=-(1\u003c\u003c30)-1\u003c0 if r := atomic.AddInt32(\u0026rw.readerCount, -1); r \u003c 0 { // Outlined slow-path to allow the fast-path to be inlined rw.rUnlockSlow(r) } } func (rw *RWMutex) rUnlockSlow(r int32) { // 场景三和场景四是异常情况 if r+1 == 0 || r+1 == -rwmutexMaxReaders { race.Enable() throw(\"sync: RUnlock of unlocked RWMutex\") } // 如果写锁的goroutine被阻塞，需要将读锁的goroutine全部释放，才会唤醒写锁 if atomic.AddInt32(\u0026rw.readerWait, -1) == 0 { // The last reader unblocks the writer. runtime_Semrelease(\u0026rw.writerSem, false, 1) } } 因为写加锁时是把readerCount+-rwmutexMaxReaders，所以在已经有写加锁时，readerCount一定是负数。 而对没有读锁没有写锁这种异常情况，readerCount-1后为-1 而对没有读锁，有写锁时，此时readerCount+1=-rwmutexMaxReaders 这两种情况都会报错。 对于有读锁，有写锁时，如果是最后一个读解锁，那么唤醒写锁。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/:3:0","tags":["源码解析","sync"],"title":"并发编程之读写锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["月霜天的GO"],"content":"写加锁Lock func (rw *RWMutex) Lock() { // 首先，获取互斥锁，与其他来获取写锁的goroutine互斥 rw.w.Lock() // 告诉其他来获取读锁的goroutine，现在已经有人获取了写锁 // 减去最大读锁的数量，用负数来表示，写锁已经被获取 r := atomic.AddInt32(\u0026rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders // 设置需要等待释放的读锁数量，如果有挂起写锁 if r != 0 \u0026\u0026 atomic.AddInt32(\u0026rw.readerWait, r) != 0 { runtime_SemacquireMutex(\u0026rw.writerSem, false, 0) } } 这里先用互斥锁保护下面的操作： 设置读等待的数量readerWait，如果不为0，就挂起写锁 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/:4:0","tags":["源码解析","sync"],"title":"并发编程之读写锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["月霜天的GO"],"content":"写解锁Unlock func (rw *RWMutex) Unlock() { // 向读锁的goroutine发出通知，没有写锁了 // 还原加锁时的readerCount r := atomic.AddInt32(\u0026rw.readerCount, rwmutexMaxReaders) if r \u003e= rwmutexMaxReaders { race.Enable() throw(\"sync: Unlock of unlocked RWMutex\") } for i := 0; i \u003c int(r); i++ { runtime_Semrelease(\u0026rw.readerSem, false, 0) } // Allow other writers to proceed. rw.w.Unlock() } 写解锁时，首先将readerCount数量还原，然后去唤醒读锁 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/:5:0","tags":["源码解析","sync"],"title":"并发编程之读写锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["月霜天的GO"],"content":"总结 源码中可以看到，读写锁首先内置了一个互斥锁，再加上各种计数器来实现读写锁。 读锁不能阻塞读锁，所以添加readerCount 读锁需要阻塞写锁，直到所有的读锁释放，引入writerSem 写锁需要阻塞读锁，直到所有写锁释放，引入readerSem 写锁需要阻塞写锁，引入mutex实现 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/:6:0","tags":["源码解析","sync"],"title":"并发编程之读写锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%AF%BB%E5%86%99%E9%94%81/"},{"categories":["月霜天的GO"],"content":"并发必然会带来对于资源的竞争，这时需要使用go提供的sync.Mutex这把互斥锁来保证临界资源的访问互斥了。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/:0:0","tags":["源码解析","sync"],"title":"并发编程之互斥锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/"},{"categories":["月霜天的GO"],"content":"锁的性质 在代码注释开篇就有一大段注释，里面讲了锁的设计理念。大致意思如下： 锁有两种模式：正常模式和饥饿模式。 在正常模式下，所有的等待锁的goroutine都会存在一个先进先出的队列中（轮流被唤醒） 但是一个被唤醒的goroutine并不是直接获得锁，而是仍然需要和那些新请求锁的（new arrivial）的goroutine竞争，而这其实是不公平的，因为新请求锁的goroutine有一个优势——它们正在CPU上 运行，并且数量可能会很多。所以一个被唤醒的goroutine拿到锁的概率是很小的。在这种情况下， 这个被唤醒的goroutine会加入到队列的头部。如果一个等待的goroutine有超过1ms（写死在代码中） 都没获取到锁，那么就会把锁转变为饥饿模式。 在饥饿模式中，锁的所有权会直接从释放锁(unlock)的goroutine转交给队列头的goroutine， 新请求锁的goroutine就算锁是空闲状态也不会去获取锁，并且也不会尝试自旋。它们只是排到队列的尾部。 如果一个goroutine获取到了锁之后，它会判断以下两种情况： 它是队列中最后一个goroutine； 它拿到锁所花的时间小于1ms； 以上只要有一个成立，它就会把锁转变回正常模式。 正常模式会有比较好的性能，因为即使有很多阻塞的等待锁的goroutine， 一个goroutine也可以尝试请求多次锁。 饥饿模式对于防止尾部延迟来说非常的重要。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/:1:0","tags":["源码解析","sync"],"title":"并发编程之互斥锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/"},{"categories":["月霜天的GO"],"content":"字段定义 // A Mutex must not be copied after first use. type Mutex struct { state int32 // 锁的当前状态 sema uint32 // 信号量，用户唤醒goroutine } const ( // 是否加锁的标识 mutexLocked = 1 \u003c\u003c iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota // Mutex fairness. starvationThresholdNs = 1e6 ) state的状态： mutexLocked：对应低1位bit代表锁被占用，0标识锁空闲 mutexWoken：对应低2位bit代表已唤醒，0标识未唤醒 mutexStarving：对应低3位bit代表处于饥饿模式，0标识正常模式 mutexWaiterShift：3(011)，m.state\u003e\u003emutexWaiterShift得到当前阻塞的goroutine数目，最多可以阻塞2^29^个goroutine。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/:2:0","tags":["源码解析","sync"],"title":"并发编程之互斥锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/"},{"categories":["月霜天的GO"],"content":"Lock func (m *Mutex) Lock() { // Fast path: grab unlocked mutex. // 判断是否可以加锁。 // 第一个可以直接加锁返回 if atomic.CompareAndSwapInt32(\u0026m.state, 0, mutexLocked) { return } // Slow path (outlined so that the fast path can be inlined) m.lockSlow() } func (m *Mutex) lockSlow() { var waitStartTime int64 // 饥饿模式 starving := false // 协程唤醒 awoke := false // 循环次数 iter := 0 // 当前锁状态 old := m.state for { // Don't spin in starvation mode, ownership is handed off to waiters // so we won't be able to acquire the mutex anyway. // 条件一：old被获取到锁，但不处于饥饿状态。如果处于饥饿状态，锁的所有权直接交给等待队列第一个 // 条件二：可以自旋，多核、压力不大并且在一定次数内可以自旋。sync_runtime_canSpin的实现 if old\u0026(mutexLocked|mutexStarving) == mutexLocked \u0026\u0026 runtime_canSpin(iter) { // Active spinning makes sense. // Try to set mutexWoken flag to inform Unlock // to not wake other blocked goroutines. // 自旋过程中如果发现state没有设置唤醒标识，添加awoke标识，并标记自己已唤醒 if !awoke \u0026\u0026 old\u0026mutexWoken == 0 \u0026\u0026 old\u003e\u003emutexWaiterShift != 0 \u0026\u0026 atomic.CompareAndSwapInt32(\u0026m.state, old, old|mutexWoken) { awoke = true } // 主动自旋 runtime_doSpin() iter++ old = m.state continue } // 到了这一步：state的状态可能是 // 1、锁没有释放，锁处于正常状态（011） // 2、锁没有释放，锁处于饥饿状态（111） // 3、锁已经释放，锁处于正常状态（010） // 4、锁已经释放，锁处于饥饿状态（110） // 复制一个新的状态 new := old // Don't try to acquire starving mutex, new arriving goroutines must queue. // 如果不是饥饿状态，new设置锁，尝试获取锁 // 如果处于饥饿状态，不设置状态 if old\u0026mutexStarving == 0 { new |= mutexLocked // 标记为获取锁（实际上还没有获取到） } // 如果old锁处于被获取或饥饿状态，就把期望状态的等待队列的等待者数量+1 if old\u0026(mutexLocked|mutexStarving) != 0 { new += 1 \u003c\u003c mutexWaiterShift } // The current goroutine switches mutex to starvation mode. // But if the mutex is currently unlocked, don't do the switch. // Unlock expects that starving mutex has waiters, which will not // be true in this case. // 如果处于饥饿状态，并且state已经被加锁，将new state标记为饥饿状态 if starving \u0026\u0026 old\u0026mutexLocked != 0 { new |= mutexStarving } if awoke { // The goroutine has been woken from sleep, // so we need to reset the flag in either case. // goroutine已经被唤醒，因此需要reset if new\u0026mutexWoken == 0 { throw(\"sync: inconsistent mutex state\") } // 设为未唤醒状态 new \u0026^= mutexWoken } // 原子更新state if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { // 如果old状态不是饥饿状态也不是被获取状态，代表当前goroutine已经获取了锁 if old\u0026(mutexLocked|mutexStarving) == 0 { break // locked the mutex with CAS } // If we were already waiting before, queue at the front of the queue. // 如果之前在等待了，就排在队列前面 queueLifo := waitStartTime != 0 // 如果没有等待过，初始化等待时间 if waitStartTime == 0 { waitStartTime = runtime_nanotime() } // 如果queueLifo为true，将等待服务方针等待队列队头，被阻塞 runtime_SemacquireMutex(\u0026m.sema, queueLifo, 1) // 阻塞被唤醒 // 如果是饥饿状态或等待超过1ms，将当前goroutine状态设置为饥饿 starving = starving || runtime_nanotime()-waitStartTime \u003e starvationThresholdNs old = m.state // 如果是饥饿状态 if old\u0026mutexStarving != 0 { // If this goroutine was woken and mutex is in starvation mode, // ownership was handed off to us but mutex is in somewhat // inconsistent state: mutexLocked is not set and we are still // accounted as waiter. Fix that. if old\u0026(mutexLocked|mutexWoken) != 0 || old\u003e\u003emutexWaiterShift == 0 { throw(\"sync: inconsistent mutex state\") } // 当前的goroutine获取锁，waiter-1 delta := int32(mutexLocked - 1\u003c\u003cmutexWaiterShift) // 如果当前goroutine不是饥饿状态或当前goroutine是队列中最后一个，退出饥饿模式，状态设为正常 if !starving || old\u003e\u003emutexWaiterShift == 1 { // Exit starvation mode. // Critical to do it here and consider wait time. // Starvation mode is so inefficient, that two goroutines // can go lock-step infinitely once they switch mutex // to starvation mode. delta -= mutexStarving } atomic.AddInt32(\u0026m.state, delta) break } awoke = true iter = 0 } else { // cas不成功，说明没有成功获取到锁，更新old old = m.state } } } 加锁流程 1、原子判断是否可以加锁，如果当前锁没有被使用，当前goroutine获取锁，结束本次Lock操作 2、如果已经被别的goroutine持有了，启动一个for循环去抢占锁： 会存在两种状态的切换：饥饿状态和正常状态 如果一个等待的goroutine有超过1ms没有获取到锁，那么把锁转换为饥饿模式； 如果一个goroutine获取到锁后 1、它是队列中最后一个goroutine 2、它拿到锁花费的时间小于1ms 上面的两个只要有一个条件成立，就会把锁转为正常状态。 3、如果锁已经被其他goroutine持有了，但不是饥饿状态，并且满足自旋状态，当前goroutine会不断自旋，等待锁被释放 4、不满足自旋条件的goroutine，结束自旋状态 5、如果old.state不是饥饿状态，新的goroutine会去尝试获取锁，如果是饥饿状态，就直接把锁交给等待队列的第一个 6、如果锁时被获取或饥饿状态，等待者数量+1 7、当本goroutine被唤醒","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/:3:0","tags":["源码解析","sync"],"title":"并发编程之互斥锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/"},{"categories":["月霜天的GO"],"content":"UnLock func (m *Mutex) Unlock() { if race.Enabled { _ = m.state race.Release(unsafe.Pointer(m)) } // Fast path: drop lock bit. // 修改锁的状态 new := atomic.AddInt32(\u0026m.state, -mutexLocked) if new != 0 { // 如果new=0，说明只有一个Lock并且被解开了 // Outlined slow path to allow inlining the fast path. // To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock. m.unlockSlow(new) } } func (m *Mutex) unlockSlow(new int32) { // （new+1）\u00261==0，new=-1，也就是上面已经Unlock后又调用一次Unlock会出现这种情况 if (new+mutexLocked)\u0026mutexLocked == 0 { throw(\"sync: unlock of unlocked mutex\") } if new\u0026mutexStarving == 0 { // 不是饥饿状态 old := new for { // 如果锁没有等待拿锁的goroutine // 或锁被获取了（在循环过程中被其他goroutine获取了） // 或锁是被唤醒状态（表示有goroutine被唤醒，不需要再去尝试唤醒其他goroutine） // 或者锁是饥饿状态（会直接交给队列头的goroutine） // 那么直接返回 if old\u003e\u003emutexWaiterShift == 0 || old\u0026(mutexLocked|mutexWoken|mutexStarving) != 0 { return } // Grab the right to wake someone. // 将等待队列-1，设置woken标识 new = (old - 1\u003c\u003cmutexWaiterShift) | mutexWoken // 设置新的state，通过信号量会唤醒一个阻塞的goroutine去获取锁 if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { runtime_Semrelease(\u0026m.sema, false, 1) return } old = m.state } } else { // 饥饿模式下，直接将锁的所有权转给等待队列中的第一个。 // 注意此时state的mutexLocked还没有设置，唤醒的goroutine会设置它。 // 在此期间，如果有新的goroutine来请求锁，因为mutex处于饥饿状态，mutex还会被认为处于锁的状态，新来的goroutine不会抢占锁 runtime_Semrelease(\u0026m.sema, true, 1) } } 解锁流程 1、判断锁的状态，不能重复解锁 2、如果锁是正常模式，会不断尝试解锁 3、如果锁时饥饿模式，通过信号量，唤醒饥饿模式下Lock操作队列中第一个goroutine ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/:4:0","tags":["源码解析","sync"],"title":"并发编程之互斥锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/"},{"categories":["月霜天的GO"],"content":"总结 加锁过程会存在正常模式和饥饿模式的转换 饥饿模式是保证锁的公平性，正常模式下的互斥锁能提供更好的性能，饥饿模式能避免goroutine由于陷入等待无法获取锁造成的高尾延迟 锁的状态切换，用的是位运算 一个已经锁定的互斥锁，只能被解锁一次 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/:5:0","tags":["源码解析","sync"],"title":"并发编程之互斥锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/"},{"categories":["月霜天的GO"],"content":"如果atomic可以保证原子性，那么和mutex有什么区别呢？ Mutexes are slow, due to the setup and teardown, and due to the fact that they block other goroutines for the duration of the lock. Atomic operations are fast because they use an atomic CPU instruction, rather than relying on external locks to. 互斥锁其实是通过阻塞其他协程起到了原子操作的功能，而atomic是通过控制更底层的CPU指令，来达到值操作的原子性。 mutex类似于悲观锁，总是假设会有并发的操作要修改被操作的值，所以使用锁将相关操作放入临界区加以保护 而原子锁CAS趋向于乐观锁，总是假设被操作值未曾修改（与旧值相等），一旦确认就立即进行值替换。在值被频繁变更的情况下，CAS操作并不是容易成功需要不断尝试。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/:5:1","tags":["源码解析","sync"],"title":"并发编程之互斥锁","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.mutex/"},{"categories":["月霜天的GO"],"content":"sync.Cond字面意思就是同步条件变量，它实现的是一种监视器(Monitor)模式。 对于Cond而言，它实现一个条件变量，是goroutine间等待和通知的点。条件变量和共享的数据隔离，它可以同时阻塞多个goroutine，知道另外的goroutine更改了条件变量，并通知唤醒阻塞着的一个或多个goroutine。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/:0:0","tags":["源码解析","sync"],"title":"并发编程之条件变量Cond","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/"},{"categories":["月霜天的GO"],"content":"演示例子 下面我们看一下 GopherCon 2018 上《Rethinking Classical Concurrency Patterns》 中的演示代码例子。 type Item = int type Queue struct { items []Item itemAdded sync.Cond } func NewQueue() *Queue { q := new(Queue) q.itemAdded.L = \u0026sync.Mutex{} // 为 Cond 绑定锁 return q } func (q *Queue) Put(item Item) { q.itemAdded.L.Lock() defer q.itemAdded.L.Unlock() q.items = append(q.items, item) q.itemAdded.Signal() // 当 Queue 中加入数据成功，调用 Singal 发送通知 } func (q *Queue) GetMany(n int) []Item { q.itemAdded.L.Lock() defer q.itemAdded.L.Unlock() for len(q.items) \u003c n { // 等待 Queue 中有 n 个数据 q.itemAdded.Wait() // 阻塞等待 Singal 发送通知 } items := q.items[:n:n] q.items = q.items[n:] return items } func main() { q := NewQueue() var wg sync.WaitGroup for n := 10; n \u003e 0; n-- { wg.Add(1) go func(n int) { items := q.GetMany(n) fmt.Printf(\"%2d: %2d\\n\", n, items) wg.Done() }(n) } for i := 0; i \u003c 100; i++ { q.Put(i) } wg.Wait() } 在这个例子中，Queue是存储Item的结构体，通过Cond类型的itemAdded来控制数据的输入与输出。可以看到，这里通过10个goroutine来消费数据，但是逐步添加100个数据至Queue中。最后，我们能够看到10个goroutine都能被唤醒，得到数据。 程序的运行结果如下： 3: [11 12 13] 2: [ 0 1] 9: [ 2 3 4 5 6 7 8 9 10] 1: [14] 6: [41 42 43 44 45 46] 4: [32 33 34 35] 5: [36 37 38 39 40] 7: [25 26 27 28 29 30 31] 8: [47 48 49 50 51 52 53 54] 10: [15 16 17 18 19 20 21 22 23 24] 当然，每次的运行结果都不会相同。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/:1:0","tags":["源码解析","sync"],"title":"并发编程之条件变量Cond","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/"},{"categories":["月霜天的GO"],"content":"源码实现 Cond的实现还是比较简单的，代码量比较少，复杂的逻辑已经被Locker和runtime的等待队列实现了。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/:2:0","tags":["源码解析","sync"],"title":"并发编程之条件变量Cond","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/"},{"categories":["月霜天的GO"],"content":"结构体 首先来看它的结构体： // A Cond must not be copied after first use. type Cond struct { noCopy noCopy // 不允许拷贝 // L is held while observing or changing the condition // L 是观察和改变条件的 L Locker notify notifyList // 通知列表，调用Wait()方法的goroutine会放入list中，每次被唤醒从这里取出 checker copyChecker // 拷贝检查，检查cond是否被拷贝 } 这里的notifyList通知列表： type notifyList struct { wait uint32 // 写一个等待goroutine的ticket，是原子性的，在锁外递增 notify uint32 // 下一个通知的goroutine的ticket，在锁外读取，但只能在持有锁的情况下写入 lock uintptr // 需要传入的锁的标记 head unsafe.Pointer // 基于*sudog的双向链表的前驱指针 tail unsafe.Pointer // 基于*sudog的双向链表的后驱指针 } 基本结构大致就是这样，下面来看看实现方法。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/:2:1","tags":["源码解析","sync"],"title":"并发编程之条件变量Cond","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/"},{"categories":["月霜天的GO"],"content":"Wait方法的实现 func (c *Cond) Wait() { c.checker.check() t := runtime_notifyListAdd(\u0026c.notify) // 加入到通知列表 c.L.Unlock() runtime_notifyListWait(\u0026c.notify, t) // 等待通知 c.L.Lock() } 执行运行期间拷贝检查，如果发生了拷贝，则直接panic 调用runtime_notifyListAdd将等待计数器加1并解锁 调用runtime_notifyListWait等待其他goroutine的唤醒并加锁 而在runtime/sema.go中runtime_notifyListAdd的实现： func notifyListAdd(l *notifyList) uint32 { // This may be called concurrently, for example, when called from // sync.Cond.Wait while holding a RWMutex in read mode. return atomic.Xadd(\u0026l.wait, 1) - 1 } 实现比较简单，就是原子操作将等待计数器+1，而返回的值是代表下一个等待唤醒的goroutine的索引 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/:2:2","tags":["源码解析","sync"],"title":"并发编程之条件变量Cond","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/"},{"categories":["月霜天的GO"],"content":"runtime_notifyListWait的实现 func notifyListWait(l *notifyList, t uint32) { lock(\u0026l.lock) // Return right away if this ticket has already been notified. if less(t, l.notify) { unlock(\u0026l.lock) return } // Enqueue itself. s := acquireSudog() s.g = getg() s.ticket = t s.releasetime = 0 t0 := int64(0) if blockprofilerate \u003e 0 { t0 = cputicks() s.releasetime = -1 } if l.tail == nil { l.head = s } else { l.tail.next = s } l.tail = s goparkunlock(\u0026l.lock, waitReasonSyncCondWait, traceEvGoBlockCond, 3) if t0 != 0 { blockevent(s.releasetime-t0, 2) } releaseSudog(s) } 检查当前wait与notify索引位置是否匹配，如果已经通知过了，则立即返回 获取当前goroutine，并且将当前的goroutine加入到链表末端 调用goparkunlock方法挂起当前goroutine 被唤醒后，调用releaseSudog释放当前goroutine Signal和Boardcast都会唤醒等待队列，不过Signal是唤醒链表最前面的goroutine，Boardcast会唤醒队列中全部的goroutine。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/:2:3","tags":["源码解析","sync"],"title":"并发编程之条件变量Cond","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/"},{"categories":["月霜天的GO"],"content":"Signal // 通知等待列表中的一个 func (c *Cond) Signal() { c.checker.check() runtime_notifyListNotifyOne(\u0026c.notify) } func notifyListNotifyOne(l *notifyList) { // Fast-path: if there are no new waiters since the last notification // we don't need to acquire the lock at all. if atomic.Load(\u0026l.wait) == atomic.Load(\u0026l.notify) { return } lock(\u0026l.lock) // Re-check under the lock if we need to do anything. t := l.notify if t == atomic.Load(\u0026l.wait) { unlock(\u0026l.lock) return } // Update the next notify ticket number. atomic.Store(\u0026l.notify, t+1) for p, s := (*sudog)(nil), l.head; s != nil; p, s = s, s.next { if s.ticket == t { n := s.next if p != nil { p.next = n } else { l.head = n } if n == nil { l.tail = p } unlock(\u0026l.lock) s.next = nil readyWithTime(s, 4) return } } unlock(\u0026l.lock) } 我们记得在wait代码中，每次调用都会原子累加wait，那么这个wait就代表最大的wait值，对应唤醒时，也会对应一个notify属性。我们在notifyList链表中逐个检查，找到ticket对应相等的notify属性。 notifyList并不是一直有序的，wait方法中调用runtime_notifyListAdd和runtime_notifyListWait完全是两个独立的行为。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/:2:4","tags":["源码解析","sync"],"title":"并发编程之条件变量Cond","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/"},{"categories":["月霜天的GO"],"content":"Broadcast // Broadcast唤醒所有等待的协程 func (c *Cond) Broadcast() { c.checker.check() runtime_notifyListNotifyAll(\u0026c.notify) } func notifyListNotifyAll(l *notifyList) { // Fast-path: if there are no new waiters since the last notification // we don't need to acquire the lock. if atomic.Load(\u0026l.wait) == atomic.Load(\u0026l.notify) { return } // Pull the list out into a local variable, waiters will be readied // outside the lock. lock(\u0026l.lock) s := l.head l.head = nil l.tail = nil // Update the next ticket to be notified. We can set it to the current // value of wait because any previous waiters are already in the list // or will notice that they have already been notified when trying to // add themselves to the list. atomic.Store(\u0026l.notify, atomic.Load(\u0026l.wait)) unlock(\u0026l.lock) // Go through the local list and ready all waiters. for s != nil { next := s.next s.next = nil readyWithTime(s, 4) s = next } } 全部唤醒的实现简单一点，主要是通过调用readyWithTime方法唤醒链表中的goroutine，唤醒的顺序也是按照加入队列的先后顺序唤醒，而后加入的goroutine可能需要等待调度器的调度。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/:2:5","tags":["源码解析","sync"],"title":"并发编程之条件变量Cond","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/"},{"categories":["月霜天的GO"],"content":"使用场景 每次向队列中添加元素后就需要调用Broadcast通知所有的等待者，使用Cond很合适，相比channel减少了代码的复杂度。 当然使用的姿势一定要正确： c.L.Lock() for !condition() { c.Wait() } // ... make use of condition ... c.L.Unlock() ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/:3:0","tags":["源码解析","sync"],"title":"并发编程之条件变量Cond","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.cond/"},{"categories":["月霜天的GO"],"content":"waitgroup的使用场景： 一个waitgroup对象可以等到一组协程结束，也就是等待一组goroutine返回。 首先我们来看看sync.WaitGroup的结构： // A WaitGroup must not be copied after first use. type WaitGroup struct { noCopy noCopy // 64-bit value: high 32 bits are counter, low 32 bits are waiter count. // 64-bit atomic operations require 64-bit alignment, but 32-bit // compilers do not ensure it. So we allocate 12 bytes and then use // the aligned 8 bytes in them as state, and the other 4 as storage // for the sema. // 64bit(8bytes)的值分成两段，高32位是计数值，低32位是waiter的计数 // 64位值的原子操作需要在64位编译器上，但32位不支持，所以使用12bytes，8bytes表示状态，4bytes表示信号量 state1 [3]uint32 } 这里总共就2个字段，一个是nocopy是为了保证该结构不会被拷贝，是一种保护机制。一个是state1主要是存储状态和信号量，这里使用的8字节对齐。 这里的state1一共被分配了12个字节，被设定成3种状态： 其中对齐的8个字节作为状态，高32位为计数的数量，低32位为等待的goroutine数量 其中的4个字节作为信号量存储 // state returns pointers to the state and sema fields stored within wg.state1. func (wg *WaitGroup) state() (statep *uint64, semap *uint32) { if uintptr(unsafe.Pointer(\u0026wg.state1))%8 == 0 { // 如果是64位，数组前两个元素做state，后一个元素做信号量 return (*uint64)(unsafe.Pointer(\u0026wg.state1)), \u0026wg.state1[2] } else { // 如果是32位，数组后两个元素做state，第一个元素做信号量 return (*uint64)(unsafe.Pointer(\u0026wg.state1[1])), \u0026wg.state1[0] } } 为了保证waitgroup在32位平台上使用，就不能分成2个字段来写，考虑到字段的顺序平台的不同，内存对齐的方式不同，因此这里判断数组的首地址是否处于8字节对齐的位置上。 当数组的首地址是处于一个8字节对齐的位置上时，那么就将这个数组的前8个字节作为64位值使用表示状态，后4个字节作为32位值表示信号量(semaphore)。同理如果首地址没有处于8字节对齐的位置上时，那么就将前4个字节作为semaphore，后8个字节作为64位数值。画个图表示一下： waitgroup提供了Add方法增加一个计数器，Done方法减掉一个计数器，而Done方法实际上就是Add(-1)。 所以我们来看看Add()方法： // Add主要操作state的计数值部分（高32位） func (wg *WaitGroup) Add(delta int) { statep, semap := wg.state() // 将delta添加到计数值上 state := atomic.AddUint64(statep, uint64(delta)\u003c\u003c32) // 当前的计数值 v := int32(state \u003e\u003e 32) // 当前的waiter w := uint32(state) if v \u003c 0 { panic(\"sync: negative WaitGroup counter\") } // Add(1)必须在Wait之前 if w != 0 \u0026\u0026 delta \u003e 0 \u0026\u0026 v == int32(delta) { panic(\"sync: WaitGroup misuse: Add called concurrently with Wait\") } if v \u003e 0 || w == 0 { return } // This goroutine has set counter to 0 when waiters \u003e 0. // Now there can't be concurrent mutations of state: // - Adds must not happen concurrently with Wait, // - Wait does not increment waiters if it sees counter == 0. // Still do a cheap sanity check to detect WaitGroup misuse. // 如果计数值v=0且waiter\u003e0，那么state的值就是waiter的数量 // 将waiter设置为0，唤醒所有的waiter if *statep != state { panic(\"sync: WaitGroup misuse: Add called concurrently with Wait\") } // Reset waiters count to 0. *statep = 0 for ; w != 0; w-- { runtime_Semrelease(semap, false, 0) } } 而Wait方法会阻塞goroutine知道waitgroup的计数器变为0。 // 不断检查state的值，如果其中计数值为0，说明所有的子goroutine已全部执行完毕，调用者不必等待，全部返回。 // 如果计数值\u003e0,说明此时还有任务没有完成，那么调用者变成等待者，需要加入wait队列，并且阻塞自己 func (wg *WaitGroup) Wait() { statep, semap := wg.state() for { state := atomic.LoadUint64(statep) v := int32(state \u003e\u003e 32) // 计数值（Add） w := uint32(state) // waiter if v == 0 { // Counter is 0, no need to wait. return } // Increment waiters count. if atomic.CompareAndSwapUint64(statep, state, state+1) { runtime_Semacquire(semap) // 阻塞完成，所有的Add已经完成 if *statep != 0 { panic(\"sync: WaitGroup is reused before previous Wait has returned\") } return } } } 小结 Add方法与Wait方法不可以并发同时调用，Add方法必须在Wait方法之前调用 Add方法必须与实际等待的goroutine数量一致，否则会panic 调用Wait方法后，必须等待Wait方法返回后才能重新使用waitgroup，也就是不能再wait没有返回前调用Add waitgroup对象只能有一份，不可以拷贝给其他变量。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.waitgroup/:0:0","tags":["源码解析","sync"],"title":"并发编程之WaitGroup","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.waitgroup/"},{"categories":["月霜天的GO"],"content":"Go语言标准库中的sync.Once可以保证go程序在运行期间的某段代码只执行一次。 而我们来看看sync.Once的源码，发现是比较少的。 去掉注释后： type Once struct { done uint32 m Mutex } func (o *Once) Do(f func()) { // todo：为什么不用cas？ if atomic.LoadUint32(\u0026o.done) == 0 { o.doSlow(f) } } func (o *Once) doSlow(f func()) { o.m.Lock() defer o.m.Unlock() if o.done == 0 { // todo：为什么用defer来计数？ defer atomic.StoreUint32(\u0026o.done, 1) f() } } 提出两个问题： ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.once%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:0","tags":["源码解析","sync"],"title":"并发编程之sync.Once","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.once%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["月霜天的GO"],"content":"为什么Once.Do没有用cas来判断？ 什么是cas？ 在sync.atomic里有CompareAndSwapUint32函数来实现cas功能。意思就是Compare And Swap的缩写，把判断和赋值包装成一个原子操作。 那么这里为什么用以下方式实现： if atomic.CompareAndSwapUint32(\u0026o.done,0,1) { f() } 看上去，也实现了只执行一次的语义。当o.done==0的时候，会赋值o.done==1,然后执行f()。 其他并发请求的时候，o.done==1，就不会再进入这个分支，貌似可行。 注释里有写道： 当o.done判断为0时，立即设置成1，然后再执行f()，这样语义就不正确。 Once需要不仅要保证只执行一次，还要保证其他用户看到o.done==1的时候，f()已经完成。 这涉及到逻辑的正确性。例如通过sync.Once创建唯一的全局变量，如果调用sync.Once通知用户已经创建成功，实际上f()还在执行过程中，全局变量还没有创建完成，那么这个逻辑就是错误的。 那么怎么解决： 1、快路径：用原子读o.done的值，保证竞态条件正确 2、慢路径：既然不能用cas原子操作，那么就用锁机制来保证原子性。先执行f()，然后再去设置o.done为1. 第一次可能在锁互斥的时候比较慢，但只要执行过一次后，就不会走到锁机制，都是走原子操作。 既然内部是用互斥锁来保证代码的临界区，那么就不能嵌套锁 once1.Do(func() { once1.Do(func() { /* do something*/ }) }) ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.once%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:1","tags":["源码解析","sync"],"title":"并发编程之sync.Once","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.once%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["月霜天的GO"],"content":"为什么Once.doSlow用defer来加计数？ 为什么不可以这样？ if o.done == 0 { // todo：为什么用defer来计数？ f() atomic.StoreUint32(\u0026o.done, 1) } 因为这样处理不了panic异常，会导致o.done没有加计数，但f()已经执行了 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.once%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:2","tags":["源码解析","sync"],"title":"并发编程之sync.Once","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.once%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["月霜天的GO"],"content":"Once的语义 1、Once.Do保证只调用一次的语义，无论f()内部有没有执行完（panic） 2、只有f()执行完成，Once.Do才会返回，否则阻塞等待f()的第一次执行完成。 ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.once%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:3","tags":["源码解析","sync"],"title":"并发编程之sync.Once","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.once%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["月霜天的GO"],"content":"总结 1、Once 对外提供 f() 只调用一次的语义; 2、Once.Do 返回之后，按照约定，f() 一定被执行过一次，并且只执行过一次。如果没有执行完，会阻塞等待 f() 的第一次执行完成； 3、Once 只执行一次的语义是跟实例绑定的关系，多个 Once 实例的话，每个实例都有一次的机会； 4、内部用锁机制来保证逻辑的原子性，先执行 f() ，然后设置 o.done 标识位； 5、Once 用 defer 机制保证 panic 的场景，也能够保证 o.done 标识位被设置； 6、Once 实例千万注意，不要嵌套，内部有锁，乱用的话容易死锁； ","date":"2021-07-16","objectID":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.once%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:4","tags":["源码解析","sync"],"title":"并发编程之sync.Once","uri":"/2021/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8Bsync.once%E7%9A%84%E5%AE%9E%E7%8E%B0/"},{"categories":["月霜天的GO"],"content":"channel设计的基本思想是： 不要通过共享内存来通信，而是要通过通信来实现共享内存。 Do not communicate by sharing memory; instead, share memory by communicating. channel在设计上本质就是一个有锁的环形队列，包括发送方队列、接收方队列、互斥锁等结构。 下面就开始源码剖析这个有锁的环形队列是如何设计的。 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:0:0","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"数据结构 在runtime/chan.go中可以看到hchan的结构如下： // 64位占用80,32位占用44 type hchan struct { qcount uint // 队列中数据的个数 dataqsiz uint // 队列容量 buf unsafe.Pointer // 存放在环形数组的数据 elemsize uint16 // channel中数据类型大小 closed uint32 // channel是否关闭，0表示未关闭，非0表示已关闭 elemtype *_type // 元素类型 sendx uint // send的数组索引 recvx uint // receive的数组索引 recvq waitq // \u003c-ch 阻塞在chan上的队列 list of recv waiters sendq waitq // ch\u003c- 阻塞在chan上的队列 list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // 不要在持有锁（特别是G没有准备好的时候）改变另一个G的状态，因为这可能导致栈收缩 // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } buf是指向底层的循环数组，dataqsiz就是这个循环数组的长度，qcount就是当前循环数据中的元素数量。 elemsize和elemtype就是创建channel时设置的元素类型和大小 sendq和recvq是一个双向链表，分别表示被阻塞的goroutine链表，这些goroutine由于尝试读取/发送数据而阻塞。 基于此，如下图 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:1:0","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"channel的创建 通常我们使用make进行创建，make在经过编译器编译后的两种方法runtime.makechan和runtime.makechan64。 //go:linkname reflect_makechan reflect.makechan func reflect_makechan(t *chantype, size int) *hchan { return makechan(t, size) } func makechan64(t *chantype, size int64) *hchan { if int64(int(size)) != size { panic(plainError(\"makechan: size out of range\")) } return makechan(t, int(size)) } makechan64实际上也是调用makechan方法，只不过是多了一个数值溢出的校验。大多数情况还是使用makechan。 // 初始化chan， make(chan int,4) func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. // 对发送的元素进行限制 1\u003c\u003c16 if elem.size \u003e= 1\u003c\u003c16 { throw(\"makechan: invalid channel element type\") } if hchanSize%maxAlign != 0 || elem.align \u003e maxAlign { throw(\"makechan: bad alignment\") } // 计算 类型长度*容量， 如果溢出或超过可分配内存，报错 mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u003e maxAlloc-hchanSize || size \u003c 0 { panic(plainError(\"makechan: size out of range\")) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG's are referenced from their owning thread so they can't be collected. // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. var c *hchan switch { case mem == 0: // 缓冲区大小为0，只分配sizeof(hchan)大小的内存 c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = c.raceaddr() case elem.ptrdata == 0: // 数据类型不是指针，分配一块连续内存容纳hchanSize和缓冲区对象 c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // 数据类型包含指针，hchan和buf单独分配. c = new(hchan) c.buf = mallocgc(mem, elem, true) } // channel元素大小，如果是int，就是8字节 c.elemsize = uint16(elem.size) // 元素类型 c.elemtype = elem // 元素buffer数组的大小，比如make(chan int,2)，那么size=2 c.dataqsiz = uint(size) /* 初始化核心字段： 1、buf：指明buffer地址 2、elemsize：指明元素大小 3、elemtype：指明元素类型 4、dataqsiz：指明数组大小 */ if debugChan { print(\"makechan: chan=\", c, \"; elemsize=\", elem.size, \"; dataqsiz=\", size, \"\\n\") } return c } 这里主要是一些内存分配的操作。 如果创建的channel是无缓冲的，或创建的有缓冲的channel中存储的数据类型不是指针类型，就会调用mallocgc分配一段连续的内存。 如果创建的channel中存储的类型存在指针引用，就会连同hchan和底层数组同时分配一段连续的内存空间。 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:2:0","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"入队 channel发送数据部分的代码是runtime.chansend1 func chansend1(c *hchan, elem unsafe.Pointer) { chansend(c, elem, true, getcallerpc()) } ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:3:0","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"前置检查 // 如果chan是空的，对于非阻塞发送，直接返回false。对于阻塞的通道，将goroutine挂起，并且永远不返回 // 也就是不要向一个nil的chan发送数据 if c == nil { if !block { return false } gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\"unreachable\") } if debugChan { print(\"chansend: chan=\", c, \"\\n\") } if raceenabled { racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) } // 非阻塞情况下，如果通道没有关闭，而且没有接受者，缓冲区已经满了或没有缓冲区（即不可以发送数据），返回false // 因为这里是允许并发执行的，所以要仔细分析一下 // 判断完closed之后，通道可能在这一瞬间从未关闭变成关闭状态（closed不会从非0变为0，但可能从0变成非0，也就是通道可能被关闭） // 那么这里会有两种情况： // 1、通道没有关闭，而且已经满了，那么这段逻辑运行正确，应该返回false // 2、通道已经关闭，而关闭的时候（加锁操作）是将recvq和sendq全部出队列，所以也是返回false if !block \u0026\u0026 c.closed == 0 \u0026\u0026 ((c.dataqsiz == 0 \u0026\u0026 c.recvq.first == nil) || (c.dataqsiz \u003e 0 \u0026\u0026 c.qcount == c.dataqsiz)) { return false } var t0 int64 if blockprofilerate \u003e 0 { t0 = cputicks() } 这里主要的检查就是判断当前channel是否为nil，往一个nil的channel中发送数据时，会调用gopark函数将当前执行的goroutine从running状态转入waiting状态，这会表现出panic事件。 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:3:1","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"加锁/异常检查 // 对chan加锁 lock(\u0026c.lock) // 如果chan关闭，panic if c.closed != 0 { unlock(\u0026c.lock) panic(plainError(\"send on closed channel\")) } 前置校验通过后，对channel加锁，防止多个协程同时操作并发修改数据。如果channel已经关闭，那么发送数据会panic。 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:3:2","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"channel直接发送数据 // 场景一：从recvq中取出一个接受者，如果接受者存在，则向接受者发送数据 if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true } 这里主要调用了send方法 // send函数将ep作为参数传送给接收方sg，然后使用goready将其唤醒。 func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { // sg.elem如果非空，则将ep的内容直接拷贝到elem指向的地址 // elem是接收到的值存放的位置 if sg.elem != nil { // 调用sendDirect进行内存拷贝，从发送者拷贝到接受者 sendDirect(c.elemtype, sg, ep) sg.elem = nil } gp := sg.g unlockf() gp.param = unsafe.Pointer(sg) if sg.releasetime != 0 { sg.releasetime = cputicks() } // 唤醒接受的goroutine goready(gp, skip+1) } 然后，我们再看看sendDirect方法 func sendDirect(t *_type, sg *sudog, src unsafe.Pointer) { // src is on our stack, dst is a slot on another stack. // Once we read sg.elem out of sg, it will no longer // be updated if the destination's stack gets copied (shrunk). // So make sure that no preemption points can happen between read \u0026 use. dst := sg.elem typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) // No need for cgo write barrier checks because dst is always // Go memory. memmove(dst, src, t.size) } 这里直接调用memmove方法进行内存拷贝，这里是从一个goroutine直接写入另一个goroutine栈的操作，减少了一次内存copy，不用先拷贝到channel的buf，直接由发送者到接收者。 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:3:3","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"channel发送到数据缓冲区 // 场景二：如果缓冲区还有多余的空间，那么将数据写入缓冲区。写入缓冲区后，将发送位置后移一位，将qcount+1 if c.qcount \u003c c.dataqsiz { // Space is available in the channel buffer. Enqueue the element to send. qp := chanbuf(c, c.sendx) // typedmemmove 将ep的内容复制到qp上 typedmemmove(c.elemtype, qp, ep) // 递增索引 c.sendx++ // 回环空间 if c.sendx == c.dataqsiz { c.sendx = 0 } // 递增元素个数 c.qcount++ unlock(\u0026c.lock) return true } 这里的几步还是比较好理解的： 如果当前缓冲区还有可用空间，则调用chanbuf方法获取底层缓冲数组sendx索引元素指针值 调用typedmemmove方法将发送的值拷贝到缓冲区中 数据拷贝成功，sendx++，指向下一个待发送元素再循环数组中的位置。如果下一个索引位置正好是循环队列的长度，那么把索引置0。 队列元素长度自增，至此发送数据完成，释放锁 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:3:4","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"channel发送数据无可用缓冲区 缓冲区满了之后，有两种方式可以选择，一种是直接返回，一种是阻塞等待。 // 如果是非阻塞的，那么就直接解锁返回了 if !block { unlock(\u0026c.lock) return false } 下面是阻塞等待的代码 // 代码走到这里，说明都是因为条件不满足，要阻塞当前 goroutine，所以做的事情本质上就是保留好通知路径，等待条件满足，会在这个地方唤醒； // 获取当前goroutine的sudog，然后入channel的send队列 // Block on the channel. Some receiver will complete our operation for us. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil // 把 goroutine 相关的线索结构入队，等待条件满足的唤醒； c.sendq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we're about // to park on a channel. The window between when this G's status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(\u0026gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren't considered as roots of the // stack tracer. // 防止变量被CG KeepAlive(ep) 这里先通过getg获取当前的goroutine，然后调用acquireSudog方法构造sudog结构体，然后设置待发送消息和goroutine等信息（sudog通过g绑定goroutine，而goroutine通过waiting绑定sudog），构造完毕后通过c.sendq.enqueue放入待发送的等待队列，最后调用gopark方法挂起当前的goroutine进入wait状态。 此时goroutine处于wait状态，等待被唤醒 // goroutine被唤醒，表示数据已经发送完成，做清理工作 // someone woke us up. if mysg != gp.waiting { throw(\"G waiting list is corrupted\") } gp.waiting = nil gp.activeStackChans = false if gp.param == nil { if c.closed == 0 { throw(\"chansend: spurious wakeup\") } panic(plainError(\"send on closed channel\")) } gp.param = nil if mysg.releasetime \u003e 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) return true 唤醒的逻辑就是判断goroutine是否存在，检查当前channel是否被关闭了。取消goroutine和sudog的绑定。 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:3:5","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"出队 channel结构数据有两种方式： val := \u003c- ch val,ok := \u003c- ch 它们在编译器编译后的分别对应的是runtime.chanrecv1和runtime.chanrecv2： // entry points for \u003c- c from compiled code //go:nosplit func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } //go:nosplit func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } 其实都是调用chanrecv方法 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:4:0","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"前置检查 // chan为nil，非阻塞直接返回，阻塞就等待并抛出异常 if c == nil { if !block { return } gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\"unreachable\") } if !block \u0026\u0026 (c.dataqsiz == 0 \u0026\u0026 c.sendq.first == nil || c.dataqsiz \u003e 0 \u0026\u0026 atomic.Loaduint(\u0026c.qcount) == 0) \u0026\u0026 atomic.Load(\u0026c.closed) == 0 { return } var t0 int64 if blockprofilerate \u003e 0 { t0 = cputicks() } 判断当前channel是否为nil，如果为nil则为非阻塞接受，直接返回。如果nil channel为阻塞接受，会调用gopark挂起。 当循环队队列为0且等待队列sendq内没有goroutine正在等待或等待队列为空时，直接返回。 这里把判断channel是否关闭放在最后判断，是因为如果放在前面判断，判断到后面条件时，closed状态可能会被改变。 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:4:1","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"加锁/异常检查 lock(\u0026c.lock) // 如果通道已经关闭并且没有数据可以读取，返回(true,false) if c.closed != 0 \u0026\u0026 c.qcount == 0 { unlock(\u0026c.lock) if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } 如果channel被关闭了，并且缓存区没有数据，则直接释放锁和清理ep中的指针数据。 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:4:2","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"channel直接接收数据 // 场景一：如果有发送者在队列中等待，那么直接从发送者提取数据，并唤醒发送者。 if sg := c.sendq.dequeue(); sg != nil { // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender's value to the tail of the queue (both map to // the same buffer slot because the queue is full). recv(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true, true } 这一步与channel直接发送数据是对应的，当发现channel上有阻塞的等待发送的发送方时，则直接进行接收。 等待发送队列中有goroutine存在，有两种可能： 非缓冲的channel 缓冲的channel，但是缓冲区满了 针对这两种情况，在recv中有不同的行为： // 如果无缓冲，直接取出数据；如果有缓冲，将缓冲区的数据取出来，然后将等待中的发送者的数据拷贝到缓冲区中 func recv(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) { if c.dataqsiz == 0 { // 如果不带缓冲区 if ep != nil { // copy data from sender // 直接从发送者复制数据到ep recvDirect(c.elemtype, sg, ep) } } else { // Queue is full. Take the item at the // head of the queue. Make the sender enqueue // its item at the tail of the queue. Since the // queue is full, those are both the same slot. // 如果带缓冲区，由于有发送者等待，所以缓冲区一定是满的。将缓冲区的第一个数据复制到ep，然后将发送者的数据赋值到缓冲区 qp := chanbuf(c, c.recvx) // copy data from queue to receiver if ep != nil { typedmemmove(c.elemtype, ep, qp) } // copy data from sender to queue typedmemmove(c.elemtype, qp, sg.elem) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz } sg.elem = nil gp := sg.g unlockf() gp.param = unsafe.Pointer(sg) if sg.releasetime != 0 { sg.releasetime = cputicks() } // 将发送者唤醒 goready(gp, skip+1) } 这里主要就是分两种情况： 非缓冲channel：未忽略接受值时直接调用recvDirect方法直接从发送方的goroutine调用栈中将数据拷贝到接收方的goroutine 带缓冲区的channel：调用chanbuf方法根据recv索引的位置读取缓冲区元素，并将其拷贝到接收方的内存地址，拷贝完成后调整sendx和recvx索引的位置。 最后goready唤醒发送方的goroutine继续发送数据。 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:4:3","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"channel缓冲区有数据 // 场景二：如果缓冲区有数据，从缓冲区复制数据到ep，并且修改下次接收位置和qcount if c.qcount \u003e 0 { // Receive directly from queue // 存元素 qp := chanbuf(c, c.recvx) if raceenabled { raceacquire(qp) racerelease(qp) } if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(\u0026c.lock) return true, true } ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:4:4","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"channel缓冲区无数据 // 执行上面的流程后，仍然没有返回，说明缓冲区没有数据，且没有发送者在等待。 // 如果是非阻塞，直接返回(false,false)(走default) if !block { unlock(\u0026c.lock) return false, false } // 对于阻塞接收的情况，将调用者goroutine挂起，并且等待被唤醒 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil // goroutine 作为一个 waiter 入队列，等待条件满足之后，从这个队列里取出来唤醒； c.recvq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we're about // to park on a channel. The window between when this G's status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(\u0026gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) 剩下的就是被唤醒后清理现场。 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:4:5","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"关闭channel // 关闭通道 func closechan(c *hchan) { if c == nil { panic(plainError(\"close of nil channel\")) } lock(\u0026c.lock) // 不能对已经关闭的通道再次执行关闭操作 if c.closed != 0 { unlock(\u0026c.lock) panic(plainError(\"close of closed channel\")) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) } // 设置关闭标识 c.closed = 1 var glist gList // g对象的列表 // 唤醒所有的接受者，将接收数据置0 for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // 唤醒所有的发送者，令其panic for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(\u0026c.lock) // Ready all Gs now that we've dropped the channel lock. for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } 不允许对nil的channel进行关闭 不允许重复关闭channel 获取当前正在阻塞的发送或接受的goroutine，此时它们处于挂起状态，然后将它们唤醒。这是发送方不允许向channel发送数据，但不影响接收方继续接受数据，如果没有元素，获取到的元素为零值。 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:5:0","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"总结 channel的设计不是特别复杂，本质上就是维护了一个循环队列，发送数据依赖于FIFO，数据传递依赖于内存拷贝。 ","date":"2021-07-15","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/:6:0","tags":["源码解析","channel"],"title":"深入理解channel","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3channel/"},{"categories":["月霜天的GO"],"content":"前言 Map是一种常用的数据结构，通常用于存储无序的键值对。但是，Map在Golang中是如何实现的？ 如果判断Map中是否包含某个key？ Map是如何实现增删改查的？ Map的扩容机制是什么？ Map是线程安全的吗？ 概述 我们在使用过程中，发现map有如下特点： map是一个无序的key/value集合 map中所有的key是不相同的 通过给定的key，可以在常数时间复杂度(O(1))内查找、更新或删除相应的value 而想要实现一个性能优异的map，需要解决以下关键点： 哈希算法 处理哈希冲突 扩容策略 哈希算法 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:0:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"什么是哈希算法？ 哈希算法又称哈希函数/散列算法/散列函数，是一种从任何一种数据中创建小的数字“指纹”的方法。哈希算法把消息或数据压缩成摘要，使得数据量变小，将数据的格式固定下来。 哈希算法最重要的特点就是： 相同的输入一定得到相同的输出； 不同的输入大概率得到不同的输出。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:1:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"Map中为什么需要哈希算法？ Map中使用哈希算法是为了实现快速查找和定位。 一个优秀的哈希函数应该包含以下特性： 均匀性：一个好的哈希函数应该在其输出范围内尽可能均匀地映射，也就是说，应以大致相同的概率生成输出范围内的每个哈希值。 高效率：哈希效率要高，即使很长的输入参数也能快速计算出哈希值。 可确定性：哈希过程必须是确定性的，这意味着对于给定的输入值，它必须始终生成相同的哈希值。 雪崩效应：微小的输入值变化也会让输出值发生巨大的变化。 不可逆：从哈希函数的输出值不可反向推导出原始的数据。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:2:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"常见的哈希算法 下图是不同哈希算法的性能对比，测试环境是 Open-Source SMHasher program by Austin Appleby ，在 Windows 7 上通过 Visual C 编译，只有一个线程，CPU 内核是 Core 2 Duo @3.0GHz。 其中，第一栏是哈希算法名称，第二栏是速度的对比，第三栏是哈希质量。从表中数据看，质量最高、速度最快的是 xxHash。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:3:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"Golang使用的哈希算法 Golang 选择哈希算法时，根据 CPU 是否支持 AES 指令集进行判断 ，如果 CPU 支持 AES 指令集，则使用 Aes Hash，否则使用 memhash。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:4:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"AES Hash AES 指令集全称是高级加密标准指令集（或称英特尔高级加密标准新指令，简称AES-NI），是一个 x86指令集架构的扩展，用于 Intel 和 AMD 处理器。 利用 AES 指令集实现哈希算法性能很优秀，因为它能提供硬件加速。 查看 CPU 是否支持 AES 指令集： $ cat /proc/cpuinfo | grep aes flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc aperfmperf eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch epb fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 invpcid rtm rdseed adx smap xsaveopt dtherm ida arat pln pts 相关代码： runtime/alg.go asm_amd64.s asm_arm64.s ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:4:1","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"memhash 网上没有找到这个哈希算法的作者信息，只在 Golang 的源码中有这几行注释，说它的灵感来源于 xxhash 和 cityhash。 // Hashing algorithm inspired by // xxhash: https://code.google.com/p/xxhash/ // cityhash: https://code.google.com/p/cityhash/ 相关代码： runtime/hash64.go runtime/hash32.go 处理哈希冲突 通常情况下，哈希算法的输入范围一定会远远大于输出范围，所以当输入的key足够多时一定会遇到冲突，这时需要一些方法来解决哈希冲突问题。 比较常用的哈希冲突解决方案有链地址法和开放寻址法。 Golang 及多数编程语言都使用链地址法处理哈希冲突。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:4:2","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"链地址法 链地址法一般会使用数组加上链表实现，有些语言会引入红黑树以优化性能。 下面以一个简单的哈希函数H(key)=key MOD 7（除数取余法）对一组元素[50,700,76,85,92,73,101]进行映射。 在遍历当前桶中的链表时，会遇到以下两种情况： 1、找到键相同的键值对，则更新键对应的值 2、没有找到键相同的键值对，则在链表的末尾追加新键值对。 特点：平均查找长度短，用于存储节点的内存是动态申请的，可以节省较多内存。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:5:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"开放地址法 开放地址法的核心思路是：对数组中的元素依次探测和比较，以判断目标键值对是否存在于map中。 对于链地址法而言，槽位数m与键的数目n是没有直接关系的。但是对于开放寻址法而言，所有的元素都是存储在hash表中，所以无论如何都要保证哈希表的槽位数m\u003e=键的数目n。（必要时，需要对哈希表进行动态扩容） 开放寻址法有多种方式：线性探测法、平方探测法、随机探测法、双重哈希法。 线性探测法 设Hash(key)表示关键字key的哈希值，表示哈希表的槽位数（哈希表的大小）。 线性探测法可以表示为： 如果Hash(x)%M已经有数据，则尝试(Hash(x)+1)%M 如果(Hash(x)+1)%M有数据，则尝试(Hash(x)+2)%M 如果(Hash(x)+2)%M有数据，则尝试(Hash(x)+3)%M … 同样以哈希函数H(key)=key MOD 7（除数取余法）对一组元素[50,700,76,85,92,73,101]进行映射。 如上图所示，当我们向当前map写入新数据时发生了冲突，就将键值写入到下一个不为空的位置。 开放地址中对性能影响最大的是装载因子，它是数组中元素数量和数组大小的比值。随着装载因子的增加，线性探测的平均用时会逐渐增加，这会影响map的读写性能。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:6:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"两种方案的比较 对于开放寻址法而言，它只有数组一种数据结构就可完成存储，继承了数组的优点，对CPU缓存友好，易于序列化操作。但是它对内存的利用率不如链地址法，且发生冲突时代价更高。当数据量明确、装载因子小，适合采用开放寻址法。 链表节点可以在需要时再创建，不必像开放寻址法那样事先申请好足够内存，因此链地址法对于内存的利用率会比开方寻址法高。 链地址法对装载因子的容忍度会更高，并且适合存储大对象、大数据量的哈希表。而且相较于开放寻址法，它更加灵活，支持更多的优化策略，比如可采用红黑树代替链表。但是链地址法需要额外的空间来存储指针。 在Python中dict在发生哈希冲突时采用的开放寻址法，而java的HashMap采用的是链地址法。 Go解决哈希冲突的方式是链地址法，即通过使用数组+链表的数据结构来表达map。 扩容策略 随着 Map 中元素的增加，发生哈希冲突的概率会增加，Map 的读写性能也会下降，所以我们需要更多的桶和更大的内存来保证 Map 的读写性能。 在实际应用中，当装载因子超过某个阈值时，会动态地增加 Map 长度，实现自动扩容。 每当 Map 长度发生变化后，所有 key 在 Map 中对应的索引需要重新计算。如果一个一个计算原 Map 中的 key 的索引并插入到新 Map 中，这种一次性扩容方式是达不到生产环境的要求的，因为时间复杂度太高了O(n)，在数据量大的情况下性能会很差。 在实际应用中，Map 扩容都是分多次、渐进式地完成，而不是一性次完成扩容。 具体实现 Golang Map的具体定义在src/runtime/map.go文件中。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:7:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"常量定义 const ( // 一个桶中最多能装载的键值对的个数为8 bucketCntBits = 3 bucketCnt = 1 \u003c\u003c bucketCntBits // 触发扩容的装载因此13/2=6.5 loadFactorNum = 13 loadFactorDen = 2 // 键和值超过128个字节，就会被转为指针 maxKeySize = 128 maxElemSize = 128 // 数据偏移量是bmap结构体的大小，需要对齐。 // 对于amd64p32而言，意味着，即使指针时32位的，也是64位对齐 dataOffset = unsafe.Offsetof(struct { b bmap v int64 }{}.v) // 每个桶（如果有溢出，则包含它的overflow的链桶）在搬迁完成状态(evacuated* states)下，要么包含它的所有键值对， // 要么一个都不包含（但不包括调用evacuate()方法阶段，该方法调用只会在对map发起write时发生，在该阶段其他goroutine是无法查看该map的）。 // 简单的说，桶里的数据要么一起搬走，要么一个都还未搬。 // tophash除了放置正常的高8位hash值，还会存储一些特殊状态值（标志该cell的搬迁状态）。正常的tophash值，最小应该是5，以下列出的就是一些特殊状态值。 // 表示cell为空，并且比它高索引位的cell或者overflows中的cell都是空的。（初始化bucket时，就是该状态） emptyRest = 0 // this cell is empty, and there are no more non-empty cells at higher indexes or overflows. // 空的cell，cell已经被搬迁到新的bucket emptyOne = 1 // this cell is empty // 键值对已经搬迁完毕，key在新buckets数组的前半部分 evacuatedX = 2 // key/elem is valid. Entry has been evacuated to first half of larger table. // 键值对已经搬迁完毕，key在新buckets数组的后半部分 evacuatedY = 3 // same as above, but evacuated to second half of larger table. // cell为空，整个bucket已经搬迁完毕 evacuatedEmpty = 4 // cell is empty, bucket is evacuated. // tophash的最小正常值 minTopHash = 5 // minimum tophash for a normal filled cell. // flags // 可能有迭代器在使用buckets iterator = 1 // there may be an iterator using buckets // 可能有迭代器在使用oldbuckets oldIterator = 2 // there may be an iterator using oldbuckets // 有协程正在向map写入key hashWriting = 4 // a goroutine is writing to the map // 等量扩容 sameSizeGrow = 8 // the current map growth is to a new map of the same size // 用于迭代器检查的bucket ID noCheck = 1\u003c\u003c(8*sys.PtrSize) - 1 ) ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:8:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"装载因子为什么是6.5？ 这个值太大会导致溢出桶（overflow buckets）过多，查找效率降低，过小则会浪费存储空间。 据 Google 开发人员称，这个值是一个测试程序测量出来的一个经验值。 %overflow ：溢出率，平均每个桶（bucket）有多少键值对 key/value 时会溢出。 bytes/entry ：存储一个键值对 key/value 时， 所需的额外存储空间（字节）。 hitprobe ：查找一个存在的 key 时，所需的平均查找次数。 missprobe ：查找一个不存在的 key 时，所需的平均查找次数。 经过这几组测试数据，最终选定 6.5 作为临界的装载因子。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:9:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"map header定义 // A header for a Go map. type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler's definition. // 键值对的数量 count int // # live cells == size of map. Must be first (used by len() builtin) // 标识状态 flags uint8 // 2^B = len(buckets) B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) // 溢出桶里bmap大致数量 noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details // hash因子 hash0 uint32 // hash seed // 指向一个数组（连续内存空间），数组类型为[]bmap，bmap类型就是存在键值对的结构 buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. // 扩容时，存放之前的buckets oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing // 分流次数，成倍扩容分流操作计数的字段 nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) // 溢出桶结构，正常桶里面某个bmap存满了，会使用这里面的内存空间存放键值对 extra *mapextra // optional fields } 在Golang的map header结构中，包含2个指向桶数组的指针，buckets指向新的桶数组，oldbuckets指向旧的桶数组。 oldbuckets在哈希表扩容时用于保存旧桶数据，它的大小是当前buckets的一半。 hmap的最后一个字段指向一个mapextra结构的指针。 // mapextra holds fields that are not present on all maps. type mapextra struct { // If both key and elem do not contain pointers and are inline, then we mark bucket // type as containing no pointers. This avoids scanning such maps. // However, bmap.overflow is a pointer. In order to keep overflow buckets // alive, we store pointers to all overflow buckets in hmap.extra.overflow and hmap.extra.oldoverflow. // overflow and oldoverflow are only used if key and elem do not contain pointers. // overflow contains overflow buckets for hmap.buckets. // oldoverflow contains overflow buckets for hmap.oldbuckets. // The indirection allows to store a pointer to the slice in hiter. // 溢出桶，当正常桶存满后就使用hmap.extra.overflow的bmap // bmap.overflow是指针类型，存放了对应使用的hmap.extra.overflow里的bmap地址 overflow *[]*bmap // 扩容时存放之前的overflow oldoverflow *[]*bmap // nextOverflow holds a pointer to a free overflow bucket. // 指向溢出桶里下一个可以使用的bmap nextOverflow *bmap } 如上图所示map里的桶就是bmap，每一个bmap能存储8个键值对。 当map中存储的数据过多，单个桶装满时就会使用extra.overflow中的桶存储溢出的数据。 上面的黄色的bmap就是正常桶，绿色的bmap就是溢出桶。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:10:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"桶的结构体bmap // A bucket for a Go map. type bmap struct { // tophash generally contains the top byte of the hash value // for each key in this bucket. If tophash[0] \u003c minTopHash, // tophash[0] is a bucket evacuation state instead. // tophash包含此桶中每个键的哈希值最高字节（高8位）信息（也就是前面所述的high-order bits）。 // 如果tophash[0] \u003c minTopHash，tophash[0]则代表桶的搬迁（evacuation）状态。 tophash [bucketCnt]uint8 // Followed by bucketCnt keys and then bucketCnt elems. // NOTE: packing all the keys together and then all the elems together makes the // code a bit more complicated than alternating key/elem/key/elem/... but it allows // us to eliminate padding which would be needed for, e.g., map[int64]int8. // Followed by an overflow pointer. } bmap结构体其实不止包含tophash字段，由于 Map 中可能存储不同类型的键值对，并且 Golang 不支持泛型，所以键值对占据的内存空间大小只能在编译时进行推导，这些额外字段在运行时都是通过计算内存地址的方式直接访问的，所以 bmap 的定义中就没有包含这些额外的字段。 这会在编译期间的cmd/compile/internal/gc/reflect.go重建bmap的结构。 type bmap struct { topbits [8]uint8 // 长度为8的数组，元素为：key获取的hash的高8位，遍历时对比使用，提高性能。 keys [8]keytype // 长度为8的数组，[]keytype，元素为：具体的key值 values [8]valuetype // 长度为8的数组，[]elemtype，元素为：键值对的key对应的值 overflow uintptr // 指向hmap.extra.overflow溢出桶里的`bmap`，上面字段长度为8，最多存8组键值对，存满了就往这项的这个bmap存 } // bmap makes the map bucket type given the type of the map. func bmap(t *types.Type) *types.Type { ... field := make([]*types.Field, 0, 5) // The first field is: uint8 topbits[BUCKETSIZE]. arr := types.NewArray(types.Types[TUINT8], BUCKETSIZE) field = append(field, makefield(\"topbits\", arr)) arr = types.NewArray(keytype, BUCKETSIZE) arr.SetNoalg(true) keys := makefield(\"keys\", arr) field = append(field, keys) arr = types.NewArray(elemtype, BUCKETSIZE) arr.SetNoalg(true) elems := makefield(\"elems\", arr) field = append(field, elems) // If keys and elems have no pointers, the map implementation // can keep a list of overflow pointers on the side so that // buckets can be marked as having no pointers. // Arrange for the bucket to have no pointers by changing // the type of the overflow field to uintptr in this case. // See comment on hmap.overflow in runtime/map.go. otyp := types.NewPtr(bucket) if !types.Haspointers(elemtype) \u0026\u0026 !types.Haspointers(keytype) { otyp = types.Types[TUINTPTR] } overflow := makefield(\"overflow\", otyp) field = append(field, overflow) t.MapType().Bucket = bucket bucket.StructType().Map = t return bucket } 编译期间还会生成maptype结构体，定义在runtime/type.go文件中： type maptype struct { typ _type key *_type elem *_type bucket *_type // internal type representing a hash bucket // function for hashing keys (ptr to key, seed) -\u003e hash // hasher的第一个参数就是指向key的指针，h.hash0=fastrand()得到的hash0，就是hasher方法的第二个参数 // hasher方法返回的就是hash值 hasher func(unsafe.Pointer, uintptr) uintptr keysize uint8 // size of key slot elemsize uint8 // size of elem slot bucketsize uint16 // size of bucket flags uint32 } 下面是map的整体结构图 bmap是存放key/value的地方，下面是bmap的内部组成： 上图是桶的内存模型，HOB Hash 指的是 tophash。注意到 key 和 value 是各自放在一起的，并不是 key/value/key/value/… 这样的形式。 如果按照 key/value/key/value/… 这样的形式存储，为了内存对齐，在每一对 key/value 后面都要额外 padding 7 个字节； 而将所有的 key，value 分别绑定到一起，这种形式 key/key/…/value/value/…，则只需要在最后添加 padding。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:11:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"新建map 新建map有两种方式 make(map[k]v) make(map[k]v,hint) 对于不指定初始化大小或初始化大小hint\u003c=8时，会调用makemap_small函数，直接从堆上分配。当hint\u003e8时，调用makemap函数。 而我们考虑的是makemap函数： 主要工作就是分配内存并初始化hmap结构体的各项字段，例如计算B的大小，设置哈希种子hash0等。 func makemap(t *maptype, hint int, h *hmap) *hmap { // math.MulUintptr返回hint与t.bucket.size的乘积，并判断该乘积是否溢出。 mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u003e maxAlloc { hint = 0 } // initialize Hmap if h == nil { h = new(hmap) } // 得到哈希种子 h.hash0 = fastrand() // Find the size parameter B which will hold the requested # of elements. // For hint \u003c 0 overLoadFactor returns false since hint \u003c bucketCnt. // 根据输入的元素个数hint，找到能装下这些元素的B值 B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // 分配初始哈希表 // 如果 B==0，那么buckets字段会在后续的mapassign方法中lazily分配 // allocate initial hash table // if B == 0, the buckets field is allocated lazily later (in mapassign) // If hint is large zeroing this memory could take a while. if h.B != 0 { var nextOverflow *bmap // makeBucketArray创建一个map的底层保存buckets的数组，至少会分配 B^2 的大小 h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 在 B 不为 0 的情况下，会调用 makeBucketArray 函数初始化桶。 当 B \u003c 4 的时候，初始化 hmap 只会生成 8 个桶，不生成溢出桶，因为数据少几乎不可能用到溢出桶； 当 B \u003e= 4 的时候，会额外创建 2^(B−4) 个溢出桶。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:12:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"查找key key经过哈希后得到64位哈希值 用哈希值最后B个bit位计算它落在哪个桶 用哈希值高8位计算它在桶中的索引位置。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:13:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"哈希函数 在初始化go程序环境(src/runtime/proc.go中的schedinit)，需要通过alginit方法完成对哈希的初始化。 maps must not be used before this call func alginit() { // Install AES hash algorithms if the instructions needed are present. if (GOARCH == \"386\" || GOARCH == \"amd64\") \u0026\u0026 cpu.X86.HasAES \u0026\u0026 // AESENC cpu.X86.HasSSSE3 \u0026\u0026 // PSHUFB cpu.X86.HasSSE41 { // PINSR{D,Q} initAlgAES() return } if GOARCH == \"arm64\" \u0026\u0026 cpu.ARM64.HasAES { initAlgAES() return } getRandomData((*[len(hashkey) * sys.PtrSize]byte)(unsafe.Pointer(\u0026hashkey))[:]) hashkey[0] |= 1 // make sure these numbers are odd hashkey[1] |= 1 hashkey[2] |= 1 hashkey[3] |= 1 } 对于哈希算法的选择，程序会根据当前架构判断是否支持AES hash，代码实现位于`src/runtime/asm_{386,amd64,arm64}.s中； 如果不支持，其hash函数则根据xxhash算法（https://code.google.com/p/xxhash/）和cityhash算法（https://code.google.com/p/cityhash/）启发而来， 代码分别对应于32位（src/runtime/hash32.go）和64位机器（src/runtime/hash32.go）中 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:13:1","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"tophash 桶数B，如果B=5，那么桶的总数为2^5=32. 例如，有一个key经过哈希后，得到的哈希值为： 10010111 | 000011110110110010001111001010100010010110010101010 │ 01010 取最后5个bit位，也就是01010，值为10，定位到10号桶。 再用哈希值的高8位，找到此key在当前桶（10号桶）中的索引位置。如果桶中没有key，新加入的key会放入第一个空位 // tophash calculates the tophash value for hash. func tophash(hash uintptr) uint8 { top := uint8(hash \u003e\u003e (sys.PtrSize*8 - 8)) if top \u003c minTopHash { top += minTopHash } return top } 当两个不同的key落在了同一个桶中时，这时就发生了哈希冲突。 go采用链地址法：在桶中按照顺序寻到第一个空位并记录下来，后续在该桶和它的溢出桶中均为发现存在的该key，将key置于第一个空位；否则，去该桶的溢出桶中寻找空位，如果没有溢出桶，添加溢出桶，并将其置于溢出桶的第一个空位. ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:13:2","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"查找操作 v:=m[k],对应的是mapaccess1方法 v,ok:=m[k]，对应的是mapaccess2方法 mapaccess2和mapaccess1的方法逻辑相同，只是多返回了bool返回值。 mapaccessK是for range的逻辑，返回了key和value，代码逻辑也是一样。 我们来看看mapaccess1函数： func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // 如果map为空或元素个数为0，返回零值 if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return unsafe.Pointer(\u0026zeroVal[0]) } // 如果flag为hashWriting，则报错，表示map不是并发安全的 if h.flags\u0026hashWriting != 0 { throw(\"concurrent map read and map write\") } // 不同类型的key，会使用不同的hash算法，在alg.go中的typehash的逻辑 hash := t.hasher(key, uintptr(h.hash0)) m := bucketMask(h.B) // 按位与操作，找到对应的bucket b := (*bmap)(add(h.buckets, (hash\u0026m)*uintptr(t.bucketsize))) // 如果oldbuckets不为空，那么证明map发生了扩容 // 如果有扩容发生，老的buckets中的数据可能还未搬迁到新的bucket中 // 所以要先在老的bucket中查找 if c := h.oldbuckets; c != nil { if !h.sameSizeGrow() { // There used to be half as many buckets; mask down one more power of two. m \u003e\u003e= 1 } oldb := (*bmap)(add(c, (hash\u0026m)*uintptr(t.bucketsize))) // 如果在oldbuckets中的tophash[0]的值，为evacuatedX，evacuatedY，evacuatedEmpty其中之一 // 则evacuated()返回为true，代表搬迁完成 // 因此，只有当搬迁未完成时，未完成时，才会从此oldbuckets中遍历 if !evacuated(oldb) { b = oldb } } // 取出当前key的tophash值 top := tophash(hash) // 以下是查找的核心逻辑 // 双重循环遍历：外层循环是从桶到溢出桶遍历；内层是桶中的cell遍历 // 跳出循环的条件有三种：第一种是找到key值；第二种是当前桶无溢出桶；第三种是当前桶中有cell位的tophash=emptyRest，代表桶还未使用，无需遍历 bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { // 判断tophash是否相等 if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } // 因为在bucket中的key使用连续的存储空间存储，因此可以通过bucket+数据偏移量（bmap结构体大小）+keysize的大小得到k的大小 // 同理，value的地址也是相似的算法，只是要加上8个keysize的内存地址 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } if t.key.equal(key, k) { e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { e = *((*unsafe.Pointer)(e)) } return e } } } return unsafe.Pointer(\u0026zeroVal[0]) } 这里提一下定位key和value的方法： // key的定位公式 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) // value的定位公式 e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:13:3","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"插入key 插入key的过程和查找key的过程大体一致。 // Like mapaccess, but allocates a slot for the key if it is not present in the map. func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { if h == nil { panic(plainError(\"assignment to entry in nil map\")) } // 如果有其他goroutine正在写map，会抛错 if h.flags\u0026hashWriting != 0 { throw(\"concurrent map writes\") } // 通过key和哈希种子，计算哈希值 hash := t.hasher(key, uintptr(h.hash0)) // Set hashWriting after calling t.hasher, since t.hasher may panic, // in which case we have not actually done a write. // 设置写标识位 h.flags ^= hashWriting if h.buckets == nil { h.buckets = newobject(t.bucket) // newarray(t.bucket, 1) } again: // 通过hash与bucketMask按位与操作，返回在buckets数组的第几号桶 bucket := hash \u0026 bucketMask(h.B) // 如果map正在搬迁（即m.oldbuckets!=nil）中，则先进行搬迁工作 if h.growing() { growWork(t, h, bucket) } // 计算出上面求出的第几号桶的内存位置 b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize))) top := tophash(hash) var inserti *uint8 var insertk unsafe.Pointer var elem unsafe.Pointer bucketloop: for { // 遍历桶中的8个cell for i := uintptr(0); i \u003c bucketCnt; i++ { // 这里分为两种情况 // 第一种是cell位的tophash值和当前tophash值不相等，在b.tophash[i] != top的情况下 // 理论上会有一个空槽位，一般情况下map的槽位分布是这样的，e表示empty // [h0][h1][h2][h3][h4][e][e][e] // 但执行过delete操作后，可能变成这样 // [h0][h1][e][e][h5][e][e][e] // 所以如果后面再插入的话，会尽量往前面的位置插 // 在循环的时候还要顺便把前面的空位置先记下来，因为有可能在后面找到相等的key if b.tophash[i] != top { // 如果cell位为空，那么就可以在对应位置进行插入 if isEmpty(b.tophash[i]) \u0026\u0026 inserti == nil { // 赋值当前hash的高8位，标记写入成功 inserti = \u0026b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) } if b.tophash[i] == emptyRest { break bucketloop } continue } // 第二种情况是cell位的tophash值和当前tophash值相等 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() { k = *((*unsafe.Pointer)(k)) } // 即时当前cell位的tophash值相等，不代表它对应的key值也是相等的，所以还要做key值的判断 if !t.key.equal(key, k) { continue } // already have a mapping for key. Update it. // 如果已经有该key了，就更新它 if t.needkeyupdate() { typedmemmove(t.key, k, key) } // 这里获取到了要插入key对应的value的内存地址 // pos = start + dataOffset + 8*keysize + i * elemsize elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) goto done } // 正常桶的bmap遍历完了，继续遍历溢出桶的bmap，如果有的话 ovf := b.overflow(t) if ovf == nil { break } b = ovf } // 在已有的桶和溢出桶中都未找到合适的cell供key写入，那么有可能会触发以下两种情况 // 1、判断当前map的装载因子是否达到设定的6.5阈值，或者当前map的溢出桶数量是否过多，如果存在这两种情况，进行扩容操作。 // hashGrow()实际并未完成扩容，对哈希表数据的搬迁(复制)操作是通过growWork()来完成的 // 重新进入again逻辑，在完成growWork()操作后，再次遍历新的桶 // Did not find mapping for key. Allocate new cell \u0026 add entry. // If we hit the max load factor or we have too many overflow buckets, // and we're not already in the middle of growing, start growing. if !h.growing() \u0026\u0026 (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } // 2、为当前桶新建新的溢出桶，并将tophash，key插入到新建溢出桶的对应内存的0号位置 if inserti == nil { // all current buckets are full, allocate a new one. // 分配新的bmap写 newb := h.newoverflow(t, b) inserti = \u0026newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) elem = add(insertk, bucketCnt*uintptr(t.keysize)) } // store new key/elem at insert position // 在插入位置存入新的key和value if t.indirectkey() { kmem := newobject(t.key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem } if t.indirectelem() { vmem := newobject(t.elem) *(*unsafe.Pointer)(elem) = vmem } typedmemmove(t.key, insertk, key) *inserti = top // map中的key+1 h.count++ done: if h.flags\u0026hashWriting == 0 { throw(\"concurrent map writes\") } h.flags \u0026^= hashWriting if t.indirectelem() { elem = *((*unsafe.Pointer)(elem)) } return elem } 插入key和查找key有几点不同： 如果找到待插入的key，则直接更新对应的value值 会在oldbucket中查找key，但不会再oldbucket中插入key 如果在bmap中没有找到待插入的key 情况一：bmap中还有空位，在遍历bmap的时候预先标记可插入的空位，如果查找结束后也没有找到key，就把key放在预先标记的空位上 情况二：bmap中没有空位了，此时检查一次是否达到了最大装载因子。如果达到了，立即进行扩容操作。扩容后在新桶中插入key，如果没有达到最大装载因子，则新生成一个bmap，并且把前一个bmap的overflow指针指向新的bmap。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:14:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"删除key func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) { if h == nil || h.count == 0 { if t.hashMightPanic() { t.hasher(key, 0) // see issue 23734 } return } if h.flags\u0026hashWriting != 0 { throw(\"concurrent map writes\") } // 计算key的哈希值 hash := t.hasher(key, uintptr(h.hash0)) // Set hashWriting after calling t.hasher, since t.hasher may panic, // in which case we have not actually done a write (delete). h.flags ^= hashWriting bucket := hash \u0026 bucketMask(h.B) // 如果在扩容中，继续扩容 if h.growing() { growWork(t, h, bucket) } // 找到桶的位置 b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize))) bOrig := b top := tophash(hash) search: for ; b != nil; b = b.overflow(t) { // 遍历桶 for i := uintptr(0); i \u003c bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break search } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } if !t.key.equal(key, k2) { continue } // Only clear key if there are pointers in it. // 找到了key，开始清除key和对应的value if t.indirectkey() { // 如果指向的是指针，则指针置nil *(*unsafe.Pointer)(k) = nil } else if t.key.ptrdata != 0 { // 清除key的内存 memclrHasPointers(k, t.key.size) } // 清除value e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize)) if t.indirectelem() { *(*unsafe.Pointer)(e) = nil } else if t.elem.ptrdata != 0 { memclrHasPointers(e, t.elem.size) } else { memclrNoHeapPointers(e, t.elem.size) } // 标记当前桶的当前槽位为空 b.tophash[i] = emptyOne // If the bucket now ends in a bunch of emptyOne states, // change those to emptyRest states. // It would be nice to make this a separate function, but // for loops are not currently inlineable. if i == bucketCnt-1 { if b.overflow(t) != nil \u0026\u0026 b.overflow(t).tophash[0] != emptyRest { goto notLast } } else { if b.tophash[i+1] != emptyRest { goto notLast } } for { b.tophash[i] = emptyRest if i == 0 { if b == bOrig { break // beginning of initial bucket, we're done. } // Find previous bucket, continue at its last entry. c := b for b = bOrig; b.overflow(t) != c; b = b.overflow(t) { } i = bucketCnt - 1 } else { i-- } if b.tophash[i] != emptyOne { break } } notLast: h.count-- break search } } if h.flags\u0026hashWriting == 0 { throw(\"concurrent map writes\") } h.flags \u0026^= hashWriting } 删除key的流程和查找key的流程差不多： 找到对应的key后，清除对应的key和value。如果是指针类型，就把指针置为nil，如果是值就清空值对应的内存。 清除tophash里的值，并做一些标记 把hmap的计数器减1 如果是在扩容过程中，会在扩容完成后在新的bmap中执行删除操作 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:15:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"扩容 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:16:0","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"为什么要扩容？ 因为，随着 Map 中添加的 key 越来越多，key 发生哈希冲突的概率也越来越大。桶中的 8 个槽位会被逐渐塞满，查找、插入、删除 key 的效率也会越来越低，因此需要在 Map 达到一定装载率后进行扩容，保证 Map 的读写性能。 Golang 衡量装载率的指标是装载因子，它的计算方式是： loadFactor := count / (2^B) 其中： count 表示 Map 中的元素个数 2^B 表示桶数量 所以装载因子 loadFactor 的含义是平均每个桶装载的元素个数。Golang 定义的装载因子阈值是 6.5。 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:16:1","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"什么时候扩容？ 插入 key 时会在以下两种情况触发哈希的扩容： 装载因子超过 6.5，增量扩容； 使用了太多溢出桶，等量扩容； 情况 2 中，溢出桶太多的判定标准是： B \u003c 15 时，溢出桶数量 \u003e= 2^B B \u003e= 15 时，溢出桶数量 \u003e= 2^15 // mapassign中触发扩容的时机 if !h.growing() \u0026\u0026 (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } // overLoadFactor reports whether count items placed in 1\u003c\u003cB buckets is over loadFactor. // 达到装载因子的临界点 func overLoadFactor(count int, B uint8) bool { return count \u003e bucketCnt \u0026\u0026 uintptr(count) \u003e loadFactorNum*(bucketShift(B)/loadFactorDen) } // tooManyOverflowBuckets reports whether noverflow buckets is too many for a map with 1\u003c\u003cB buckets. // Note that most of these overflow buckets must be in sparse use; // if use was dense, then we'd have already triggered regular map growth. // 判断溢出桶是否太多。 // 当桶总数\u003c2^15时，如果溢出桶\u003e=桶总数，则认为溢出桶过多。 // 当桶总数\u003e2^15时，当溢出桶\u003e=2^15，则认为溢出桶过多 func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { // If the threshold is too low, we do extraneous work. // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory. // \"too many\" means (approximately) as many overflow buckets as regular buckets. // See incrnoverflow for more details. if B \u003e 15 { B = 15 } // The compiler doesn't see here that B \u003c 16; mask B to generate shorter shift code. return noverflow \u003e= uint16(1)\u003c\u003c(B\u002615) } ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:16:2","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"什么时候采用增量扩容策略？ 触发扩容的第一种情况，随着map中不断插入新的元素，装载因子不断升高直至超过6.5，这时需要增量扩容。 增量扩容后，分配的新桶数量是旧桶的2倍 ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:16:3","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"什么时候采用等量扩容策略？ 触发扩容的第二种情况，在装载因子很小的情况，map的读写效率也很低。这种情况下map中的元素少，但是溢出桶多。 可能造成这种情况的原因是：不断插入元素，不断删除元素。 等量扩容后，分配的新桶数量和旧桶数量相同，但新桶中存储的数据更加紧密。 扩容的相关方法是hashGrow()，但它只是分配了新桶，并没有真正迁移数据 // 没有真正搬迁，只是分配好新的buckets，并将老的buckets挂到oldbuckets字段上 func hashGrow(t *maptype, h *hmap) { // If we've hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \"grow\" laterally. // 看扩容类型 bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } // 记录老的buckets oldbuckets := h.buckets // 申请新的buckets空间 newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) // 转移标志位 flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } // commit the grow (atomic wrt gc) // 提交grow h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets // 搬迁进度为0 h.nevacuate = 0 // noverflow buckets数为0 h.noverflow = 0 // 如果发现hmap是通过extra字段来存储overflow buckets时 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } ","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:16:4","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的GO"],"content":"迁移 执行迁移工作的方法growWork func growWork(t *maptype, h *hmap, bucket uintptr) { // make sure we evacuate the oldbucket corresponding // to the bucket we're about to use // 为了确认搬迁的bucket是我们正在使用的bucket // 即如果当前key映射到老的bucket，那么就搬迁该bucket evacuate(t, h, bucket\u0026h.oldbucketmask()) // evacuate one more oldbucket to make progress on growing // 如果还未完成扩容 if h.growing() { evacuate(t, h, h.nevacuate) } } 负责迁移数据的方法evacuate func evacuate(t *maptype, h *hmap, oldbucket uintptr) { // 首先定位老的bucket的地址 b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) // newbit 代表扩容之前老的bucket个数 newbit := h.noldbuckets() // 判断该bucket是否已经被搬迁 if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // xy contains the x and y (low and high) evacuation destinations. // xy包含了高低区间的搬迁目的地内存信息 // x.b 是对应的搬迁目标桶 // x.k 是指向对应的目的桶中存储当前key的内存地址 // x.e 是指向对应的目的桶中存储当前value的内存地址 var xy [2]evacDst x := \u0026xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) // 只有当增量扩容时才计算bucket y的相关信息 if !h.sameSizeGrow() { // Only calculate y pointers if we're growing bigger. // Otherwise GC can see bad pointers. y := \u0026xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } // evacuate 每次只完成一个bucket的搬迁工作，因此需遍历完此bucket的所有cell，将有值的cell copy到新的地方 // bucket还会链接overflow bucket，同样需要搬迁 for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) // i,k,e对应tophash，key和value for i := 0; i \u003c bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] // 如果当前cell的tophash是 emptyOne/emptyRest ，则代表此cell没有key，将其置为 evacuatedEmpty ，表示已经搬迁 if isEmpty(top) { b.tophash[i] = evacuatedEmpty continue } if top \u003c minTopHash { throw(\"bad map state\") } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 // 如果是增量扩容 if !h.sameSizeGrow() { // Compute hash to make our evacuation decision (whether we need // to send this key/elem to bucket x or bucket y). // 计算哈希值，判断当前的key和value是否需要搬迁到bucket x/y hash := t.hasher(k2, uintptr(h.hash0)) if h.flags\u0026iterator != 0 \u0026\u0026 !t.reflexivekey() \u0026\u0026 !t.key.equal(k2, k2) { // If key != key (NaNs), then the hash could be (and probably // will be) entirely different from the old hash. Moreover, // it isn't reproducible. Reproducibility is required in the // presence of iterators, as our evacuation decision must // match whatever decision the iterator made. // Fortunately, we have the freedom to send these keys either // way. Also, tophash is meaningless for these kinds of keys. // We let the low bit of tophash drive the evacuation decision. // We recompute a new random tophash for the next level so // these keys will get evenly distributed across all buckets // after multiple grows. // 有一种特殊情况：有一种key，每次对它的计算hash得到的结果不一样。 // 这个key就是 math.NaN() 的结果，它的含义是not a number，类型是float64 // 把它当做map的key时，会遇到一个问题：再次计算它的哈希值和它刚插入map时计算的哈希值不一样 // 这个key是永远不会被Get操作获取的，当使用m[math.NaN()]语句时，是查不出结果的，这个key只有在遍历整个map时，才能被找到 // 并且，可以向一个 map 插入多个数量的 math.NaN() 作为 key，它们并不会被互相覆盖。 // 当搬迁碰到 math.NaN() 的 key 时，只通过 tophash 的最低位决定分配到 X part 还是 Y part（如果扩容后是原来 buckets 数量的 2 倍）。 // 如果 tophash 的最低位是 0 ，分配到 X part；如果是 1 ，则分配到 Y part。 useY = top \u0026 1 top = tophash(hash) } else { if hash\u0026newbit != 0 { useY = 1 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\"bad evacuatedN\") } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY // useY要么为0，要么为1。这里就是选取在bucket x的起始内存位置，或者选择在bucket y的起始内存位置（只有增量同步才会有这个选择可能）。 dst := \u0026xy[useY] // evacuation destination // 如果目的地桶已经装满（8个cell），那么需要新建一个溢出桶，继续搬迁到溢出桶上去 if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst","date":"2021-07-14","objectID":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/:16:5","tags":["源码解析","map"],"title":"深入理解Golang Map","uri":"/2021/07/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3map/"},{"categories":["月霜天的小笔记"],"content":"一、什么是幂等？ 幂等（idempotent、idempotence）是一个数学与计算机学概念，常见于抽象代数中。 在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“setTrue()”函数就是一个幂等函数,无论多次执行，其结果都是一样的.更复杂的操作幂等保证是利用唯一交易号(流水号)实现。 幂等性：就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:1:0","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"二、使用场景 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:2:0","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"1、前端重复提交 用户注册，用户创建商品等操作，前端都会提交一些数据给后台服务，后台需要根据用户提交的数据在数据库中创建记录。如果用户不小心多点了几次，后端收到了好几次提交，这时就会在数据库中重复创建了多条记录。这就是接口没有幂等性带来的 bug。 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:2:1","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"2、接口超时重试 对于给第三方调用的接口，有可能会因为网络原因而调用失败，这时，一般在设计的时候会对接口调用加上失败重试的机制。如果第一次调用已经执行了一半时，发生了网络异常。这时再次调用时就会因为脏数据的存在而出现调用异常。 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:2:2","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"3、消息重复消费 在使用消息中间件来处理消息队列，且手动 ack 确认消息被正常消费时。如果消费者突然断开连接，那么已经执行了一半的消息会重新放回队列。 当消息被其他消费者重新消费时，如果没有幂等性，就会导致消息重复消费时结果异常，如数据库重复数据，数据库数据冲突，资源重复等。 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:2:3","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"三、解决方案 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:3:0","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"1、token机制 通过token 机制实现接口的幂等性,这是一种比较通用性的实现方法。 流程： 1、客户端会先发送一个请求去获取 token，服务端会生成一个全局唯一的 ID 作为 token 保存在 redis 中，同时把这个 ID 返回给客户端 2、客户端第二次调用业务请求的时候必须携带这个 token 3、服务端会校验这个 token，如果校验成功，则执行业务，并删除 redis 中的 token 4、如果校验失败，说明 redis 中已经没有对应的 token，则表示重复操作，直接返回指定的结果给客户端 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:3:1","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"2、mysql锁 这种实现方式是利用 mysql 唯一索引的特性 流程： 1、建立一张去重表，其中某个字段需要建立唯一索引 2、客户端去请求服务端，服务端会将这次请求的一些信息插入这张去重表中 3、因为表中某个字段带有唯一索引，如果插入成功，证明表中没有这次请求的信息，则执行后续的业务逻辑 4、如果插入失败，则代表已经执行过当前请求，直接返回 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:3:2","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"3、redis锁 这种实现方式是基于 SETNX 命令实现的 流程： 1、客户端先请求服务端，会拿到一个能代表这次请求业务的唯一字段 2、将该字段以 SETNX 的方式存入 redis 中，并根据业务设置相应的超时时间 3、如果设置成功，证明这是第一次请求，则执行后续的业务逻辑 4、如果设置失败，则代表已经执行过当前请求，直接返回 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:3:3","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的小笔记"],"content":"总结 这几种实现幂等的方式其实都是大同小异的，类似的还有使用状态机、悲观锁、乐观锁的方式来实现，都是比较简单的。 类似于分布锁： 数据库锁，一个表中包含方法名等字段，并在方法名字段上创建唯一索引 redis锁，setnx为锁添加一个超时时间 zookeeper锁：创建目录，在目录下创建临时顺序节点，获取最小顺序节点号 ","date":"2021-07-07","objectID":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/:4:0","tags":["api"],"title":"幂等性","uri":"/2021/07/%E5%B9%82%E7%AD%89%E6%80%A7/"},{"categories":["月霜天的GO"],"content":"在标准库中有个sync/errgroup，实现对多goroutine进行错误处理。 接下来我们看一下源码： type Group struct { cancel func() wg sync.WaitGroup errOnce sync.Once err error } func WithCancel(ctx context.Context) (*Group, context.Context) { ctx, cancel := context.WithCancel(ctx) return \u0026Group{cancel: cancel}, ctx } func (g *Group) Wait() error { g.wg.Wait() if g.cancel != nil { g.cancel() } return g.err } func (g *Group) Go(f func() error) { g.wg.Add(1) go func() { defer g.wg.Done() if err := f(); err != nil { g.errOnce.Do(func() { g.err = err if g.cancel != nil { g.cancel() } }) } }() } 很简单的实现，使用sync.WaitGroup做并发控制，用sync.Once做错误返回，使用context做上下文的处理。 ","date":"2021-07-05","objectID":"/2021/07/errgroup%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/:0:0","tags":["sync","errgroup"],"title":"Errgroup的实际应用","uri":"/2021/07/errgroup%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/"},{"categories":["月霜天的GO"],"content":"例子一 func main() { g := new(errgroup.Group) var urls = []string{ \"http://www.golang.org/\", \"https://golang2.eddycjy.com/\", \"https://eddycjy.com/\", } for _, url := range urls { url := url g.Go(func() error { resp, err := http.Get(url) if err == nil { resp.Body.Close() } return err }) } if err := g.Wait(); err == nil { fmt.Println(\"Successfully fetched all URLs.\") } else { fmt.Printf(\"Errors: %+v\", err) } } ","date":"2021-07-05","objectID":"/2021/07/errgroup%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/:1:0","tags":["sync","errgroup"],"title":"Errgroup的实际应用","uri":"/2021/07/errgroup%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/"},{"categories":["月霜天的GO"],"content":"例子二 func main() { g, ctx := errgroup.WithContext(context.Background()) svr := http.NewServer() // http server g.Go(func() error { fmt.Println(\"http\") go func() { \u003c-ctx.Done() fmt.Println(\"http ctx done\") svr.Shutdown(context.TODO()) }() return svr.Start() }) // signal g.Go(func() error { exitSignals := []os.Signal{os.Interrupt, syscall.SIGTERM, syscall.SIGQUIT, syscall.SIGINT} // SIGTERM is POSIX specific sig := make(chan os.Signal, len(exitSignals)) signal.Notify(sig, exitSignals...) for { fmt.Println(\"signal\") select { case \u003c-ctx.Done(): fmt.Println(\"signal ctx done\") return ctx.Err() case \u003c-sig: // do something return nil } } }) // inject error g.Go(func() error { fmt.Println(\"inject\") time.Sleep(time.Second) fmt.Println(\"inject finish\") return errors.New(\"inject error\") }) err := g.Wait() // first error return fmt.Println(err) } ","date":"2021-07-05","objectID":"/2021/07/errgroup%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/:2:0","tags":["sync","errgroup"],"title":"Errgroup的实际应用","uri":"/2021/07/errgroup%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/"},{"categories":["月霜天的GO"],"content":"虽然golang的定时器经过几版的改进优化，但是仍然是性能的大杀手。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:0:0","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"golang1.13和1.14的区别 golang在1.10版本之前是由一个独立的timerproc通过小顶堆和futexsleep来管理定时任务。1.10版本之后是把独立的timerproc和小顶堆分成最多64个timerproc协程和四叉堆，用来休眠的方式还是 futexsleep 而1.14版的timer是把存放定时事件的四叉堆放到了P结构中，同时取消了timerproc协程，转而使用netpoll的epoll wait来做就近时间的休眠等待。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:1:0","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"函数签名 对于NewTimer函数，我们可以找到实现 time/sleep.go#L82。其实我们可以发现，NewTimer、NewTicker、After其实都是调用addTimer来新增定时任务。 type Timer struct { C \u003c-chan Time r runtimeTimer } // NewTimer creates a new Timer that will send // the current time on its channel after at least duration d. func NewTimer(d Duration) *Timer { c := make(chan Time, 1) t := \u0026Timer{ C: c, r: runtimeTimer{ when: when(d), f: sendTime, arg: c, }, } startTimer(\u0026t.r) return t } func sendTime(c interface{}, seq uintptr) { select { case c.(chan Time) \u003c- Now(): default: } } func NewTicker(d Duration) *Ticker { if d \u003c= 0 { panic(errors.New(\"non-positive interval for NewTicker\")) } c := make(chan Time, 1) t := \u0026Ticker{ C: c, r: runtimeTimer{ when: when(d), period: int64(d), f: sendTime, arg: c, }, } startTimer(\u0026t.r) return t } 这里主要分成两步： 1、创建一个Timer对象，包含一个具有缓冲区channel的c，用来接收Timer消息的，包含的runtimeTimer结构体，when是代表timer触发的绝对时间(当前时间+d)，f是timer触发时的回调函数，arg是传给f的参数。 2、调用startTimer，实际上是调用runtime包下的addtimer函数。 3、NewTicker调用的是相同的函数，只是多了一个字段period，表示计时器再次被唤醒的时间，做轮询触发。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:2:0","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"golang1.13的定时器原理 首先会初始化一个长度为64的timers数组，通过协程的p的id取模来分配timersBucket，如果发现新的定时任务比较新，那么调用notewakeup来激活唤醒timerproc的futex等待。如果发现没有实例化timerproc，则启动。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:0","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"1、添加定时器 func addtimer(t *timer) { tb := t.assignBucket() lock(\u0026tb.lock) ok := tb.addtimerLocked(t) unlock(\u0026tb.lock) if !ok { badTimer() } } 可以看到addtimer做了两件事： 1、assignBucket找到可以被插入的bucket 2、addtimerLocked将timer插入到bucket ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:1","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"2、timersBucket const timersLen = 64 // timer包含每个P的堆，timer进入队列中关联当前的P，所以每个P中timer都是独立于其他P的 // 如果GOMAXPROCS \u003e timersLen，那么timersBucket可能会管理多个P var timers [timersLen]struct { timersBucket // 内存对齐 pad [cpu.CacheLinePadSize - unsafe.Sizeof(timersBucket{})%cpu.CacheLinePadSize]byte } type timersBucket struct { lock mutex gp *g created bool sleeping bool rescheduling bool sleepUntil int64 waitnote note t []*timer } 在runtime中，有64个全局定义的timer bucket。每个bucket负责管理timer。timer的整个生命周期包括创建、销毁、唤醒、睡眠等都是由timer bucket管理和调度。 问：为什么是64个timer bucket? 答：在1.10版本之前，只有1个timers对象，在添加定时器任务时都需要对timers进行加锁和解锁操作，影响性能；当timer过多，timers中的t很多，添加进四叉堆操作可能耗时比较长，可能会导致timer的延迟。因此引入全局64个分桶的策略，将timer分散到桶中，每个桶只负责自己的timer，有效降低了锁的粒度和timer调度的负担。 而根据最优的情况下，应该是分桶的数量应该要和GOMAXPROCS数量一致，有多少个P就有多少个timer bucket。但是，这就涉及到P的动态分配问题，所以在性能的权衡下，使用64 能够覆盖大多数的场景。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:2","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"3、分配桶 func (t *timer) assignBucket() *timersBucket { id := uint8(getg().m.p.ptr().id) % timersLen t.tb = \u0026timers[id].timersBucket return t.tb } ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:3","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"4、添加timer到四叉堆 func (tb *timersBucket) addtimerLocked(t *timer) bool { // 此时when应该是当前时间+duration if t.when \u003c 0 { t.when = 1\u003c\u003c63 - 1 } // 将timer添加到四叉堆中 t.i = len(tb.t) tb.t = append(tb.t, t) if !siftupTimer(tb.t, t.i) { return false } // 首次添加 if t.i == 0 { // 如果timerproc在sleep，唤醒它 if tb.sleeping \u0026\u0026 tb.sleepUntil \u003e t.when { tb.sleeping = false notewakeup(\u0026tb.waitnote) } // 如果timerproc被挂起了，重新调度 if tb.rescheduling { tb.rescheduling = false goready(tb.gp, 0) } // 如果timer的桶还没有创建，创建并开始timerproc if !tb.created { tb.created = true go timerproc(tb) } } return true } 问：为什么是四叉堆？ 答：上推节点的操作更快；对缓存更友好。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:4","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"5、timerproc // timerproc 外层循环不会退出 func timerproc(tb *timersBucket) { tb.gp = getg() for { lock(\u0026tb.lock) // 修改睡眠标识 tb.sleeping = false // 当前时间 now := nanotime() delta := int64(-1) for { // 如果桶内没有timer，退出 if len(tb.t) == 0 { delta = -1 break } // 获取最早触发的timer t := tb.t[0] delta = t.when - now // 还没有到达触发时间，退出 if delta \u003e 0 { break } ok := true if t.period \u003e 0 { // 需要周期性触发定时器，需要修改timer的触发时间，重新添加到最小堆中 // leave in heap but adjust next time to fire t.when += t.period * (1 + -delta/t.period) if !siftdownTimer(tb.t, 0) { ok = false } } else { // 从最小堆中移除 last := len(tb.t) - 1 if last \u003e 0 { tb.t[0] = tb.t[last] tb.t[0].i = 0 } tb.t[last] = nil tb.t = tb.t[:last] if last \u003e 0 { if !siftdownTimer(tb.t, 0) { ok = false } } t.i = -1 // 下标标记为-1，deltimer发现下标为-1时就不删除了 } f := t.f arg := t.arg seq := t.seq unlock(\u0026tb.lock) if !ok { badTimer() } if raceenabled { raceacquire(unsafe.Pointer(t)) } f(arg, seq) lock(\u0026tb.lock) } if delta \u003c 0 || faketime \u003e 0 { // 如果桶中没有timer，把协程挂起 tb.rescheduling = true goparkunlock(\u0026tb.lock, waitReasonTimerGoroutineIdle, traceEvGoBlock, 1) continue } // 如果还有timer，睡眠到桶内最早触发的时间点后唤醒 tb.sleeping = true tb.sleepUntil = now + delta noteclear(\u0026tb.waitnote) unlock(\u0026tb.lock) notetsleepg(\u0026tb.waitnote, delta) } } ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:5","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"6、小结 1、首选预分配64个的timer bucket，timer bucket里面是一个四叉堆存放timer 2、每次新增的timer，添加到四叉堆中，会尝试唤醒和调度bucket 3、第一次新增的bucket会运行协程timerproc。timerproc是一个死循环，周期性地检查定时器状态。 4、每次从最小堆中取出timer，如果是计时器，则重新加入到bucket中。如果bucket没有timer，则将timerproc挂起。如果还有timer，则睡眠到bucket中堆顶唤醒的时间。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:3:6","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"深度分析golang1.14定时器 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:0","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"1、timer type timer struct { // If this timer is on a heap, which P's heap it is on. // puintptr rather than *p to match uintptr in the versions // of this struct defined in other packages. pp puintptr // 计时器所在的处理器P的指针地址 // Timer wakes up at when, and then at when+period, ... (period \u003e 0 only) // each time calling f(arg, now) in the timer goroutine, so f must be // a well-behaved function and not block. when int64 // 计时器被唤醒的时间 period int64 // 计时器再次被唤醒的时间（周期） f func(interface{}, uintptr) // 回调函数，每次在计时器被唤醒时都会调用 arg interface{} // 回调函数的参数 seq uintptr // 回调函数的参数，仅在netpoll的应用场景下使用 // What to set the when field to in timerModifiedXX status. nextwhen int64 // 当计时器状态为timerModifiedXX时，将会使用nextwhen设置到where字段上 // The status field holds one of the values below. status uint32 // 计时器当前的状态值 } ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:1","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"2、p 在添加方式上，go1.14发生了变更，改为将每个timer存储在处理器p上。这也是我们之前提到的优化结构，64只能泛指大多数情况，实际都是需要p进行处理。所以go1.14里的p结构中有了timers字段。 type p struct { ... timersLock mutex timers []*timer ... } 同样，在timers数组仍是一个最小四叉堆。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:2","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"3、定时器状态 // Values for the timer status field. const ( // timer尚未设置状态 timerNoStatus = iota // 等待timer启动 timerWaiting // 运行timer的回调方法 timerRunning // timer已经被删除，但仍然在某些p的堆中 timerDeleted // timer即将被删除 timerRemoving // timer已经停止，且不存在任何p的堆中 timerRemoved // timer正在被修改 timerModifying // timer已被修改为更早的时间，新的时间被设置在nextwhen字段中， timerModifiedEarlier // timer已被修改为更迟的时间，新的时间被设置在nextwhen字段中， timerModifiedLater // timer已经被修改，正在被移动 timerMoving ) 因为涉及到p的管理，所以新增了10个timer的状态管理。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:3","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"4、启动定时器 func addtimer(t *timer) { // when must never be negative; otherwise runtimer will overflow // during its delta calculation and never expire other runtime timers. // 边界条件判断 if t.when \u003c 0 { t.when = maxWhen } // timer的状态为timerNoStatus if t.status != timerNoStatus { throw(\"addtimer called with initialized timer\") } t.status = timerWaiting when := t.when pp := getg().m.p.ptr() lock(\u0026pp.timersLock) // 清除处理器p中的计时器队列，可以加快创建和删除计时器的程序的速度 cleantimers(pp) // 将当前所新创建的timer新增到p的堆中 doaddtimer(pp, t) unlock(\u0026pp.timersLock) // 唤醒网络轮询器中休眠的线程，检查timer被唤醒的时间(when)是否在当前轮询预期运行的时间(pollerPollUntil)内，若是则唤醒 wakeNetPoller(when) } 添加timer到当前的p上，这应该只在一个新创建的timer中调用，这避免了更改某些p的最小堆timer的when字段的风险，因为这可能导致最小堆乱序。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:4","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"5、停止定时器 在定时器的运行中，一般会调用timer.Stop方法来停止/删除定时器，其实就是让这个timer从处理器p的堆中移除。 timerWaiting/timerModifiedLater：修改timer状态为timerDeleted，删除数量+1 timerModifiedEarlier：修改timer状态为timerDeleted，删除数量+1，adjustTimers+1 timerDeleted/timerRemoving/timerRemoved：无需变更，已经满足条件 timerRunning/timerMoving/timerModifying：正在执行、移动中，无法停止，等待下一次状态检查再处理 timerNoStatus：无法停止，不满足条件 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:5","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"6、修改/重置定时器 在程序调度中，有些因为逻辑改变，需要重置定时器。一般会调用timer.Reset()来重设Duration值。 func resettimer(t *timer, when int64) { modtimer(t, when, t.period, t.f, t.arg, t.seq) } 实际调用modtimer方法。 timerRunning/timerRemoving/timerMoving/timerModifying：等待状态改变 timerDeleted-\u003etimerModifying-\u003etimerModifiedXXX timerNoStatus/timerRemoved-\u003etimerModifying-\u003etimerWaiting timerWaiting/timerModifiedXXX-\u003etimerModifying-\u003etimerModifiedXXX 在处理完处理器的状态后，会分为两种情况进行处理： 1、待修改的定时器已经被删除：由于原定时器没有了，所以会调用doaddtimer方法创建一个定时器，并赋值原先的timer，再调用wakeNetPoller在预定的时间唤醒网络轮询器 2、正常逻辑处理：如果修改后的定时器的触发时间小于原本的触发是按，则修改定时器状态为timerModifiedEalier，并调用wakeNetPoller在预定的时间唤醒网络轮询器 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:6","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"7、触发定时器 前面提到过，timers已经归属到p中去了，所以定时器的触发分成两个部分： 通过调度器在调度时进行定时器的触发 通过系统监控检查并触发定时器（到期未执行） 1、调度器触发 调度器触发一般分为两种情况。 一种是调度循环中调用checkTimers方法进行计时器的触发 func schedule() { _g_ := getg() ... top: pp := _g_.m.p.ptr() pp.preempt = false ... checkTimers(pp, 0) ... execute(gp, inheritTime) } 另一种是当前处理器p没有可执行的timer，且没有可执行的G。那么按照调度模型，就会去窃取其他定时器和G: func findrunnable() (gp *g, inheritTime bool) { _g_ := getg() ... top: _p_ := _g_.m.p.ptr() ... now, pollUntil, _ := checkTimers(_p_, 0) ... } 我们来进一步分析checkTimers方法： 1、检查处理器p上是否有需要处理的timer 2、如果没有需要执行的timer，则直接返回；否则，判断标记为删除的timer数量如果小于p上的timer数量则直接返回 3、对需要处理的timer，根据时间将timers重新排序 4、在调整完timers后，调用runtimer方法真正执行timer，触发定时器 5、在最后的阶段，如果被标记为删除的timer数量如果大于p上的timer数量，则对标记为删除的timer进行清理。 2、系统监控触发 通过每次调度器调度和窃取的是否触发，还是有一定的随机性。 因此需要一个系统监控来触发定时器。 func sysmon() { ... for { ... next, _ := timeSleepUntil() if debug.schedtrace \u003c= 0 \u0026\u0026 (sched.gcwaiting != 0 || atomic.Load(\u0026sched.npidle) == uint32(gomaxprocs)) { lock(\u0026sched.lock) if atomic.Load(\u0026sched.gcwaiting) != 0 || atomic.Load(\u0026sched.npidle) == uint32(gomaxprocs) { if next \u003e now { atomic.Store(\u0026sched.sysmonwait, 1) unlock(\u0026sched.lock) // Make wake-up period small enough // for the sampling to be correct. sleep := forcegcperiod / 2 if next-now \u003c sleep { sleep = next - now } shouldRelax := sleep \u003e= osRelaxMinNS if shouldRelax { osRelax(true) } notetsleep(\u0026sched.sysmonnote, sleep) if shouldRelax { osRelax(false) } now = nanotime() next, _ = timeSleepUntil() lock(\u0026sched.lock) atomic.Store(\u0026sched.sysmonwait, 0) noteclear(\u0026sched.sysmonnote) } idle = 0 delay = 20 } unlock(\u0026sched.lock) } ... // poll network if not polled for more than 10ms lastpoll := int64(atomic.Load64(\u0026sched.lastpoll)) if netpollinited() \u0026\u0026 lastpoll != 0 \u0026\u0026 lastpoll+10*1000*1000 \u003c now { atomic.Cas64(\u0026sched.lastpoll, uint64(lastpoll), uint64(now)) list := netpoll(0) // non-blocking - returns list of goroutines if !list.empty() { incidlelocked(-1) injectglist(\u0026list) incidlelocked(1) } } if next \u003c now { startm(nil, false) } ... } } 1、在每次系统监控时，都会在流程上调用timeSleepUntil方法去获取下一个定时器应触发的时间，以及保存改定时器已经打开的定时器堆的p. 2、检查当前是否存在GC，若正在STW则获取调度互斥锁。若发现下一个timer触发时间已经过去，则重新调用timeSleepUntil获取下一个定时器的时间和相应的p。 3、如果发现超过10ms没有进行netpoll网络轮询，则主动调用netpoll方法触发轮询 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:7","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"8、运行定时器 这里来分析一下runtimer方法： 只有被标记为timerWaiting状态的定时器才能运行，尝试将状态更新为timerRunning，然后执行runOneTimer方法。 标记为timerDeleted状态的定时器会去删除定时器，标记为timerModifiedXXX状态的定时器会去重新添加定时器。 func runOneTimer(pp *p, t *timer, now int64) { f := t.f arg := t.arg seq := t.seq if t.period \u003e 0 { // ticker，需要再次触发 // 重新计算下一次的触发时间，并且更新其在最小堆 delta := t.when - now t.when += t.period * (1 + -delta/t.period) siftdownTimer(pp.timers, 0) // 将状态修改为timerWaiting if !atomic.Cas(\u0026t.status, timerRunning, timerWaiting) { badTimer() } // 设置p的下一次触发时间 updateTimer0When(pp) } else { // 移除timer dodeltimer0(pp) if !atomic.Cas(\u0026t.status, timerRunning, timerNoStatus) { badTimer() } } unlock(\u0026pp.timersLock) // 回调方法 f(arg, seq) lock(\u0026pp.timersLock) } ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:8","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"9、小结 通过大致的go1.14源码分析，可以看出有以下改变： 在每个处理器p中，timers以最小四叉堆方式存储 在调度器的每轮跳读中都会对定时器进行触发和检查 在系统监听netpoll会定时进行定时器的触发和检查 在定时器的处理中，10个状态的流转和处理变化 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:4:9","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的GO"],"content":"总结 go1.13最多可以开到GOMAXPROCS数量的timerproc协程，当然不超过64。但我们要知道timerproc自身就是协程，也需要runtime pmg的调度。反而go 1.14把检查到期定时任务的工作交给了runtime.schedule，不需要额外的调度，每次runtime.schedule和findrunable时直接运行到期的定时任务。 线程上下文切换开销？新添加的定时任务的到期时间更小时，不管是使用futex还是epoll_wait系统调用都会被唤醒重新休眠，被唤醒的线程会产生上下文切换。但由于go1.14没有timerproc的存在，新定时任务可直接插入或多次插入后再考虑是否休眠。 结论，golang 1.13的定时器在任务繁多时，必然会造成更多的上线文切换及runtime pmg调度，而golang 1.14做了更好的优化。 ","date":"2021-07-01","objectID":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/:5:0","tags":["源码解析","time"],"title":"Go定时器源码分析","uri":"/2021/07/go%E5%AE%9A%E6%97%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"categories":["月霜天的小笔记"],"content":"零、前言 redis的主要知识点 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:1:0","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"一、基础 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:0","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"1、redis是什么？ Redis是一个数据库，不过与传统RDBM(关系型数据库)不同，Redis属于NoSQL，也就是非关系型数据库，它的存储结构是Key-Value。Redis的数据直接存在内存中，读写速度非常快，因此 Redis被广泛应用于缓存方向。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:1","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"2、NoSQL的BASE理论 BASE理论是CAP中一致性的妥协。和传统事务的ACID截然不同，BASE不追求强一致性，而是允许数据在一段时间内是不一致的，但最终达到一致状态，从而获得更高的可用性和性能。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:2","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"3、常用的redis命令 读操作是get a，表示获取a对应的数据 写操作是setex a t b，表示将a的数据设置为b，并且在t秒后过期。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:3","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"4、Redis的过期键清除策略 过期键清除策略有三种，分别是定时删除、定期删除和惰性删除。 定时删除，是在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作 定期删除，每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键 惰性删除，是指使用的时候，发现Key过期了，此时再进行删除 Redis过期键采用的是定期删除+惰性删除二者结合的方式进行删除的。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:4","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"5、如果过期键没有被访问，而周期性删除又跟不上新键产生的速度，内存不就慢慢耗尽了吗？ Redis支持内存淘汰，配置参数maxmemory_policy决定了内存淘汰策略的策略。这个参数一共有8个枚举值。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:5","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"6、内存淘汰用到的是LRU算法？ Redis用的是近似LRU算法，LRU算法需要一个双向链表来记录数据的最近被访问顺序，但是出于节省内存的考虑，Redis的LRU算法并非完整的实现。 Redis通过对少量键进行取样，然后和目前维持的淘汰池综合比较，回收其中的最久未被访问的键。通过调整每次回收时的采样数量maxmemory-samples，可以实现调整算法的精度。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:2:6","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"二、数据结构 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:0","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"1、redis的数据结构 对外暴露5种Redis对象，分别是String、List、Hash、Set、Zset。底层实现依托于sds、ziplist、skiplist、dict等更基础数据结构。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:1","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"2、Redis字符串的特点 Redis的字符串如果保存的对象是整数类型，那么就用int存储。如果不能用整数表示，就用SDS来表示，SDS通过记录长度，和预分配空间，可以高效计算长度，进行append操作。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:2","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"3、hash扩容过程 两张Hash表，平常起作用的都是0号表，当装载因子超过阈值时就会进行Rehash，将0号每上每一个bucket慢慢移动到1号表，所以叫渐进式Rehash，这种方式可以减少迁移系统的影响。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:3","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"4、rehash过程 当周期函数发现为装载因子超过阈值时就会进行Rehash。Rehash的流程大概分成三步。 首先，生成新Hash表ht[1]，为 ht[1] 分配空间。此时字典同时持有ht[0]和ht[1]两个哈希表。字典的偏移索引从静默状态-1，设置为0，表示Rehash 工作正式开始。 然后，迁移ht[0]数据到ht[1]。在 Rehash进行期间，每次对字典执行增删查改操作，程序会顺带迁移一个ht[0]上的数据，并更新偏移索引。与此同时，周期函数也会定时迁移一批。 最后，ht[1]和ht[0]指针对象交换。随着字典操作的不断执行， 最终在某个时间点上，ht[0]的所有键值对都会被Rehash至 ht[1]，此时再将ht[1]和ht[0]指针对象互换，同时把偏移索引的值设为-1，表示Rehash操作已完成。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:4","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"5、如果字典正在Rehash，此时有请求过来，Redis会怎么处理？ 针对新增Key，是往ht[1]里面插入。针对读请求，先从ht[0]读，没找到再去ht[1]找。至于删除和更新，其实本质是先找到位置，再进行操作，所以和读请求一样，先找ht[0]，再找ht[1]，找到之后再进行操作。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:5","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"6、跳表的实现 跳表本质上是对链表的一种优化，通过逐层跳步采样的方式构建索引，以加快查找速度。如果只用普通链表，只能一个一个往后找。跳表就不一样了，可以高层索引，一次跳跃多个节点，如果找过头了，就用更下层的索引。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:6","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"7、每个节点有多少层？ 使用概率均衡的思路，确定新插入节点的层数。Redis使用随机函数决定层数。直观上来说，默认1层，和丢硬币一样，如果是正面就继续往上，这样持续迭代，最大层数32层。 50%的概率被分配到第一层，25%的概率被分配到第二层，12.5%的概率被分配到第三层。这种方式保证了越上层数量越少，自然跨越起来越方便。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:7","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"8、Redis的Zset为什么同时需要字典和跳表来实现 Zset是一个有序列表，字典和跳表分别对应两种查询场景，**字典用来支持按成员查询数据，跳表则用以实现高效的范围查询，**这样两个场景，性能都做到了极致。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:3:8","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"三、系统容灾 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:0","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"1、Redis是基于内存的存储，如果服务重启，数据不就丢失了吗？ 可以通过持久化机制，备份数据。 有两种方式，一种是开启RDB，RDB是Redis的二进制快照文件，优点是文件紧凑，占用空间小，恢复速度比较快。同时，由于是子进程Fork的模式，对Redis本身读写性能的影响很小。 另一种方式是AOF，AOF中记录了Redis的操作命令，可以重放请求恢复现场，AOF的文件会比RDB大很多。 出于性能考虑，如果开启了AOF，会将命令先记录在AOF缓冲，之后再刷入磁盘。数据刷入磁盘的 时机根据参数决定，有三种模式：1.关闭时刷入；2.每秒定期刷入；3.执行命令后立刻触发。 AOF的优点是故障情况下，丢失的数据会比RDB更少。如果是执行命令后立马刷入，AOF会拖累执行速度，所以一般都是配置为每秒定期刷入，这样对性能影响不会很大。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:1","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"2、这样看起来，AOF文件会越来越大，最后磁盘都装不下 不会的，Redis可以在AOF文件体积变得过大时，自动地在后台Fork一个子进程，专门对AOF进行重写。说白了，就是针对相同Key的操作，进行合并，比如同一个Key的set操作，那就是后面覆盖前面。 在重写过程中，Redis不但将新的操作记录在原有的AOF缓冲区，而且还会记录在AOF重写缓冲区。一旦新AOF文件创建完毕，Redis 就会将重写缓冲区内容，追加到新的AOF文件，再用新AOF文件替换原来的AOF文件。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:2","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"3、Redis机器挂掉怎么办？ 可以用主从模式部署，即有一个或多个备用机器，备用机会作为Slave同步Master的数据，在Redis出现问题的时候，把Slave升级为Master。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:3","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"4、主从可以自动切换吗？ 本身是不能，但可以写脚本实现，只是需要考虑的问题比较多。Redis已经有了现成的解决方案：哨兵模式。哨兵来监测Redis服务是否正常，异常情况下，由哨兵代理切换。为避免哨兵成为单点，哨兵也需要多机部署 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:4","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"5、如果Master挂掉，会选择哪个Slave呢？ 当哨兵集群选举出哨兵Leader后，由哨兵Leader从Redis从节点中选择一个Redis节点作为主节点： 1、过滤故障的节点； 2、选择优先级slave-priority最大的从节点作为主节点，如不存在，则继续 3、选择复制偏移量最大的从节点作为主节点，如果都一样，则继续。这里解释下，数据偏移量记录写了多少数据，主服务器会把偏移量同步给从服务器，当主从的偏移量一致，则数据是完全同步 4、选择runid最小的从节点作为主节点。Redis每次启动的时候生成随机的runid作为Redis的标识 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:5","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"6、哨兵Leader，那它是怎么来的呢？ 每一个哨兵节点都可以成为Leader，当一个哨兵节点确认Redis集群的主节点主观下线后，会请求其他哨兵节点要求将自己选举为Leader。被请求的哨兵节点如果没有同意过其他哨兵节点的选举请求，则同意该请求，也就是选举票数+1，否则不同意。 如果一个哨兵节点获得的选举票数超过节点数的一半，且大于quorum配置的值，则该哨兵节点选举为Leader；否则重新进行选举。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:4:6","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"四、性能优化 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:5:0","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"1、redis性能 只能说在十万级。使用之前，要跑BenchMark，实际情况下会受带宽、负载、单个数据大小、是否开启多线程等因素影响，脱开具体场景谈性能，就没有意义。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:5:1","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"2、Redis性能这么高，那它是协程模型，还是多线程模型 Redis是单线程Reactor模型，通过高效的IO复用以及内存处理实现高性能。如果是6.0之前我会毫不犹豫说是单线程，6.0之后，我还是会说单线程，但会补充一句，IO解包通过多线程进行了优化，而处理逻辑，还是单线程。 另外，如果考虑到RDB的Fork，一些定时任务的处理，那么Redis也可以说多进程，这没有问题。但是Redis对数据的处理，至始至终，都是单线程。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:5:2","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"3、6.0版本发布的多线程功能 多线程功能，主要用于提高解包的效率。和传统的Multi Reactor多线程模型不同，Redis的多线程只负责处理网络IO的解包和协议转换，一方面是因为Redis的单线程处理足够快，另一方面也是为了兼容性做考虑。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:5:3","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"4、如果数据太大，Redis存不下了怎么办 使用集群模式。也就是将数据分片，不同的Key根据Hash路由到不同的节点。集群索引是通过一致性Hash算法来完成，这种算法可以解决服务器数量发生改变时，所有的服务器缓存在同一时间失效的问题。 同时，基于Gossip协议，集群状态变化时，如新节点加入、节点宕机、Slave提升为新Master，这些变化都能传播到整个集群的所有节点并达成一致。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:5:4","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"5、一致性Hash 传统的Hash分片，可以将某个Key，落到某个节点。但有一个问题，当节点扩容或者缩容，路由会被完全打乱。如果是缓存场景，很容易造成缓存雪崩问题。 为了优化这种情况，一致性Hash就应运而生了。一致性Hash是说将数据和服务器，以相同的Hash函数，映射到同一个Hash环上，针对一个对象，在哈希环上顺时针查找距其最近的机器，这个机器就负责处理该对象的相关请求。 这种情况下，增加节点，只会分流后面一个节点的数据。减少节点，那么请求会由后一个节点继承。也就是说，节点变化操作，最多只会影响后面一个节点的数据。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:5:5","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"五、应用场景 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:0","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"1、Redis经常用作缓存，那数据一致性怎么保证？ 从设计思路来说，有Cache Aside和Read/Write Through两种模式，前者是把缓存责任交给应用层，后者是将缓存的责任，放置到服务提供方。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:1","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"2、哪种模式更好 两种模式各有优缺点，从透明性考虑，服务方比较合适；如果从性能极致来说，业务方会更有优势，毕竟可以减去服务RPC的损耗。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:2","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"3、如果数据发生变化，如何更新缓存 更新方式的话，大概有四种： 1、数据存到数据库中，成功后，再让缓存失效，等到读缓存不命中的时候，再加载进去； 2、通过消息队列更新缓存 3、先更新缓存，再更新服务，这种情况相当于把Cache也做Buffer用 4、起一个同步服务，作为MySQL一个从节点，通过解析binlog同步重要缓存 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:3","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"4、缓存雪崩 缓存雪崩表示在某一时间段，缓存集中失效，导致请求全部走数据库，有可能搞垮数据库，使整个服务瘫痪。雪崩原因一般是由于缓存过期时间设置得相同造成的。 针对这种情况，可以借鉴ETCD中Raft选举的优化，让过期时间随机化，避免同一批请求，在同一时间过期。另一方面，还可以业务层面容灾，为热点数据使用双缓存。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:4","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"5、缓存穿透 缓存穿透指请求数据库里面根本没有的数据，高频请求不存在的Key，有可能是正常的业务逻辑，但更可能的，是黑客的攻击。 可以用布隆过滤器来应对，布隆过滤器是一种比较巧妙的概率型数据结构，特点是高效地插入和查询，可以用来告诉我们 某样东西一定不存在或者可能存在。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:5","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"6、布隆过滤器的实现 布隆过滤器底层是一个64位的整型，将字符串用多个Hash函数映射不同的二进制位置，将整型中对应位置设置为1。 在查询的时候，如果一个字符串所有Hash函数映射的值都存在，那么数据可能存在。为什么说可能呢，就是因为其他字符可能占据该值，提前点亮。 可以看到，布隆过滤器优缺点都很明显，优点是空间、时间消耗都很小，缺点是结果不是完全准确。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:6","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"7、缓存击穿 指某一热键，被超高的并发访问，在失效的一瞬间，还没来得及重新产生，就有海量数据，直达数据库。 这种情况和缓存雪崩的不同之处，在于雪崩是大量缓存赶巧儿一起过期，击穿只是单个超热键失效。 这种超高频Key，可以让它不过期，再单独实现数据同步逻辑，来维护数据的一致性。当然，无论如何，对后端肯定是需要限频的，不然如果Redis数据丢失，数据库还是会被打崩。限频方式可以是分布式锁或分布式令牌桶。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:7","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"8、redis消息队列 Redis本身没有支持AMQP规范，消息可靠性不强。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:8","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"9、redis在秒杀场景的应用 Redis主要是起到选拔流量的作用，记录商品总数，还有就是已下单数，等达到总数之后拦截所有请求。可以多放些请求进来，然后塞入消息队列。 蚂蚁金服的云Redis提到消息队列可以用Redis来实现，但我觉得更好的方式是用Kafka这种标准消息队列组件。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:9","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"10、redis分布式锁 锁是计算机领域一个非常常见的概念，分布式锁也依赖存储组件，针对请求量的不同，可以选择Etcd、MySQL、Redis等。前两者可靠性更强，Redis性能更高。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:10","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"11、redis限流 在微服务架构下，限频器也需要分布式化。无论是哪种算法，都可以结合Redis来实现。这里我比较熟悉的是基于Redis的分布式令牌桶。 很显然，Redis负责管理令牌，微服务需要进行函数操作，就向Redis申请令牌，如果Redis当前还有令牌，就发放给它。拿到令牌，才能进行下一步操作。 另一方面，令牌不光要消耗，还需要补充，出于性能考虑，可以使用懒生成的方式：使用令牌时，顺便生成令牌。这样子还有个好处：令牌的获取，和令牌的生成，都可以在一个Lua脚本中，保证了原子性。 ","date":"2021-07-01","objectID":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/:6:11","tags":["redis"],"title":"Redis知识图谱","uri":"/2021/07/redis%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"},{"categories":["月霜天的小笔记"],"content":"限流又称为流量控制，是限制到达系统的并发请求数，当达到限制条件时可以拒绝请求，可以起到保护下游服务，熔断流量的作用。常用的限流策略有漏桶算法、令牌桶算法、滑动窗口。 ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:0:0","tags":["golang"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的小笔记"],"content":"限流算法 ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:1:0","tags":["golang"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的小笔记"],"content":"计数器算法 计数器算法是限流算法中最简单也是最容易实现的一种算法。设置某段时间内的计数器是一个定值，当请求值在范围内则放行，如果超过计数器则限流。 func New(duration time.Duration, allowRequests int32) *fixedWindowCounter { c := \u0026fixedWindowCounter{duration: duration, allowRequests: allowRequests} go func() { for { select { case \u003c-time.After(c.duration): atomic.StoreInt32(\u0026c.currentRequests, 0) } } }() return c } func (c *fixedWindowCounter) Take() error { curRequest := atomic.LoadInt32(\u0026c.currentRequests) if curRequest \u003e= c.allowRequests { return ErrExceededLimit } if !atomic.CompareAndSwapInt32(\u0026c.currentRequests, curRequest, curRequest+1) { return ErrExceededLimit } return nil } ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:1:1","tags":["golang"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的小笔记"],"content":"滑动窗口 计数器算法虽然简单，但是会有临界问题，如果有恶意请求在时间边界处大量请求，这会导致瞬间的请求量变大。 所以引入滑动窗口，例如把1分钟化成6格，每格就是10秒，每过10秒，滑动窗口就会向右滑动一格，每个格子都有自己的计数器。 由此可见，当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。 var ( ErrExceededLimit = errors.New(\"Too many requests, exceed the limit. \") ) type slidingWindowCounter struct { total, slot time.Duration durationRequests chan int32 inDurRequests int32 currentRequests, allowRequests int32 } func New(slot, total time.Duration, allowRequests int32) *slidingWindowCounter { c := \u0026slidingWindowCounter{durationRequests: make(chan int32, total/slot/1000), total: total, slot: slot, allowRequests: allowRequests} go func() { go sliding(c) go calculate(c) }() return c } func (c *slidingWindowCounter) Take() error { curRequest := atomic.LoadInt32(\u0026c.currentRequests) if curRequest \u003e= c.allowRequests { return ErrExceededLimit } if !atomic.CompareAndSwapInt32(\u0026c.currentRequests, curRequest, curRequest+1) { return ErrExceededLimit } atomic.AddInt32(\u0026c.inDurRequests,1) return nil } func sliding(c *slidingWindowCounter) { for { select { case \u003c-time.After(c.slot): t := atomic.SwapInt32(\u0026c.inDurRequests, 0) c.durationRequests \u003c- t } } } func calculate(c *slidingWindowCounter) { // 通道加满 for { \u003c-time.After(c.slot) if len(c.durationRequests) == cap(c.durationRequests) { break } } // 定时从通道中取出数据，对currentRequests置0 for { \u003c-time.After(c.slot) t := \u003c- c.durationRequests if t != 0 { atomic.AddInt32(\u0026c.currentRequests, -t) } } } ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:1:2","tags":["golang"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的小笔记"],"content":"漏桶算法 水（请求）先到漏桶中，漏桶以一定速率出水，当水的流入速度过大时会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。 var ( ErrExceededLimit = errors.New(\"Too many requests, exceed the limit. \") ) type leakyBucket struct { duration time.Duration bucketSize chan struct{} allowRequests int32 } func New(duration time.Duration, bucketSize, allowRequests int32) *leakyBucket { c := \u0026leakyBucket{duration: duration, bucketSize: make(chan struct{}, allowRequests/bucketSize), allowRequests: allowRequests} go func() { for { select { case \u003c-time.After(time.Duration(c.duration.Nanoseconds()/int64(c.allowRequests))): c.bucketSize \u003c- struct{}{} } } }() return c } func (c *leakyBucket) Take() error { select { case \u003c-c.bucketSize: return nil default: } return ErrExceededLimit } ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:1:3","tags":["golang"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的小笔记"],"content":"令牌桶算法 令牌桶是一种常见于用于控制速率的控流算法。系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。 var ( ErrExceededLimit = errors.New(\"Too many requests, exceed the limit. \") ) type leakyBucket struct { duration time.Duration token chan struct{} allowRequests int32 } func New(duration time.Duration, allowRequests int32) *leakyBucket { c := \u0026leakyBucket{duration: duration, token: make(chan struct{}, allowRequests), allowRequests: allowRequests} go func() { for { select { case \u003c-time.After(time.Duration(c.duration.Nanoseconds()/int64(c.allowRequests))): c.token \u003c- struct{}{} } } }() return c } func (c *leakyBucket) Take() error { select { case \u003c-c.token: return nil default: } return ErrExceededLimit } ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:1:4","tags":["golang"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的小笔记"],"content":"小结 计数器算法优点是简单，能够满足简单的限流需求，缺点是临界问题，流量曲线可能不够平滑，会有“突刺现象”，在窗口切换时可能会产生两倍于阈值的流量请求。 滑动窗口算法作为对计数器算法的改进，能有效解决窗口切换时可能会产生两倍于阈值的流量请求的问题。 漏桶算法的出水速度是恒定的，那么瞬时大流量，将有大部分请求会被丢弃。 令牌桶算法生成的令牌速度是恒定的，而请求去拿令牌桶是没有速度限制的，这意味着面对瞬时流量，可以短时间内拿到大量令牌。 ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:1:5","tags":["golang"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的小笔记"],"content":"限流源码 ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:2:0","tags":["golang"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的小笔记"],"content":"golang.org/x/time/rate 是一个令牌桶算法。 Limiter有三个主要的方法 Allow、Reserve和Wait，最常用的是Wait和Allow方法 这三个方法每调用一次都会消耗一个令牌，这三个方法的区别在于没有令牌时，他们的处理方式不同 Allow： 如果没有令牌，则直接返回false Reserve：如果没有令牌，则返回一个reservation， Wait：如果没有令牌，则等待直到获取一个令牌或者其上下文被取消。 tokens更新的策略： 1、 成功获取到令牌或成功预约(Reserve)到令牌 2、预约取消时(Cancel)并且需要还原令牌到令牌桶中时 3、重新设置限流器的速率时(SetLimit) 4、重新设置限流器的容量时(SetBurst) Limit类型 // Limit 就是float64的别名，定义事件的最大频率，表示每秒发生的事件数。0表示无限制。 type Limit float64 // Inf 是无限速率限制允许所有事件(即使突发为0) const Inf = Limit(math.MaxFloat64) // Every 指定向Token桶中防止token的间隔，计算出每秒的数据量 func Every(interval time.Duration) Limit { if interval \u003c= 0 { return Inf } return 1 / Limit(interval.Seconds()) } Limiter结构体 // The methods AllowN, ReserveN, and WaitN consume n tokens. type Limiter struct { mu sync.Mutex limit Limit burst int // 令牌桶的最大数量，如果burst=0且limit=Inf，则允许处理任何事件 tokens float64 // 可用令牌数 last time.Time // 记录上次limiter的tokens被更新的时间 lastEvent time.Time // 记录速率受限的时间点（过去时间点或未来时间点） } Revervation结构体 // Reservation 预定令牌的操作，timeToAct 是本次预约需要等待到的指定时间点才有足够预约的令牌。 type Reservation struct { ok bool // 到截止时间是否能够获取足够的令牌 lim *Limiter tokens int // 需要获取的令牌数 timeToAct time.Time // 需要等待的时间点 limit Limit // 代表预定的时间，可以被更改 } Limiter消费token Limiter有3个消费token的方法，分别是Allow/Reverse/Wait，最终这些方法调用reserveN和advance来实现。 advance的实现 // advance 更新令牌桶的状态，计算出令牌桶未更新的时间，然后计算出需要向令牌桶中添加的令牌数 func (lim *Limiter) advance(now time.Time) (newNow time.Time, newLast time.Time, newTokens float64) { // last不能在now之后，否则计算出来的elapsed为负数，会导致令牌桶数量减少 last := lim.last if now.Before(last) { last = now } // 根据令牌桶的余数计算出令牌桶未进行更新的最大时间 maxElapsed := lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens) elapsed := now.Sub(last) if elapsed \u003e maxElapsed { elapsed = maxElapsed } // 根据未更新的时间（未向桶中加入令牌的时间段）计算出产生的令牌数 delta := lim.limit.tokensFromDuration(elapsed) tokens := lim.tokens + delta if burst := float64(lim.burst); tokens \u003e burst { tokens = burst } return now, last, tokens } reverseN的实现 // reserveN is a helper method for AllowN, ReserveN, and WaitN. // reserveN 判断在maxFutureReserve时间内是否有足够的令牌 func (lim *Limiter) reserveN(now time.Time, n int, maxFutureReserve time.Duration) Reservation { lim.mu.Lock() if lim.limit == Inf { lim.mu.Unlock() return Reservation{ ok: true, // 桶中有足够的令牌 lim: lim, tokens: n, timeToAct: now, } } // 更新桶的状态，tokens为桶可用的令牌数 now, last, tokens := lim.advance(now) // 计算取完后桶中剩下的令牌数 tokens -= float64(n) // 如果tokens\u003c0，说明tokens不够，计算需要等待的时间 var waitDuration time.Duration if tokens \u003c 0 { waitDuration = lim.limit.durationFromTokens(-tokens) } ok := n \u003c= lim.burst \u0026\u0026 waitDuration \u003c= maxFutureReserve // Prepare reservation r := Reservation{ ok: ok, lim: lim, limit: lim.limit, } if ok { r.tokens = n r.timeToAct = now.Add(waitDuration) } // 更新桶中的token，时间，lastEvent if ok { lim.last = now lim.tokens = tokens lim.lastEvent = r.timeToAct } else { lim.last = last } lim.mu.Unlock() return r } 这上面提到了durationFromTokens和tokensFromDuration两种方法。 // durationFromTokens 限制令牌所花费的时间 func (limit Limit) durationFromTokens(tokens float64) time.Duration { seconds := tokens / float64(limit) return time.Nanosecond * time.Duration(1e9*seconds) // 1s * seconds } // tokensFromDuration 根据时间可以产生的令牌数 func (limit Limit) tokensFromDuration(d time.Duration) float64 { // Split the integer and fractional parts ourself to minimize rounding errors. // See golang.org/issues/34861. // 之前的版本如下 // return d.Seconds() * float64(limit) // 这里的d.Seconds()已经是小数了，两个小数相乘会带来精度的缺失。 sec := float64(d/time.Second) * float64(limit) nsec := float64(d%time.Second) * float64(limit) return sec + nsec/1e9 } Limiter归还token func (r *Reservation) CancelAt(now time.Time) { if !r.ok { return } r.lim.mu.Lock() defer r.lim.mu.Unlock() // 如果无需限流或tokens为0或过了截止时间，无需处理取消操作 if r.lim.limit == Inf || r.tokens == 0 || r.timeToAct.Before(now) { return } // 计算需要还原的令牌数量 restoreTokens := float64(r.tokens) - r.limit.tokensFromDuration(r.lim.lastEvent.Sub(r.timeToAct)) if restoreTokens \u003c= 0 { return } // 重新计算令牌桶的状态 now, _, tokens := r.lim.advance(now) // 还原当前令牌桶的令牌数量，当前的令牌数tokens加上需要还原的令牌数restoreTokens tokens += restoreT","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:2:1","tags":["golang"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的小笔记"],"content":"uber-go/ratelimit 基于漏桶实现。 例子 rl := ratelimit.New(100) // per second prev := time.Now() for i := 0; i \u003c 10; i++ { now := rl.Take() fmt.Println(i, now.Sub(prev)) prev = now } // Output: // 0 0 // 1 10ms // 2 10ms // 3 10ms // 4 10ms // 5 10ms // 6 10ms // 7 10ms // 8 10ms // 9 10ms 基本实现 要实现上面的每秒固定速率，很简单。 在ratelimit的New函数中，传入的参数是每秒允许请求量(Requests Per Second)。 我们就能很轻松计算出每个请求的时间间隔： perRequest := time.Second / time.Duration(rate) 如图，当请求1处理结束后，记录请求1的处理完成时间，记为limiter.last。请求2到达时，如果此时的时间与limiter.last的时间间隔小于preRequest，那么sleep一段时间。 sleepFor = t.PreRequest - now.Sub(t.last) if sleepFor \u003e 0 { t.clock.Sleep(sleepFor) t.last = now.Add(sleepFor) } else { t.last = now } 然而，在现实请求中，流量经常是突发的，有些请求间隔比较长，有些请求间隔比较短。 所以uber引入最大松弛量，把之前间隔比较长的请求时间，匀给后面的使用。 而实现起来也很简单，就是把每个请求多出的等待时间累加起来，给后面的请求冲抵。 t.sleepFor += t.preReqeust - now.Sub(t.last) if t.sleepFor \u003c t.maxSlack { t.sleepFor = t.maxSlack } if t.sleepFor \u003e 0 { t.clock.Sleep(t.sleepFor) t.last = now.Add(t.sleepFor) t.sleepFor = 0 } else { t.last = now } 源码解析： func New(rate int, opts ...Option) Limiter { return newAtomicBased(rate, opts...) } // buildConfig combines defaults with options. func buildConfig(opts []Option) config { c := config{ clock: clock.New(), slack: 10, per: time.Second, } for _, opt := range opts { opt.apply(\u0026c) } return c } func newAtomicBased(rate int, opts ...Option) *atomicLimiter { config := buildConfig(opts) // 两个请求的最小时间间隔 perRequest := config.per / time.Duration(rate) l := \u0026atomicLimiter{ perRequest: perRequest, maxSlack: -1 * time.Duration(config.slack) * perRequest, // 最大松弛量 clock: config.clock, } initialState := state{ last: time.Time{}, sleepFor: 0, } atomic.StorePointer(\u0026l.state, unsafe.Pointer(\u0026initialState)) return l } func (t *atomicLimiter) Take() time.Time { var ( newState state taken bool interval time.Duration ) for !taken { now := t.clock.Now() previousStatePointer := atomic.LoadPointer(\u0026t.state) oldState := (*state)(previousStatePointer) newState = state{ last: now, sleepFor: oldState.sleepFor, } // 如果是第一次请求，更新状态 if oldState.last.IsZero() { taken = atomic.CompareAndSwapPointer(\u0026t.state, previousStatePointer, unsafe.Pointer(\u0026newState)) continue } newState.sleepFor += t.perRequest - now.Sub(oldState.last) // 例如请求1完成后，请求2在几个小时后到达，那么对于now.Sub(oldState.last)会非常大，而这里newState.sleepFor表示允许冲抵的最长时间。 if newState.sleepFor \u003c t.maxSlack { // t.maxSlack默认10个请求的间隔大小 newState.sleepFor = t.maxSlack } if newState.sleepFor \u003e 0 { // 代表此前的请求多余出的时间，无法完全冲抵此次所需量 newState.last = newState.last.Add(newState.sleepFor) interval, newState.sleepFor = newState.sleepFor, 0 } taken = atomic.CompareAndSwapPointer(\u0026t.state, previousStatePointer, unsafe.Pointer(\u0026newState)) } t.clock.Sleep(interval) return newState.last } ","date":"2021-06-28","objectID":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/:2:2","tags":["golang"],"title":"高并发系统下的限速策略","uri":"/2021/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E9%99%90%E9%80%9F%E7%AD%96%E7%95%A5/"},{"categories":["月霜天的GO"],"content":"原子操作 我们先给原子操作下一个定义： 原子(atom)：在化学反应中不可再分的基本微粒。 原子操作(atomic operation)：不会被线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会有任何的上下文切换。 简单来说，就是多个线程对同一块内存的操作是串行的，不会因为并发操作而同时读写内存。 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:1:0","tags":["源码解析","sync"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"原子性 在处理器层面，基于缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。通过加锁保证从系统内存中读取或写入一个字节是原子的，也就是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。 总线锁 如果多个处理器同时对共享变量进行读写操作(i++)，那么共享变量就会被多个处理器同时进行操作，这样读写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。 总线锁其实就是处理器提供一个LOCK#信号，当一个处理器在总线上输出信号时，其他处理器的请求将被阻塞，那么改处理器就能独占共享内存。 在同一时刻，只需保证对某个内存地址的操作是原子性即可，但总线锁把CPU和内存之间的通信锁住了，使得其他处理器不能操作其他内存地址的数据，所以总线锁的开销比较大，缓存锁可以在某些场合代替总线锁进行优化。 缓存锁 内存区域如果被缓存在处理器的缓存行中，并且在LOCK#操作期间，那么当它执行操作回写到内存时，处理器不能在总线上声明LOCK#信号，而是修改内部的内存地址，允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性会阻止同时修改两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行数据时，会使缓存行无效。 但有两种情况下处理器不会使用缓存锁定： 1、当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行(cache line)，则处理器会调用总线锁 2、有些处理器不支持缓存锁定。 锁机制虽然能保证原子性，但是锁机制最主要的问题：多线程竞争的情况下，会出现线程阻塞和唤醒锁带来的性能问题，互斥同步(阻塞同步)。 锁机制采用的是悲观锁策略，并不是一种特别高效的解决方案。可以采用乐观锁，每次不加锁，而是假设没有冲突去完成某项操作，如果有冲突就重试，知道成功为止。这就是无锁操作CAS(Compare and swap)。 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:2:0","tags":["源码解析","sync"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"CAS CAS是一条原子指令，CAS(V,O,N)，包含三个值分别为：V内存地址存放的实际值，O预期的值(旧值)，N更新的值，作用是让CPU先比较旧值O和内存实际值V，如果相等就表明没有被其他线程修改过，就会把新值N赋值给V。反之，V和O不相等，不能把N赋值给V，返回V即可。 伪代码： func CompareAndSwap(addr *int, oldValue,newValue int) bool { if addr == nil { return false } if *addr == oldValue { *addr = newValue return true } return false } 不过上面的代码可能会发生一个问题，也就是ABA问题。因为CAS需要在操作值的时候检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变回了A，那么使用CAS检查时会发现它的值没有发生变化，但实际上发生了变化。ABA问题的解决思路就是使用版本号，在遍历前面追加版本号，每次更新的时候都会把版本号加1，那么A-B-A就会变成1A-2B-3A。 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:3:0","tags":["源码解析","sync"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"go包中的原子操作 在src/sync/atomic/doc.go下，把底层硬件提供的原子操作封装成了Go的函数，分为5个系列： 1、SwapXXX(addr *int32, new int32) (old int32)：原子性的将new的值保存到*addr并返回旧值 2、CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)：原子性比较*addr和old的值，如果相同则将new赋值给*addr并返回true 3、AddInt32(addr *int32, delta int32) (new int32)：原子性的将delta的值加到*addr并返回新值 4、LoadInt32(addr *int32) (val int32)：原子性的获取*addr的值 5、StoreInt32(addr *int32, val int32)：原子性的将val的值保存到*addr ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:4:0","tags":["源码解析","sync"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"源码解析 原子操作是基于汇编实现的，基于plan9的。 我们可以看一下value.go文件的源码。 type Value struct { v interface{} } 虽然这里是interface类型，但是这里其实是分解了类型和值的。 type ifaceWords struct { typ unsafe.Pointer data unsafe.Pointer } ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:5:0","tags":["源码解析","sync"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"Value的写入 func (v *Value) Store(x interface{}) { if x == nil { panic(\"sync/atomic: store of nil value into Value\") } vp := (*ifaceWords)(unsafe.Pointer(v)) xp := (*ifaceWords)(unsafe.Pointer(\u0026x)) for { typ := LoadPointer(\u0026vp.typ) if typ == nil { // Attempt to start first store. // Disable preemption so that other goroutines can use // active spin wait to wait for completion; and so that // GC does not see the fake type accidentally. runtime_procPin() if !CompareAndSwapPointer(\u0026vp.typ, nil, unsafe.Pointer(^uintptr(0))) { runtime_procUnpin() continue } // Complete first store. StorePointer(\u0026vp.data, xp.data) StorePointer(\u0026vp.typ, xp.typ) runtime_procUnpin() return } if uintptr(typ) == ^uintptr(0) { // First store in progress. Wait. // Since we disable preemption around the first store, // we can wait with active spinning. continue } // First store completed. Check type and overwrite data. if typ != xp.typ { panic(\"sync/atomic: store of inconsistently typed value into Value\") } StorePointer(\u0026vp.data, xp.data) return } } // Disable/enable preemption, implemented in runtime. func runtime_procPin() func runtime_procUnpin() 通过报错信息和注释我们知道，存入的值不能为nil，类型必须与原类型相同。 写入步骤： 1、判断写入值不能为nil，否则触发panic 2、将oldValue和newValue转换成ifaceWords类型，方便获取类型和值 3、为了保证原子性，循环处理，当已经有Store正在写入时，会进行等待。 4、如果还没有写入数据，类型为空，那么会开始第一次写入操作，会先调用runtime_procPin方法禁止调度器对当前goroutine的抢占 5、调用CAS方法来判断当前地址是否有被抢占，如果失败，就会解除抢占锁，解除禁止调度器，循环等待 6、设置中间值成功后，可以安全的把v设为传入的新值了，写入值和类型。 7、第一次写入没有完成，通过uintptr(typ) == ^uintptr(0)来判断，因为还是第一次放入的中间类型，会继续等待第一次完成 8、如果第一次写入完成，会检查类型是否一致，然后写入数据 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:5:1","tags":["源码解析","sync"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"Value的读取 func (v *Value) Load() (x interface{}) { vp := (*ifaceWords)(unsafe.Pointer(v)) typ := LoadPointer(\u0026vp.typ) if typ == nil || uintptr(typ) == ^uintptr(0) { // First store not yet completed. return nil } data := LoadPointer(\u0026vp.data) xp := (*ifaceWords)(unsafe.Pointer(\u0026x)) xp.typ = typ xp.data = data return } 先转换oldValue，然后根据类型判断是否有数据或第一次写入有没有完成，通过检查后，获取值。 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:5:2","tags":["源码解析","sync"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"总结 golang包中的原子操作可以看成是乐观锁，而互斥锁可以看成是悲观锁。 原子锁操作更加轻量，可以在不形成临界区和创建互斥量的情况下并发安全的值替换操作，可以大大减少同步对程序性能的损耗。 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:6:0","tags":["源码解析","sync"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的GO"],"content":"参考资料 原子操作 ","date":"2021-06-03","objectID":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/:7:0","tags":["源码解析","sync"],"title":"并发编程之原子操作","uri":"/2021/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/"},{"categories":["月霜天的小笔记"],"content":"一、简介 当集群中的某个服务需要升级时，我们需要停止目前与该服务的相关的所有pod，然后下载新版本镜像并创建新的pod。如果集群规模比较大，则这个工作就会很麻烦。kubernetes提供了滚动升级功能来解决这个问题。 ","date":"2021-03-24","objectID":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/:1:0","tags":["kubernetes","pod"],"title":"Pod升级与回滚","uri":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/"},{"categories":["月霜天的小笔记"],"content":"二、Deployment的升级 nginx-deployment.yamlapiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deploymentspec:selector:matchLabels:app:nginxreplicas:3template:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.7.9ports:- containerPort:80 当pod的镜像需要被升级为nginx:1.9.1时，可以通过kubectl set image命令 kubectl set image deployment/nginx-deploymnet nginx=nginx:1.9.1 或通过kubectl edit修改Deployment配置。 在Deployment的定义中，可以通过spec.strategy指定Pod更新的策略，目前支持Recreate（重建）和RollingUpdate（滚动更新），默认值为滚动更新。 Recreate：表示Deployment在更新pod时，会先杀掉所有正在运行的Pod，然后创建新的Pod RollingUpdate：会以滚动更新的方式逐个更新Pod。 spec.strategy.rollingUpdate.maxUnavailable：用于指定Deployment在更新过程中不可用状态的Pod数量上限。 spec.strategy.rollingUpdate.maxSurge：用于指定Deployment更新Pod的过程中Pod总数超过Pod期望副本数部分的最大值。 多重更新（Rollover） 如果Deployment的上一次更新正在进行，此时用户再次发起Deployment的更新操作，那么Deployment会为每一次更新都创建一个ReplicaSet，而每次在新的ReplicaSet创建成功后，会逐个增加Pod副本数，同时将之前正在扩容的ReplicaSet停止扩容，并将其加入旧版本ReplicaSet列表中，然后开始缩容至0的操作。 ","date":"2021-03-24","objectID":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/:2:0","tags":["kubernetes","pod"],"title":"Pod升级与回滚","uri":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/"},{"categories":["月霜天的小笔记"],"content":"三、Deployment的回滚 可以使用kubectl rollout history命令检查Deployment部署的历史记录。 kubectl rollout history deployment/nginx-deployment 注意：这里需要在新建Deployment时使用--record参数。 如果需要查看特定版本的详细信息，则可以加上--revision=\u003cN\u003e参数。 撤销本次发布并回滚到上一个部署版本 kubectl rollout undo deployment/nginx-deployment 当然，也可以使用--to-revision参数指定回滚到的部署版本号。 ","date":"2021-03-24","objectID":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/:3:0","tags":["kubernetes","pod"],"title":"Pod升级与回滚","uri":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/"},{"categories":["月霜天的小笔记"],"content":"四、暂停和恢复Deployment的部署操作 对于一次复杂的Deployment配置修改，为了避免频繁触发Deployment的更新操作，可以先暂停Deployment的更新操作，然后进行配置修改，再恢复Deployment，一次触发完整的更新操作。 通过使用kubectl rollout pause暂停Deployment的更新操作 kubectl rollout pause deployment/nginx-deployment 通过使用kubectl rollout resume恢复操作 kubectl rollout resume deploy/nginx-deployment ","date":"2021-03-24","objectID":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/:4:0","tags":["kubernetes","pod"],"title":"Pod升级与回滚","uri":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/"},{"categories":["月霜天的小笔记"],"content":"五、其他更新操作 1、RC的滚动更新 kubectl rolling-update命令，通过配置文件 RC名字不与旧RC相同；在selector中应至少有一个Label与旧RC的Label不同，以标识其为新RC。 kubectl rolling-update redis-master -f redis-master-ctl-v2.yaml kubectl rolling-update命令，不通过配置文件 kubectl rolling-update redis-master --image=redis-master:2.0 执行结果是旧RC被删除，新的RC将使用旧RC的名称 2、DaemonSet的更新策略 OnDelete：默认的升级策略，新的Pod并不会自动创建，直到用户手动删除旧版本的Pod，才触发新建操作。 RollingUpdate：整个过程和Deployment类似，但不支持查看DaemonSet的更新历史记录；不能通过rollback回滚，必须通过再次提交旧版本配置的方式实现。 3、Statefulset的更新策略 实现了RollingUpdate、OnDelete和Paritioned策略。 Partition:3表示索引3以上的对象更新。 ","date":"2021-03-24","objectID":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/:5:0","tags":["kubernetes","pod"],"title":"Pod升级与回滚","uri":"/2021/03/pod%E5%8D%87%E7%BA%A7%E4%B8%8E%E5%9B%9E%E6%BB%9A/"},{"categories":["月霜天的小笔记"],"content":"一、简介 在大多数情况下，我们不关心pod会被调度到哪个节点，只关心pod是否被成功调度到集群的一个可用节点。但是，在真实生产环境中存在一种需求：希望某种pod全部运行在一个或一些节点上。比如需要ssd的pod都运行在具有ssd磁盘的目标节点上。 ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:1:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"二、全自动调度 deployment或rc的主要功能之一就是自动部署一个容器应用的多份副本，以及持续监控副本的数量，在集群中始终维持用户指定的副本数量。 nginx-deployment.yamlapiVersion:apps/v1kind:Deploymentmetadata:name:nginx-deploymentspec:selector:matchLabels:app:nginxreplicas:3template:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.7.9ports:- containerPort:80 使用kubectl create命令创建这个deployment： # kubectl create -f nginx-deployment.yaml deployment \"nginx-deployment\" created 可以看到Deployment已经创建好3个副本，并且所有副本都是最新可用的。从调度策略上来说，这3个pod由系统全自动完成调度，用户无法干预调度过程和结果。 ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:2:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"三、NodeSelector：定向调度 通过Node的标签（Label）和Pod的nodeSelector属性相匹配来讲Pod调度到指定的一些Node上。 1、通过kubectl label命令给目标Node打上一些标签： kubectl label nodes \u003cnode-name\u003e \u003clabel-key\u003e=\u003clabel-value\u003e 2、在Pod的定义中加上nodeSelector的设置 apiVersion:v1kind:ReplicationControllermetadata:name:redis-masterlabels:name:redis-masterspec:replicas:3selector:name:redis-mastertemplate:metadata:labels:name:redis-masterspec:containers:- name:masterimage:reids-masterports:- containerPort:6379nodeSelector: # 节点标签选择器zone:north 如果给多个Node都定义了相同的标签，则scheduler会根据调度算法从Node组中挑选一个可用的Node进行调度。 除了用户可以自行给Node添加标签，kubernetes也会给Node预定义一些标签。 kubernetes.io/hostname kubernetes.io/os kubernetes.io/arch ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:3:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"四、NodeAffinity：Node亲和性调度 NodeAffinity为Node亲和性的调度策略，是用于替换NodeSelector的全新调度策略。目前有两种节点亲和性表达。 RequiredDuringSchedulingIgnoredDuringExecution：必须满足指定的规则才能调度Pod到Node上，相当于硬限制。 PreferredDuringSchedulingIgnoredDuringExecution：强调优先满足指定规则，调度器会尝试调度Pod到Node上，但不强求，相当于软限制。多个优先级规则还可以设置权重(weight)值，以定义执行的先后顺序。 IgnoredDuringExecution：如果一个Pod所在的结点在Pod运行期间标签发生了变更，不再符合Pod的结点亲和性需求，则系统将忽略Node上的Label变化，该Pod能继续在该节点上运行。 apiVersion:v1kind:Podmetadata:name:with-node-affinityspec:affinity:nodeAffinity:# 要求只在amd64的节点上运行requiredDuringSchedulingIgnoredDuringExecution:nodeSelectorTerms:- matchExpressions:- key:beta.kubernetes.io/archoperator:Invalues:- amd64preferredDuringSchedulingIgnoredDuringExecution:- weight:1# 尽量运行在磁盘类型为ssd的节点上preference:matchExpressions:- key:disk-typeoperator:Invalues:- ssdcontainers:- name:with-node-affinityimage:pause:2.0 NodeAffinity语法支持的操作符包括In、NotIn、Exists、DoesNotExist、Gt、Lt。 NodeAffinity规则设置的注意事项： 如果同时定义了nodeSelector和nodeAffinity，那么必须两个条件都得到满足，Pod才能最终运行在指定的Node上 如果nodeAffinity指定了多个nodeSelectorTerms，那么其中一个能够匹配成功即可 如果nodeSelectorTerms中有多个matchExpressions，则一个节点必须满足所有matchExpressions才能运行Pod。 ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:4:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"五、PodAffinity：Pod亲和与互斥调度策略 如果在具有标签相同的Node上运行了一个或多个符合条件的Pod，那么Pod应该运行在这个Node上。 topologyKey：节点所属的topoloty kubernets.io/hostname failure-domain.beta.kubernetse.io/zone failure-domain.beta.kubernets.io/region pod的亲和与互斥的条件设置也是RequiredDuringSchedulingIgnoredDuringExecution和PreferredDuringSchedulingIgnoredDuringExecution。 Pod的亲和性被定义在podAffinity，Pod的互斥性被定义在podAntiAffinity。 1、参考目标Pod 创建一个名为pod-flag的pod，带有标签security=S1和app=nginx。 apiVerson:v1kind:Podmetadata:name:pod-flaglabels:security:\"S1\"app:\"nginx\"spec:containers:- name:nginximage:nginx 2、Pod的亲和性调度 apiVerson:v1kind:Podmetadata:name:pod-affinityspec:affinity:podAffinity:requiredDuringSchedulingIgnoredDuringExecution:- labelSelector:matchExpressions:- key:securityoperator:Invalues:- S1topologyKey:kubernets.io/hostnamecontainers:- name:with-pod-affinityimage:pause:2.0 3、Pod的互斥性调度 apiVerson:v1kind:Podmetadata:name:anti-affinityspec:affinity:podAffinity:requiredDuringSchedulingIgnoredDuringExecution:- labelSelector:matchExpressions:- key:securityoperator:Invalues:- S1topologyKey:failure-domain.beta.kubernets.io/zonepodAntiAffinity:requiredDuringSchedulingIgnoredDuringExecution:- labelSelector:matchExpressions:- key:securityoperator:Invalues:- nginxtopologyKey:kubernets.io/hostnamecontainers:- name:anti-pod-affinityimage:pause:2.0 新pod与security=S1的pod为同一个zone，但不与app=nginx的Pod为同一个zone。 topologyKey的限制（出于性能和安全方面考虑）： 在Pod亲和性和RequiredDuringScheduing的Pod互斥性的定义中，不允许使用空的topologyKey。 如果Admission Controller包含了LimitPodHardAntiAffinityTopology，那么针对Required DuringScheduling的Pod互斥性定义就被限制为kubernetes.io/hostname，要使用自定义的topologyKey就要改写或禁用该控制器。 在PreferredDruingScheduling类型的Pod互斥性定义中，空的topologyKey会被解释为kubernets.io/hostname、failure-domain.beta.kubernetse.io/zone、failure-domain.beta.kubernets.io/region的组合。 如果不是上述情况，就可以采用任意合法的topologyKey。 PodAffinity规则设置的注意事项： 除了设置Label Selector和topologyKey，用户还可以指定Namespace列表来进行限制，同样，使用Label Selector对Namespace进行选择。 在所有关联requiredDuringSchedulingIgnoredDuringExecution的matchExpressions全部满足之后，系统才能将Pod调度到某个Node上。 ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:5:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"六、Taints和Tolerations（污点和容忍） 在Node上设置一个或多个Taint之后，除非Pod明确声明能够容忍这些污点，否则无法在这些Node上运行。Toleration是Pod的属性，让Pod能够运行在标注了taint的Node上。 # kubectl taint nodes node1 key=value:NoSchedule 然后在pod上声明toleration。 tolerations:- key:\"key\"operator:\"Equal\"value:\"value\"effect:\"NoSchedule\"tolerations:- key:\"key\"operator:\"Exists\"effect:\"NoSchedule\" 如果不指定operator，默认值为Equal。空的key配合Exists能够匹配所有键和值。空的effect能够匹配所有的effect。 NoSchedule：不调度 PreferNoSchedule：不优先调度 NoExecute：不运行，已经在这个节点上的Pod会被驱逐。 ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:6:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"七、Pod Priority Preemption：Pod优先级调度 优先级抢占调度策略的核心行为分别是驱逐（Eviction）和抢占（Preemption）。Evection是kubelet行为，即当一个Node发生资源不足情况时，该节点上的kubelet进程会发生驱逐动作，此时kubelet会综合考虑Pod的优先级、资源申请量与实际使用量等信息计算哪些Pod需要被驱逐；当同样优先级的Pod需要被驱逐时，实际使用的资源量超过申请量最大倍数的高耗能Pod会被首先驱逐。 服务质量等级Qos： Guaranteed：pod设置了limit或limit=request Burstable：pod里的一个容器limit！=request Best-Effort：limit和request均未设置 1、创建PriorityClasses apiVersion:scheduling.k8s.io/v1beta1kind:PriorityClassmetadata:name:high-priorityvalue:1000000globalDefault:falsedescription:\"This priority class should be used for service pods only\" 2、可以在任意pod中引用优先级类别 apiVersion:v1kind:Podmetadata:name:nginxlabels:env:testspec:containers:- name:nginximage:nginximagePullPolicy:IfNotPresentpriorityClassName:high-priority ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:7:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"八、其他情况 1、DaemonSet：在每个Node上都调度一个Pod 2、Job和CronJob的批处理调度，可以设置任务数completions和并行度parallelism ","date":"2021-03-23","objectID":"/2021/03/pod%E8%B0%83%E5%BA%A6/:8:0","tags":["kubernetes","pod"],"title":"Pod调度","uri":"/2021/03/pod%E8%B0%83%E5%BA%A6/"},{"categories":["月霜天的小笔记"],"content":"一、简介 pod在整个生命周期中被系统定义为各种状态，熟悉pod的各种状态对于理解如何设置pod的调度策略、重启策略都是很有必要的。 ","date":"2021-03-22","objectID":"/2021/03/pod%E5%9F%BA%E7%A1%80/:1:0","tags":["kubernetes","pod"],"title":"Pod的基础","uri":"/2021/03/pod%E5%9F%BA%E7%A1%80/"},{"categories":["月霜天的小笔记"],"content":"二、pod状态 Pending：API Server已经创建该Pod，但在Pod内还有一个或多个容器的镜像没有创建，包括正在下载镜像的过程 Running：Pod内所有容器均已创建，且至少有一个容器处于运行状态。正在启动状态或重启状态 Succeeded：Pod内所有容器均成功执行后退出，且不会再重启 Failed：Pod内所有容器均已退出，但至少有一个容器退出为失败状态，退出码不为0 Unknown：由于某种原因无法获取该Pod的状态，可能由于网络通信不畅导致（无法连接API Server） ","date":"2021-03-22","objectID":"/2021/03/pod%E5%9F%BA%E7%A1%80/:2:0","tags":["kubernetes","pod"],"title":"Pod的基础","uri":"/2021/03/pod%E5%9F%BA%E7%A1%80/"},{"categories":["月霜天的小笔记"],"content":"三、Pod重启策略 pod的重启策略（RestartPolicy）应用于Pod内的所有容器，并且仅在Pod所处的Node上由kubelet进行判断和重启操作。当某个容器异常退出或健康检查失败时，kubelet会根据重启策略来进行相应的操作。 Always：默认策略，当容器失效时，由kubelet自动重启容器 OnFailure：当容器终止运行且退出码不为0时，由kubelet自动重启该容器 Never：不论容器的运行状态都不重启 kubelet重启容器的时间间隔以sync-frequency乘以2来计算，例如1、2、4、8倍等，最长5min，并且在成功重启后10min后重置该时间。 每种控制器对pod的重启策略要求： RC和DaemonSet：必须为Always，需要保证容器持续运行 Job：OnFailure或Never，确保容器执行完成后不再重启 kubelet：在pod失效后重启，不论将RestartPolicy设置为什么值，也不会对pod进行健康检查 常见的状态转换场景（最终状态） pod包含的容器数 pod当前的状态 发生事件 always OnFailure Never 1 running 成功退出 running succeed succeed 1 running 失败退出 running running failed 2 running 1个失败退出 running running running 2 running oom running running failed ","date":"2021-03-22","objectID":"/2021/03/pod%E5%9F%BA%E7%A1%80/:3:0","tags":["kubernetes","pod"],"title":"Pod的基础","uri":"/2021/03/pod%E5%9F%BA%E7%A1%80/"},{"categories":["月霜天的小笔记"],"content":"四、健康检查 LivenessProbe存活探针：判断容器是否存活（running状态）。如果探针探测到容器不健康，kubelet会杀掉容器，并根据容器的重启策略处理。如果容器不包含存活探针，那么会认为容器一直健康。 ReadinessProbe就绪探针：判断容器服务是否可用（ready状态），达到ready状态的pod才能接受请求。如果在运行过程中ready状态变为false，则系统自动将其从service的后端endpoint列表中隔离出去，后续再把恢复到ready状态的pod加回到endpoint列表。这样就能保证客户端再访问service时不会被转发到服务不可用的pod实例上。 三种实现方式： ExecAction：在容器内部执行命令，如果命令的状态码返回0，则表明容器健康。 livenessProbe:exec:command:- cat- /tmp/health TCPSocketAction：通过容器的IP地址和端口号Port执行TCP检查，如果能够建立TCP连接，则表明容器健康 livenessProbe:tcpSocket:port:80 HTTPGetAction：通过容器的IP地址、端口号及路径调用HTTP Get方法，如果响应的状态码大于等于200且小于400，则认为容器健康 livenessProbe:httpGet:path:/_status/healthzport:80 对于每种探测方式，都需要设置参数 initialDelaySeconds：启动容器后进行首次健康检查的等待时间 timeoutSeconds：健康检查发送请求后等待响应的超时时间 ","date":"2021-03-22","objectID":"/2021/03/pod%E5%9F%BA%E7%A1%80/:4:0","tags":["kubernetes","pod"],"title":"Pod的基础","uri":"/2021/03/pod%E5%9F%BA%E7%A1%80/"},{"categories":["月霜天的小笔记"],"content":"一般来说，模块作者需要使用一种方法来只是不应该使用某个已发布的模块。 出现一个严重的安全漏洞 不闲不兼容或bug 版本发布错误 出现过模块最新版本为1.0.0，错误发布1.1.0，然后在github上把版本删除，使用1.0.1版本，但是有人使用代理模块并且下载了1.1.0版本，所以其他人再下载指定latest会下载1.1.0版本的代码。 ","date":"2021-02-25","objectID":"/2021/02/golang_retract/:0:0","tags":["golang"],"title":"Golang 1.16版本新特性 =\u003e 撤回版本(retract)","uri":"/2021/02/golang_retract/"},{"categories":["月霜天的小笔记"],"content":"准备工作 retract模块，github的完整路径是https://github.com/betterfor/retract，你可以使用自己的模块实验。 awesomeProjcet，本地模块，使用了test包的依赖的简单main函数。 请确保golang版本是1.16+ ","date":"2021-02-25","objectID":"/2021/02/golang_retract/:1:0","tags":["golang"],"title":"Golang 1.16版本新特性 =\u003e 撤回版本(retract)","uri":"/2021/02/golang_retract/"},{"categories":["月霜天的小笔记"],"content":"创建test模块 1、先在github上创建好仓库 2、拉取代码仓库 $ git clone https://github.com/betterfor/retract.git $ cd retract/ $ go mod init go: creating new go.mod: module github.com/betterfor/retract 3、在模块中新建foo.go文件 package retract func Foo() string { return \"v0.0.1\" } 4、将retract模块的改动提交git并push $ git add . $ git commit -m \"Initial commit\" $ git push -u origin master 这是模块的初始版本，我们用v0版本来表示，代表它不稳定。 $ git tag v0.1.0 $ git push origin v0.1.0 To https://github.com/betterfor/retract.git * [new tag] v0.1.0 -\u003e v0.1.0 此时retract模块第一个版本已经发布，我们在awesomeProjcet项目使用它。 5、创建awesomeProjcet本地项目，引用retract模块。 $ mkdir awesomeProjcet $ cd awesomeProjcet/ $ go mod init package main import ( \"fmt\" \"github.com/betterfor/retract\" ) func main() { fmt.Println(retract.Foo()) } $ go get github.com/betterfor/retract@v0.1.0 此时版本正常使用。 6、retract模块更新 foo.go文件修改 package retract func Foo() string { return \"v0.2.0\" } 我们提交并推送到github上，给它标记一个新的标签v0.2.0. $ git tag v0.2.0 $ git push origin v0.2.0 7、然后我们在awesomeProjcet项目中使用retract的v0.2.0版本，发现可以正常运行。 $ go get github.com/betterfor/retract@v0.2.0 go: downloading github.com/betterfor/retract v0.2.0 go get: upgraded github.com/betterfor/retract v0.1.0 =\u003e v0.2.0 $ go run main.go v0.2.0 8、撤回版本 此时我们作为retract模块的作者，发现v0.2.0版本不完善，需要撤回这个版本，应该怎么做？ 我们可以在go.mod中增加retract指令来撤回某个模块版本。 $ go mod edit -retract=v0.2.0 此时go.mod内容如下 module github.com/betterfor/retract go 1.16 // tag version error retract v0.2.0 当然你也可以不使用命令，直接在go.mod文件中修改，一般会在retract加上撤回原因.go get、go list等会显示这个原因。 提交修改内容至github，给它标记一个新的标签v0.3.0。 awesomeProjcet项目中使用retract的v0.3.0版本，发现可以正常运行。 $ go get github.com/betterfor/retract@v0.3.0 go: downloading github.com/betterfor/retract v0.3.0 go get: upgraded github.com/betterfor/retract v0.2.0 =\u003e v0.3.0 $ go get github.com/betterfor/retract@v0.2.0 go: warning: github.com/betterfor/retract@v0.2.0: retracted by module author: tag version error go: to switch to the latest unretracted version, run: go get github.com/betterfor/retract@latestgo get: downgraded github.com/betterfor/retract v0.3.0 =\u003e v0.2.0 我们发现出现warning信息，但是这个版本的包还是可用的。 我们来查看模块的版本列表 $ go list -m -versions github.com/betterfor/retract github.com/betterfor/retract v0.1.0 v0.3.0 此时我们查看模块的版本发现，没有v0.2.0版本了。 通过增加-retracted选项可以查看撤回的版本。 $ go list -m -versions -retracted github.com/betterfor/retract github.com/betterfor/retract v0.1.0 v0.2.0 v0.3.0 那么我们怎么知道我们的项目有没有依赖已撤回版本的模块呢？使用go list命令 $ go list -m -u all awesomeProjcet github.com/betterfor/retract v0.2.0 (retracted) [v0.3.0] ","date":"2021-02-25","objectID":"/2021/02/golang_retract/:2:0","tags":["golang"],"title":"Golang 1.16版本新特性 =\u003e 撤回版本(retract)","uri":"/2021/02/golang_retract/"},{"categories":["月霜天的小笔记"],"content":"问题 如果模块现在的版本是v0版本，不小心发布了v1版本，需要撤回v1版本，该怎么操作？ 1、按照上面的操作步骤进行，我们发现打过v1.0.0版本后,仍会显示v1.0.0 $ go list -m -versions github.com/betterfor/retract github.com/betterfor/retract v0.1.0 v0.3.0 v0.4.0 v1.0.0 这就要求我们需要使用一个比v1.0.0大的版本号v1.0.1来写入撤回信息。 module github.com/betterfor/retract go 1.16 retract ( // tag version error v0.2.0 // v1 提前发布了 [v1.0.0, v1.0.1] ) 将这次改动提交，并标记一个新的版本v1.0.1。 然后拉取模块 $ go get github.com/betterfor/retract@v1.0.0 $ go get github.com/betterfor/retract@v1.0.1 $ go get github.com/betterfor/retract@v0.4.0 go list -m -versions github.com/betterfor/retract github.com/betterfor/retract v0.1.0 v0.3.0 v0.4.0 ok! v0.4.0就是最新的版本 如果你将来发布v1版本时，应该要从v1.0.2开始，因为v1.0.0和v1.0.1已经被占用了 ","date":"2021-02-25","objectID":"/2021/02/golang_retract/:3:0","tags":["golang"],"title":"Golang 1.16版本新特性 =\u003e 撤回版本(retract)","uri":"/2021/02/golang_retract/"},{"categories":["月霜天的小笔记"],"content":" Docker是一个虚拟环境容器，可以将你的开发环境、代码、配置文件等一并打包到这个容器中，并发布和应用到任意平台中。所以你需要知道一点docker的命令。 这里是关于docker的基础命令（第一节） 版本信息：查看docker的各项基础信息 仓库管理：管理镜像存储的仓库 版本信息 ","date":"2021-02-12","objectID":"/2021/02/docker_command/:0:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"info docker info：显示Docker系统信息，包括镜像、容器数量和镜像仓库。 语法 docker info [OPTIONS] Options: -f, --format string 显示返回值的模板文件 实例 Client: Context: default Debug Mode: false Plugins: app: Docker App (Docker Inc., v0.9.1-beta3) buildx: Build with BuildKit (Docker Inc., v0.5.1-docker) Server: Containers: 1 Running: 1 Paused: 0 Stopped: 0 Images: 1 Server Version: 20.10.3 Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options: seccomp Profile: default Kernel Version: 3.10.0-1160.15.2.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 1.795GiB Name: localhost.localdomain ID: 4NYR:4KA5:NBOL:V6Y7:SE6H:B2R7:2LRD:FNIL:CK5J:4L4J:6K63:5RMO Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Live Restore Enabled: false ","date":"2021-02-12","objectID":"/2021/02/docker_command/:1:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"version docker version：显示Docker版本信息。 语法 docker version [OPTIONS] Options: -f, --format string 显示返回值指定的模板文件 --kubeconfig string k8s配置文件 实例 Client: Docker Engine - Community Version: 20.10.3 API version: 1.41 Go version: go1.13.15 Git commit: 48d30b5 Built: Fri Jan 29 14:34:14 2021 OS/Arch: linux/amd64 Context: default Experimental: true Server: Docker Engine - Community Engine: Version: 20.10.3 API version: 1.41 (minimum version 1.12) Go version: go1.13.15 Git commit: 46229ca Built: Fri Jan 29 14:32:37 2021 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.4.3 GitCommit: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc: Version: 1.0.0-rc92 GitCommit: ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init: Version: 0.19.0 GitCommit: de40ad0 通常刚安装完docker时，使用docker version来验证docker的client和server是否可用。如果server显示权限不足，可以通过sudo docker或 给docker添加sudo权限。 镜像仓库 ","date":"2021-02-12","objectID":"/2021/02/docker_command/:2:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"login docker login：登录到一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库。 语法 docker login [OPTIONS] [SERVER] Options: -p, --password string 登录的密码 --password-stdin 使用标准输入输入密码 -u, --username string 登录的用户名 实例 docker login -u 用户名 -p 密码 ","date":"2021-02-12","objectID":"/2021/02/docker_command/:3:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"logout docker logout：登出一个Docker镜像仓库，如果没有指定镜像仓库地址，默认为官方仓库。 语法 docker logout [SERVER] 实例 docker logout ","date":"2021-02-12","objectID":"/2021/02/docker_command/:4:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"pull docker pull：从镜像仓库中拉取或者更新指定镜像。 语法 docker pull [OPTIONS] NAME[:TAG|@DIGEST] Options: -a, --all-tags 下载镜像在仓库中的所有版本 --disable-content-trust 忽略镜像的校验，默认开启 --platform string 如果服务器支持多平台，设置平台 -q, --quiet 静默拉取 实例 docker pull hello-world docker pull hello-world -a docker pull hello-wprld -q ","date":"2021-02-12","objectID":"/2021/02/docker_command/:5:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"push docker push：将本地的镜像上传到镜像仓库（已经登录到镜像仓库）。 语法 docker push [OPTIONS] NAME[:TAG] Options: -a, --all-tags 推送本地所有打过tag的镜像 --disable-content-trust 忽略镜像的检验，默认开启 -q, --quiet 静默上传 实例 docker push hello-world:v1 ","date":"2021-02-12","objectID":"/2021/02/docker_command/:6:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"search docker search：从镜像仓库中查找镜像。 语法 docker search [OPTIONS] TERM Options: -f, --filter filter 根据过滤的条件输出结果 --format string 使用特定的模板输出搜索结果 --limit int 最大搜索结果，默认25 --no-trunc 显示完整的镜像描述 实例 docker search hello-world -f STARS=10 --limit=2 NAME DESCRIPTION STARS OFFICIAL AUTOMATED hello-world Hello World! (an example of minimal Dockeriz… 1380 [OK] tutum/hello-world Image to test docker deployments. Has Apache… 78 [OK] 参数说明： NAME：镜像仓库源的名称 DESCRIPTION：镜像的描述 STARS：表示点赞，关注的个数 OFFICIAL：是否是官方发布 AUTOMATED：自动构建 ","date":"2021-02-12","objectID":"/2021/02/docker_command/:7:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"images docker images：列出本地镜像 语法 docker images [OPTIONS] [REPOSITORY[:TAG]] Options: -a, --all 列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层） --digests 显示镜像的摘要信息 -f, --filter filter 显示满足条件的镜像 --format string 指定返回值的模板文件 --no-trunc 显示完整的镜像信息 -q, --quiet 只显示镜像ID 实例 docker images REPOSITORY TAG IMAGE ID CREATED SIZE registry.cn-hangzhou.aliyuncs.com/google_containers/kicbase v0.0.15-snapshot4 06db6ca72446 2 months ago 941MB hello-world latest bf756fb1ae65 13 months ago 13.3kB ","date":"2021-02-12","objectID":"/2021/02/docker_command/:8:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"rmi docker rmi：删除本地一个或多个镜像 语法 docker rmi [OPTIONS] IMAGE [IMAGE...] Options: -f, --force 强制删除 --no-prune 不移除该镜像的过程镜像，默认移除 实例 docker rmi hello-world -f Untagged: hello-world:latest Untagged: hello-world@sha256:31b9c7d48790f0d8c50ab433d9c3b7e17666d6993084c002c2ff1ca09b96391d Deleted: sha256:bf756fb1ae65adf866bd8c456593cd24beb6a0a061dedf42b26a993176745f6b Deleted: sha256:9c27e219663c25e0f28493790cc0b88bc973ba3b1686355f221c38a36978ac63 ","date":"2021-02-12","objectID":"/2021/02/docker_command/:9:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"tag docker tag：标记本地镜像，将其归入某一仓库。 语法 docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG] 用法 docker tag hello-world hello-world:v1 docker images hello-world REPOSITORY TAG IMAGE ID CREATED SIZE hello-world latest bf756fb1ae65 13 months ago 13.3kB hello-world v1 bf756fb1ae65 13 months ago 13.3kB ","date":"2021-02-12","objectID":"/2021/02/docker_command/:10:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"build docker build：使用Dockerfile创建镜像。 语法 docker build [OPTIONS] PATH | URL | - Options: --add-host list 添加(host:ip) --build-arg list 设置镜像创建时的变量 --cache-from strings 镜像缓存 --cgroup-parent string 容器可选的父cgroup --compress 压缩构建上下文使用gzip --cpu-period int 限制cpu cfs周期 --cpu-quota int 限制cpu cfs配额 -c, --cpu-shares int 设置cpu使用权重 --cpuset-cpus string 设置使用的cpu id --cpuset-mems string 设置使用的内存id --disable-content-trust 忽略校验，默认开启 -f, --file string 指定要使用的Dockerfile路径，默认是'PATH/Dockerfile' --force-rm 设置镜像过程中删除中间容器 --iidfile string 写入镜像id到文件 --isolation string 使用容器隔离技术 --label list 设置镜像使用的元数据 -m, --memory bytes 设置内存最大值 --memory-swap bytes 设置swap的最大值为内存+swap，-1表示不受限 --network string 在构建期间设置RUN指令的网络模式，默认为\"default\" --no-cache 创建镜像过程中不使用缓存 --pull 尝试去更新镜像的最新版本 -q, --quiet 安静模式，成功后只输出镜像ID --rm 设置镜像成功后删除中间容器 --security-opt strings 安全选项 --shm-size bytes 设置/dev/shm，默认值是64M -t, --tag list 镜像的名字及标签，通常为'name:tag'格式，可以在一次构建中为一个镜像设置多个标签 --target string 设置指定构建步骤 --ulimit ulimit Ulimit选项 用法 docker build -t my-image:v1 . ","date":"2021-02-12","objectID":"/2021/02/docker_command/:11:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"history docker history：展示一个镜像的历史。 语法 docker history [OPTIONS] IMAGE Options: --format string 指定模板输出 -H, --human 以可读的格式打印镜像大小和日期，默认true --no-trunc 显示完整的提交记录 -q, --quiet 仅列出提交记录的ID 实例 docker history hello-world:v1 IMAGE CREATED CREATED BY SIZE COMMENT bf756fb1ae65 13 months ago /bin/sh -c #(nop) CMD [\"/hello\"] 0B \u003cmissing\u003e 13 months ago /bin/sh -c #(nop) COPY file:7bf12aab75c3867a… 13.3kB ","date":"2021-02-12","objectID":"/2021/02/docker_command/:12:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"save docker save：保存一个或多个镜像成tar归档文件（默认标准输出）。 语法 docker save [OPTIONS] IMAGE [IMAGE...] Options: -o, --output string 输出到的文件 实例 docker save -o hello.tar hello-world:v1 ll hello.tar -rw-------. 1 golang golang 24576 2月 11 19:57 hello.tar ","date":"2021-02-12","objectID":"/2021/02/docker_command/:13:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"load docker load：导入使用docker save命令导出的镜像。 语法 docker load [OPTIONS] Options: -i, --input string 指定导入的文件，代替标准输入 -q, --quiet 精简输出信息 实例 $ docker images hello-world REPOSITORY TAG IMAGE ID CREATED SIZE $ docker load -i hello.tar 9c27e219663c: Loading layer [==================================================\u003e] 15.36kB/15.36kB Loaded image: hello-world:v1 $ docker images hello-world REPOSITORY TAG IMAGE ID CREATED SIZE hello-world v1 bf756fb1ae65 13 months ago 13.3kB ","date":"2021-02-12","objectID":"/2021/02/docker_command/:14:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"import docker import：从归档文件中创建镜像。 语法 docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] Options: -c, --change list 应用docker指令创建镜像 -m, --message string 提交时的说明文字 --platform string 设置多平台可用 实例 $ docker import hello.tar hello-world:v2 sha256:0243f312226d99ba0cd5e167e894c2910803595a8f81aec270305ae52dca41e6 $ docker images hello-world REPOSITORY TAG IMAGE ID CREATED SIZE hello-world v2 0243f312226d 7 seconds ago 18.3kB ","date":"2021-02-12","objectID":"/2021/02/docker_command/:15:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"image docker image：管理镜像 语法 docker image COMMAND Commands: build 同docker build history 同docker history import 同docker import inspect 展示镜像的详细信息 load 同docker load ls 列举镜像 prune 删除未使用的镜像 pull 同docker pull push 同docker push rm 同docker rmi save 同docker save tag 同docker tag ","date":"2021-02-12","objectID":"/2021/02/docker_command/:16:0","tags":["docker"],"title":"Docker命令大全","uri":"/2021/02/docker_command/"},{"categories":["月霜天的小笔记"],"content":"什么是defer？ defer是go语言提供的一种用于注册延迟调用的机制，让函数或语句可以在当前函数执行完毕后（包括通过return正常结束或panic导致的异常结束）执行。 适用场景： 打开/关闭连接 加锁/释放锁 打开/关闭文件等 defer在一些需要回收资源的场景非常有用，可以很方便在函数结束前做一些清理工作。 ","date":"2021-02-11","objectID":"/2021/02/defer/:1:0","tags":["defer","golang"],"title":"Defer的使用方法","uri":"/2021/02/defer/"},{"categories":["月霜天的小笔记"],"content":"为什么要用defer？ 在编程过程中，经常需要打开一些资源，比如数据库、文件、锁等，这些资源都需要用完释放，否则会造成内存泄漏。 当然在使用过程中，可以在函数结束时显式关闭资源，但是如果在打开和关闭资源之间如果发生了panic会退出函数，导致关闭资源没有被执行。因为这样一颗语法糖，减少了很多资源泄漏的情况。 ","date":"2021-02-11","objectID":"/2021/02/defer/:2:0","tags":["defer","golang"],"title":"Defer的使用方法","uri":"/2021/02/defer/"},{"categories":["月霜天的小笔记"],"content":"defer底层 官方对defer的解释： Each time a “defer” statement executes, the function value and parameters to the call are evaluated as usual and saved anew but the actual function is not invoked. Instead, deferred functions are invoked immediately before the surrounding function returns, in the reverse order they were deferred. If a deferred function value evaluates to nil, execution panics when the function is invoked, not when the “defer” statement is executed. 每次defer语句执行时，会把函数“压栈”，函数的参数会被拷贝下来，当外层函数退出时，defer函数按照定义的逆序执行，如果defer执行的函数为nil，那么会在最终调用函数产生panic。 这里有一道经典题： func main() { a,b := 1,2 defer cal(\"1\",a,cal(\"10\",a,b)) a = 0 defer cal(\"2\",a,cal(\"20\",a,b)) } func cal(index string, a, b int) int { ret := a + b fmt.Println(index,a,b,ret) return ret } // Output: 10 1 2 3 20 0 2 2 2 0 2 2 1 1 3 4 这是遵循先入后出的原则，同时保留当前变量的值。 看看下面这道题： func f1() (r int) { defer func() { r++ } return 0 } func f2() (r int) { t := 5 defer func() { t = t + 5 } return t } func f3() (r int) { defer func(r int) { r = r + 5 }(r) return 1 } // Output: 1 5 1 你能正确答对吗？ 关键点在于理解这条语句： return xxx 这条语句并不是一个原子命令，经过编译后，变成3条指令： 1、返回值=xxx 2、调用defer函数 3、空的return 那么我们来拆解上面3个函数。 func f1() (r int) { // 1、赋值 r = 0 // 2、闭包引用 defer func() { r++ } // 3、空的return return 0 } // defer是闭包引用，所以返回值被修改，所以f1()返回1 func f2() (r int) { t := 5 // 1、赋值 r = t // 2、闭包引用，但没有修改r defer func() { t = t + 5 } // 3、空的return return t } // 没涉及返回值r的操作，所以返回5 func f3() (r int) { // 1、赋值 r = 1 // 2、r作为参数传值，不会修改返回值的r defer func(r int) { r = r + 5 }(r) // 3、空的return return } // 第二步r是作为函数参数使用的，是一份复制，defer语句中的r和外面的r是两个变量，里面r的变化不会改变外面r，所以返回1. ","date":"2021-02-11","objectID":"/2021/02/defer/:3:0","tags":["defer","golang"],"title":"Defer的使用方法","uri":"/2021/02/defer/"},{"categories":["月霜天的小笔记"],"content":"iota是golang语言的常数计量器，只能在常量的表达式中使用。 iota在const关键字出现时被重置为0(const内部的第一行之前)。使用iota能简化定义。 1、iota只能在常量的表达式使用。 2、每次const出现时，都会让iota初始化为0，使后面的变量自动增长。 const ( a = iota // 0 b // 1 c // 2 ) 3、允许自定义类型 // go/src/time/time.go type Weekday int const ( Sunday Weekday = iota Monday Tuesday Wednesday Thursday Friday Saturday ) 周日对应0，周一对应1，如此类推。 4、可以跳过的值 type Weekday int const ( Sunday Weekday = iota Monday _ _ Thursday Friday Saturday ) 对应的值不变，适用场景：某些枚举值可能不需要。 5、位掩码 const ( a = 1\u003c\u003ciota // 1 b // 2 c // 4 ) 是连续的2的幂。 6、数量级 const ( B = 1 \u003c\u003c (10*iota) KB MB GB TB ) 按照这样的生成规则可以按照数量级生成值。 7、定义在一行的情况 const ( a,b = iota,iota+1 // 0,1 c,d // 1,2 e,f // 2,3 ) iota会在下一行得到增长，而不是立即获取它的应用。 8、中间插队 const ( a = iota // 0 b = 2 // 2 c // 2 d = iota // 3 ) const ( a = 2 // 2 b = iota // 1 c // 2 ) ","date":"2021-02-10","objectID":"/2021/02/itoa/:0:0","tags":["iota","golang"],"title":"Iota的使用方法","uri":"/2021/02/itoa/"},{"categories":["月霜天的小笔记"],"content":"背景 在复杂的分布式系统中，往往需要对大量的数据和消息进行唯一标识。数据日益增长，对数据库需要进行切分，而水平切分数据库需要一个唯一ID来标识一条数据或消息，数据库的自增ID显然不能满足需求。那么对于分布式全局ID有什么要求呢？ 全局唯一性：不能出现重复的ID号。 趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。 单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。 信息安全：如果ID是连续的，会出现安全问题，在一些场景中，会需要ID无规则，不规则。 ","date":"2021-02-08","objectID":"/2021/02/uuid/:1:0","tags":["uuid","snowflake"],"title":"生成uuid的几种方式","uri":"/2021/02/uuid/"},{"categories":["月霜天的小笔记"],"content":"UUID UUID(Universally Unique Identifier)是一个128位标识符，在其规范的文本表示中，UUID 的 16 个 8 位字节表示为 32 个十六进制（基数16）数字，显示在由连字符分隔 ‘-’ 的五个组中，“8-4-4-4-12” 总共 36 个字符（32 个字母数字字符和 4 个连字符）。例如：123e4567-e89b-12d3-a456-426655440000。 优点：性能高，本地生成，没有网络消耗 缺点： 1、不易存储：UUID太长，很多场景不适用。 2、信息不安全：基于MAC地址生成的UUID算法可能造成MAC地址泄露。 3、没有排序，无法保证递增趋势。 4、不易读，存储空间大。 go两种生成UUID的第三方包： github.com/google/uuid github.com/satori/go.uuid ","date":"2021-02-08","objectID":"/2021/02/uuid/:2:0","tags":["uuid","snowflake"],"title":"生成uuid的几种方式","uri":"/2021/02/uuid/"},{"categories":["月霜天的小笔记"],"content":"Snowflake snowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。 1、实现原理： 1位最高位：符号位不使用，0表示正数，1表示负数。 41位时间戳：1\u003c\u003c41 = 1000*3600*24*365 = 69 年。 10位工作机器id：如果我们对IDC划分有需求可以用5位给IDC，5位给工作机器，这样就可以表示32个IDC，每个IDC下有32台机器。 12位自增ID：可以表示2^12^个ID。 理论上snowflake方案的QPS约为409.3w/s，这种分配方式可以保证在任何一个IDC的任何一台机器在任意毫秒内生成的ID都是不同的。 优点： 毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。 可以根据自身业务特性分配bit位，非常灵活。 缺点： 强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。 代码实现： package main import ( \"errors\" \"fmt\" \"runtime\" \"sync\" \"time\" ) //global var var sequence int = 0 var lastTime int = -1 //every segment bit var workerIdBits = 5 var datacenterIdBits = 5 var sequenceBits = 12 //every segment max number var maxWorkerId int = -1 ^ (-1 \u003c\u003c workerIdBits) var maxDatacenterId int = -1 ^ (-1 \u003c\u003c datacenterIdBits) var maxSequence int = -1 ^ (-1 \u003c\u003c sequenceBits) //bit operation shift var workerIdShift = sequenceBits var datacenterShift = workerIdBits + sequenceBits var timestampShift = datacenterIdBits + workerIdBits + sequenceBits type Snowflake struct { datacenterId int workerId int epoch int mt *sync.Mutex } func NewSnowflake(datacenterId int, workerId int, epoch int) (*Snowflake, error) { if datacenterId \u003e maxDatacenterId || datacenterId \u003c 0 { return nil, errors.New(fmt.Sprintf(\"datacenterId cant be greater than %d or less than 0\", maxDatacenterId)) } if workerId \u003e maxWorkerId || workerId \u003c 0 { return nil, errors.New(fmt.Sprintf(\"workerId cant be greater than %d or less than 0\", maxWorkerId)) } if epoch \u003e getCurrentTime() { return nil, errors.New(fmt.Sprintf(\"epoch time cant be after now\")) } sf := Snowflake{datacenterId, workerId, epoch, new(sync.Mutex)} return \u0026sf, nil } func (sf *Snowflake) getUniqueId() int { sf.mt.Lock() defer sf.mt.Unlock() //get current time currentTime := getCurrentTime() //compute sequence if currentTime \u003c lastTime { //occur clock back //panic or wait,wait is not the best way.can be optimized. currentTime = waitUntilNextTime(lastTime) sequence = 0 } else if currentTime == lastTime { //at the same time(micro-second) sequence = (sequence + 1) \u0026 maxSequence if sequence == 0 { //overflow max num,wait next time currentTime = waitUntilNextTime(lastTime) } } else if currentTime \u003e lastTime { //next time sequence = 0 lastTime = currentTime } //generate id return (currentTime-sf.epoch)\u003c\u003ctimestampShift | sf.datacenterId\u003c\u003cdatacenterShift | sf.workerId\u003c\u003cworkerIdShift | sequence } func waitUntilNextTime(lasttime int) int { currentTime := getCurrentTime() for currentTime \u003c= lasttime { time.Sleep(1 * time.Second / 1000) //sleep micro second currentTime = getCurrentTime() } return currentTime } func getCurrentTime() int { return int(time.Now().UnixNano() / 1e6) //micro second } func main() { runtime.GOMAXPROCS(runtime.NumCPU()) datacenterId := 0 workerId := 0 epoch := 1596850974657 s, err := NewSnowflake(datacenterId, workerId, epoch) if err != nil { panic(err) } var wg sync.WaitGroup for i := 0; i \u003c 1000000; i++ { wg.Add(1) go func() { fmt.Println(s.getUniqueId()) wg.Done() }() } wg.Wait() } ","date":"2021-02-08","objectID":"/2021/02/uuid/:3:0","tags":["uuid","snowflake"],"title":"生成uuid的几种方式","uri":"/2021/02/uuid/"},{"categories":["月霜天的小笔记"],"content":"数据库ID 利用数据库字段设置auto_increment_increment和auto_increment_offset来保证ID自增，每次业务使用一下SQL读写MySQL得到ID。 begin;REPLACEintoTickets(id)values(null);selectLAST_INSERT_ID();commit; 优点：简单，利用数据库的功能实现，成本小；id单调递增。 缺点：强依赖数据库，当数据库不可用时，是致命问题；ID发号性能瓶颈限制在单台MySQL的读写性能上。 对于MySQL性能问题，可用如下方法解决： 在分布式系统中部署多台机器，每台机器设置不同的初始值，且步长相等。例如设置步长为2，TicketServer1的初始值为1 (1,3,5,7...), TicketServer1的初始值为2(2,4,6,8...)。 主键生成策略 缺点： 水平扩展比较困难，事先定好步长和机器后，如果后续新增机器，不容易扩容。 数据库压力还是大，只能靠堆机器来提高性能。 ","date":"2021-02-08","objectID":"/2021/02/uuid/:4:0","tags":["uuid","snowflake"],"title":"生成uuid的几种方式","uri":"/2021/02/uuid/"},{"categories":["月霜天的小笔记"],"content":"MongoDB ID MongoDB官方文档 ObjectID和snowflake算法类似，它设计成轻量型的，不同的机器都能用全局唯一的同种方法便利生成。通过 时间戳+机器+pid+自增id 共12个字节，通过 4+3+2+3 的方式生成24位的十六进制字符。 ","date":"2021-02-08","objectID":"/2021/02/uuid/:5:0","tags":["uuid","snowflake"],"title":"生成uuid的几种方式","uri":"/2021/02/uuid/"},{"categories":["月霜天的小笔记"],"content":"Zookeeper ID zookeeper主要通过其znode数据版本来生成序列号，可以生成32位和64位的数据版本号，客户端可以使用这个版本号来作为唯一的序列号。 很少会使用zookeeper来生成唯一ID。主要是由于需要依赖zookeeper，并且是多步调用API，如果在竞争较大的情况下，需要考虑使用分布式锁。因此，性能在高并发的分布式环境下，也不甚理想。 ","date":"2021-02-08","objectID":"/2021/02/uuid/:6:0","tags":["uuid","snowflake"],"title":"生成uuid的几种方式","uri":"/2021/02/uuid/"},{"categories":["月霜天的小笔记"],"content":"二维数组的排列顺序 数组在内存中是按行存储的，按行遍历时可以由指向数组的第一个数的指针一直向后遍历，由于二维数组的内存地址是连续的，当前行的尾和下一行的头相邻。 用代码来打印数组的地址。 func main() { var a int32 fmt.Println(unsafe.Sizeof(a)) n := 4 array := generateArray(n) for i := 0; i \u003c n; i++ { fmt.Printf(\"%p \\n\",array[i]) } } func generateArray(n int) [][]int32 { var arr = make([][]int32,n) for i := 0; i \u003c n; i++ { arr[i] = make([]int32,n) for j := 0; j \u003c n; j++ { arr[i][j] = 1 } } return arr } // Output: 4 0xc0000a0090 0xc0000a00a0 0xc0000a00b0 0xc0000a00c0 int32占用4个字节，4个int32占用16个字节，这与我们得到一个数组的地址是对应的。 我们眼中的二维数组 内存中的二维数组 那么二维数组按行遍历相当于按照内存顺序读取，而按列遍历不按内存顺序读取。 按行读取比按列读取的效率高体现在以下几个方面： CPU高速缓存：在计算机系统中，CPU高速缓存（英语：CPU Cache，在本文中简称缓存）是用于减少处理器访问内存所需平均时间的部件。在金字塔式存储体系中它位于自顶向下的第二层，仅次于CPU寄存器。其容量远小于内存，但速度却可以接近处理器的频率。当处理器发出内存访问请求时，会先查看缓存内是否有请求数据。如果存在（命中），则不经访问内存直接返回该数据；如果不存在（失效），则要先把内存中的相应数据载入缓存，再将其返回处理器。缓存之所以有效，主要是因为程序运行时对内存的访问呈现局部性（Locality）特征。这种局部性既包括空间局部性（Spatial Locality），也包括时间局部性（Temporal Locality）。有效利用这种局部性，缓存可以达到极高的命中率。 缓存从内存中抓取一般都是整个数据块，所以它的物理内存是连续的，几乎都是同行不同列的，而如果内循环以列的方式进行遍历的话，将会使整个缓存块无法被利用，而不得不从内存中读取数据，而从内存读取速度是远远小于从缓存中读取数据的。随着数组元素越来越多，按列读取速度也会越来越慢。 代码验证 func main() { arr := generateArray(2000) t0 := time.Now() readCols(arr) t1 := time.Now() readRows(arr) t2 := time.Now() fmt.Println(t1.Sub(t0),t2.Sub(t1)) } func generateArray(n int) [][]int32 { var arr = make([][]int32,n) for i := 0; i \u003c n; i++ { arr[i] = make([]int32,n) for j := 0; j \u003c n; j++ { arr[i][j] = 1 } } return arr } func readCols(arr [][]int) { for i := 0; i \u003c len(arr); i++ { for j := 0; j \u003c len(arr[0]); j++ { arr[i][j] = 1 } } } func readRows(arr [][]int) { for i := 0; i \u003c len(arr); i++ { for j := 0; j \u003c len(arr[0]); j++ { arr[j][i] = 1 } } } 可以验证按列读取的时间远远大于按行读取。 ","date":"2021-02-08","objectID":"/2021/02/%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E9%81%8D%E5%8E%86%E6%95%88%E7%8E%87/:1:0","tags":["二维数组"],"title":"二维数组按行和按列遍历的效率","uri":"/2021/02/%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E9%81%8D%E5%8E%86%E6%95%88%E7%8E%87/"},{"categories":["月霜天的小笔记"],"content":"排序算法 所谓的排序算法就是将一串记录，按照递增或递减的顺序排列起来。 通常提到的一共有十种排序：冒泡、选择、插入、快速、归并、堆、希尔、计数、桶、基数 比较类排序：通过比较来决定元素间的相对次序，通常其时间复杂度不能突破O(nlogn)，因此又称为非线性时间比较类排序。 非比较类排序：不通过比较元素间的相对次序，可以突破基于比较排序的时间下限，以线性时间运行，因此又称为线性时间非比较类排序。 时间复杂度： 排序方法 时间复杂度(平均) 时间复杂度(最坏) 时间复杂度(最好) 空间复杂度 稳定性 冒泡排序 O(n^2^) O(n^2^) O(n) O(1) 稳定 选择排序 O(n^2^) O(n^2^) O(n^2^) O(1) 不稳定 插入排序 O(n^2^) O(n^2^) O(n) O(1) 稳定 快速排序 O(nlogn) O(n^2^) O(nlogn) O(nlogn) 不稳定 归并排序 O(nlogn) O(nlogn) O(nlogn) O(n) 稳定 堆排序 O(nlogn) O(nlogn) O(nlogn) O(1) 不稳定 希尔排序 O(n^1.3^) O(n^2^) O(n) O(1) 稳定 计数排序 O(n+k) O(n+k) O(n+k) O(n+k) 稳定 桶排序 O(n+k) O(n^2^) O(n) O(n+k) 稳定 基数排序 O(n*k) O(n*k) O(n*k) O(n+k) 稳定 稳定性：如果a=b，并且a在b的前面，排序后a一定在b的前面，那么称算法是稳定的，如果不一定在前面，那么称算法是不稳定的。 ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:1:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"冒泡排序 冒泡排序(Bubble Sort)是一种简单直观的排序算法。它重复地访问要排序的数列，一次比较两个元素，如果顺序错误就调换顺序。走访数列的工作是重复地进行指导没有再需要元素交换，也就是说该数列已经排序完成。由于越小的元素会经过交换慢慢地到达顶端，就像泡泡一样会上浮，所以称为冒泡排序。 1、算法步骤 ​ 1、比较相邻的元素，如果第一个比第二个大，就交换它们。 ​ 2、对每一对相邻元素做同样的工作，从开始第一对到结尾的最后一对，这步做完后，末尾元素是最大的元素。 ​ 3、针对所有的元素重复以上步骤，除了最后一个元素 ​ 4、重复步骤1~3，直到没有任意一对元素需要比较。 2、动画演示 3、情况 最好情况：数列是正序，只需要遍历一遍，时间复杂度最好为O(n)。 最坏情况：数列是倒序，每一对都需要进行比较，时间复杂度最坏为O(n^2^)。 时间复杂度平均为O(n^2^)，空间复杂度为O(1)，是稳定排序。 4、Golang实现 func bubbleSort(arr []int) { n := len(arr) for i := 0; i \u003c n-1; i++ { for j := i + 1; j \u003c n; j++ { if arr[i] \u003e arr[j] { arr[i], arr[j] = arr[j], arr[i] } } } } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:2:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"选择排序 选择排序(Selection Sort)是一种简单直观的排序算法。它的工作原理是：首先在序列中找到最小元素，放在序列的首位，然后再从剩下的序列中寻找最小元素，放到已排序序列的末尾。 1、算法步骤 ​ 1、首先在未排序序列中找到最小元素，存放到排序序列的起始位置 ​ 2、再从剩余未排序序列中继续寻找最小元素，存放到排序序列的末尾 ​ 3、重复第2步，直到所有元素排序完毕。 2、动画演示 3、情况 时间复杂度为O(n^2^)，因为无论如何都需要遍历序列找到最小值，所以最好和最坏都是O(n^2^)。 空间复杂度为O(n^2^)，是不稳定排序。 4、Golang实现 func selectionSort(arr []int) { for i := 0; i \u003c len(arr); i++ { min := i for j := i + 1; j \u003c len(arr); j++ { if arr[j] \u003c arr[min] { min = j } } arr[min], arr[i] = arr[i], arr[min] } } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:3:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"插入排序 插入排序(Insertion Sort)是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列由后向前扫描，找到相应位置并插入。 1、算法步骤 ​ 1、把第一个元素看成一个有序序列，把第二个元素到最后一个元素看成一个未排序序列。 ​ 2、从头扫描，将扫描到的每个元素插入有序序列的适当位置。 2、动画演示 3、情况 最坏情况：每一个待插入的元素都需要插入到序列首位，即原序列是倒序序列，时间复杂度为O(n^2^)。 最好情况：每一个待插入的元素都需要插入到序列末位，即原序列是正序序列，时间复杂度为O(n) 。 时间复杂度平均为 O(n^2^)，空间复杂度为O(1) 是稳定排序。 4、Golang实现 func insertionSort(arr []int) { for i := 1; i \u003c len(arr); i++ { current := arr[i] preIndex := i - 1 for ; preIndex \u003e= 0 \u0026\u0026 current \u003c arr[preIndex]; preIndex-- { arr[preIndex+1] = arr[preIndex] } arr[preIndex+1] = current } } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:4:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"快速排序 快速排序(Quick Sort)是通过一趟排序将待排记录分隔成独立的两部分，其中一部分的关键字比另一部分的关键字小，则可分别对这两部分记录继续进行排序，直到整个序列有序。 1、算法步骤 ​ 1、从序列中挑出一个元素，作为基准。 ​ 2、重新排列数列，所有元素比基准小的放在基准前面，所有元素比基准大的放在基准后面。 ​ 3、递归地把小于基准元素的子序列和大于基准元素的子序列排序。 2、动画演示 3、情况 时间复杂度平均为O(nlogn) ，空间复杂度为O(nlogn)，是不稳定排序。 4、Golang实现 func quickSort(nums []int, left, right int) { if left \u003c right { mid := partition(nums,left,right) quickSort(nums,left,mid) quickSort(nums,mid+1,right) } } func partition(nums []int, left, right int) int { i,j := left+1,right for i\u003cj { if nums[i] \u003e nums[left] { nums[i],nums[j] = nums[j],nums[i] j-- } else { i++ } } if nums[i] \u003e= nums[left] { i-- } nums[left],nums[i] = nums[i],nums[left] return i } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:5:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"归并排序 归并排序(Merge Sort)是建立在归并操作上的一种有效排序算法，采用了分而治之的思想。 1、算法步骤 ​ 1、把长度为n的序列分为两个长度为n/2的子序列。 ​ 2、对这两个子序列分别采用归并排序。 ​ 3、将两个排序好的子序列合并成一个最终的排序序列。 2、动画演示 3、情况 时间复杂度为O(nlogn)，空间复杂度为O(n)，是稳定排序方法。 4、Golang实现 func mergeSort(nums []int, start,end int) { if start \u003c end { mid := (start+end)/2 mergeSort(nums,start,mid) // 左边排序 mergeSort(nums,mid+1,end) // 右边排序 merge(nums,start,mid,end) // 合并数组 } } func merge(nums []int, start, mid, end int) { i,j := start,mid+1 ret := []int{} for i \u003c= mid \u0026\u0026 j \u003c= end { if nums[i] \u003c= nums[j] { ret = append(ret, nums[i]) i++ } else { ret = append(ret, nums[j]) j++ } } ret = append(ret, nums[i:mid+1]...) ret = append(ret, nums[j:end+1]...) for k, v := range ret { nums[start+k] = v } } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:6:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"堆排序 堆排序(Heap Sort)是指利用堆这种数据结构所设计的一种排序算法。堆是一种近似于完全二叉树的结构，并同时满足堆积的性质：子节点的键值或索引总小于(或大于)父节点。 大根堆：每个节点的值都大于或等于其子节点的值，在堆排序算法中用于升序排列； 小根堆：每个节点的值都小于或等于其子节点的值，在堆排序算法中用于降序排列； 1、算法步骤 ​ 1、将待排序列构建成一个堆 H[0……n-1]，根据(升序降序)选择大根堆或小跟堆。 ​ 2、把堆顶和堆尾互换。 ​ 3、把堆的尺寸缩小 1，并调用 shift_down(0)，目的是把新的数组顶端数据调整到相应位置； ​ 4、重复步骤 2，直到堆的尺寸为 1。 2、动画演示 3、情况 时间复杂度平均为O(nlogn) ，空间复杂度 O(1)， 是不稳定排序。 4、Golang实现 func heapSort(arr []int) []int { arrLen := len(arr) buildMaxHeap(arr, arrLen) for i := arrLen - 1; i \u003e= 0; i-- { swap(arr, 0, i) arrLen -= 1 heapify(arr, 0, arrLen) } return arr } func buildMaxHeap(arr []int, arrLen int) { for i := arrLen / 2; i \u003e= 0; i-- { heapify(arr, i, arrLen) } } func heapify(arr []int, i, arrLen int) { left := 2*i + 1 right := 2*i + 2 largest := i if left \u003c arrLen \u0026\u0026 arr[left] \u003e arr[largest] { largest = left } if right \u003c arrLen \u0026\u0026 arr[right] \u003e arr[largest] { largest = right } if largest != i { swap(arr, i, largest) heapify(arr, largest, arrLen) } } func swap(arr []int, i, j int) { arr[i], arr[j] = arr[j], arr[i] } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:7:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"希尔排序 希尔排序是插入排序的改进版本，与插入排序不同之处在于，它会优先比较距离较远的元素，又称缩小增量排序。 基本思想是：先将整个待排序的序列分割成若干个子序列分别进行插入排序，待整个序列“基本有序”时，在依次进行插入排序。 1、算法步骤 ​ 1、选择一个增量序列 t1,t2, ……, tk，其中ti \u003e tj，tk=1; ​ 2、按增量序列个数k，对序列进行k趟排序 ​ 3、每趟排序，根据对应的增量ti，将待排序分割成若干长度为m的子序列，分别对各子表进行直接插入排序。当增量因子为1时，整个序列作为一个表来处理，表长度即为整个序列的长度。 2、动画演示 3、Golang实现 func shellSort(arr []int) { n := len(arr) for step := n / 2; step \u003e= 1; step /= 2 { for i := step; i \u003c n; i += step { for j := i - step; j \u003e= 0; j -= step { if arr[j] \u003e arr[j+step] { arr[j], arr[j+step] = arr[j+step], arr[j] continue } break } } } } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:8:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"计数排序 计数排序(Counting Sort)不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 1、算法步骤 ​ 1、找出原数组中元素最大值，记为max。 ​ 2、创建一个新数组count，其长度是max+1，其元素默认为0 。 ​ 3、遍历原数组中的元素，以原数组中的元素作为count数组的索引，以原数组中出现的元素次数作为count数组的元素值。 ​ 4、创建结果数组result，起始索引index。 ​ 5、遍历count数组，找出其中元素值大于0的元素，将其对应的索引作为元素值填充到result数组中去，每处理一次，count中的该元素值减1，直到该元素值不大于0，依次处理count中剩下的元素。 ​ 6、返回结果数组result。 2、动画演示 3、情况 时间复杂度为O(n+k)，空间复杂度为O(n+k)，是稳定排序。 4、Golang实现 func countingSort(arr []int, maxVal int) { n := maxVal+1 nums := make([]int,n) var sortedIndex int for i := 0; i \u003c len(arr); i++ { nums[arr[i]]++ } for i := 0; i \u003c n; i++ { for nums[i] \u003e 0 { arr[sortedIndex] = i sortedIndex++ nums[i]-- } } } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:9:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"桶排序 桶排序(Bucket Sort)是计数排序的升级版，利用函数的映射关系，高效与否的关键在于映射函数的确定。假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。 1、算法步骤 ​ 1、设置一个定量的数组当做空桶。 ​ 2、遍历数据，并且把数据一个个放入到对应的桶中。 ​ 3、对每个不是空桶进行排序。 ​ 4、从不是空桶里把排好序的数据拼接起来。 2、动画演示 3、情况 最好情况：当输入的数据均匀分配到每个桶中，时间复杂度为 O(n) 。 最坏情况：输入的数据被分配到同一个桶中，时间复杂度O(n^2^) 。 时间复杂度平均为O(n+k) ，空间复杂度为O(n+k)，是稳定排序算法。 4、Golang实现 func quickSort(nums []int, start, end int) []int { if start \u003c end { i, j := start, end key := nums[(start+end)/2] for i \u003c= j { for nums[i] \u003c key { i++ } for nums[j] \u003e key { j-- } if i \u003c= j { nums[i], nums[j] = nums[j], nums[i] i++ j-- } } if start \u003c j { nums = quickSort(nums, start, j) } if end \u003e i { nums = quickSort(nums, i, end) } } return nums } func bucketSort(nums []int, bucketNum int) []int { bucket := [][]int{} for i := 0; i \u003c bucketNum; i++ { tmp := make([]int, 1) bucket = append(bucket, tmp) } //将数据分配到桶中 for i := 0; i \u003c len(nums); i++ { bucket[nums[i]/bucketNum] = append(bucket[nums[i]/bucketNum], nums[i]) } //循环所有的桶进行排序 index := 0 for i := 0; i \u003c bucketNum; i++ { if len(bucket[i]) \u003e 1 { //对每个桶内部进行排序,使用快排 bucket[i] = quickSort(bucket[i], 0, len(bucket[i])-1) for j := 1; j \u003c len(bucket[i]); j++ { //去掉一开始的tmp nums[index] = bucket[i][j] index++ } } } return nums } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:10:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小笔记"],"content":"基数排序 基数排序(Radix Sort)的原理是按照整数位数切割成不同的数字，然后按每个位数分别比较。 然后我们发现，计数排序、桶排序、基数排序都用到了桶的概念。 计数排序：每个桶只存单一键值 基数排序：根据键值的每位数字来分配桶 桶排序：每个桶存储一定范围的数值 1、算法步骤 ​ 1、取得数组中的最大数，并取得位数 ​ 2、arr为原始数组，从最低位开始取个位组成radix数组 ​ 3、对radix进行计数排序 2、动画演示 3、情况 时间复杂度为O(n*k)，空间复杂度为O(n+k)，是稳定排序算法。 4、Golang实现 func RadixSort(arr[] int) []int{ if len(arr)\u003c2{ return arr } maxl:=MaxLen(arr) return RadixCore(arr,0,maxl) } func RadixCore(arr []int,digit,maxl int) []int{ if digit\u003e=maxl{ return arr } radix:=10 count:=make([]int,radix) bucket:=make([]int,len(arr)) for i:=0;i\u003clen(arr);i++{ count[GetDigit(arr[i],digit)]++ } for i:=1;i\u003cradix;i++{ count[i]+=count[i-1] } for i:=len(arr)-1;i\u003e=0;i--{ d:=GetDigit(arr[i],digit) bucket[count[d]-1]=arr[i] count[d]-- } return RadixCore(bucket,digit+1,maxl) } func GetDigit(x,d int) int{ a:=[]int{1,10,100,1000,10000,100000,1000000} return (x/a[d])%10 } func MaxLen(arr []int) int{ var maxl,curl int for i:=0;i\u003clen(arr);i++{ curl=len(strconv.Itoa(arr[i])) if curl\u003emaxl{ maxl=curl } } return maxl } ","date":"2021-02-07","objectID":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/:11:0","tags":["golang","算法"],"title":"十大基础排序算法","uri":"/2021/02/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"},{"categories":["月霜天的小教程"],"content":"使用Navicate 15连接Oracle数据库出现如下错误 通过查询可知是oci.dll版本太低，使用的11.2版本。因为Navicate是通过Oracle客户端连接Oracle服务器，Oracle的客户端分为两种，一种是标准版，一种是简洁版，即Oracle Install Client。出现ORA-28547错误时，多数是因为Navicat本地的OCI版本与Oracle服务器服务器不符造成的。 OCI下载地址 这里看到许多文章提示不管使用的32位系统还是64位系统都应下载32为的Install Client 这里我实际操作了一下，64位的系统并不支持32位，所以一定要根据自己的系统版本下载。 打开Navicate程序，打开 “工具” -\u003e “选项” -\u003e “环境” -\u003e “OCI环境” 将刚才下载的oci.dll文件完整目录填上，确定后重启Navicate，就会发现可以成功连接了。 ","date":"2021-01-18","objectID":"/2021/01/oracle_connect/:0:0","tags":["问题","oracle"],"title":"使用Navicate连接Oracle失败 ORA-25847:connection to server failed,probable Orable Net admin error","uri":"/2021/01/oracle_connect/"},{"categories":["月霜天的小笔记"],"content":"并查集 目的: 解决元素分组问题 用途: 1、判断有向图中是否产生环 2、维护无向图的连通性，判断两个点是否在同一个连通块中 操作: 1、初始化: 每个集合的parent都是自己 2、查询: 查询集合的parent 3、合并: 把不相连的元素合并到同一个集合中 ","date":"2021-01-11","objectID":"/2021/01/%E5%B9%B6%E6%9F%A5%E9%9B%86/:0:1","tags":["golang","算法"],"title":"并查集","uri":"/2021/01/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"categories":["月霜天的小笔记"],"content":"方法 1、初始化 假如有编号为1, 2, 3, …, n的n个元素，我们用一个数组fa[]来存储每个元素的父节点（因为每个元素有且只有一个父节点，所以这是可行的）。 一开始，我们先将它们的父节点设为自己。 var fa = make([]int,n) for i := 0; i \u003c n; i++ { fa[i] = i } 2、查询 我们用递归的写法实现对代表元素的查询：一层一层访问父节点，直至根节点（根节点的标志就是父节点是本身）。 要判断两个元素是否属于同一个集合，只需要看它们的根节点是否相同即可。 find = func(x int) int { if x == fa[x] { return x } return find(fa[x]) } 路径压缩方法 find = func(x int) int { if x != fa[x] { fa[x] = find(fa[x]) } return fa[x] } 3、合并 合并操作也是很简单的，先找到两个集合的代表元素，然后将前者的父节点设为后者即可。 merge := func(i,j int) { fa[find(i)] = find(j) } 按秩合并 merge := func(i,j int) { xFa,yFa := find(i),find(j) if xFa==yFa { return } // x和y不在同一个集合中，合并它们 if xFa\u003cyFa { fa[xFa]=yFa } else if xFa \u003e yFa { fa[yFa]=xFa } else { fa[yFa]=xFa rank[x]++ } } 同时使用路径压缩、按秩（rank）合并优化的程序每个操作的平均时间仅为 O(alpha (n))， 其中 alpha (n) 是 { n=f(x)=A(x,x)} 的反函数，A 是急速增加的阿克曼函数。 因为 alpha (n) 是其反函数，故 alpha (n) 在 n 十分巨大时还是小于5。 因此，平均运行时间是一个极小的常数。 实际上，这是渐近最优算法：Fredman 和 Saks 在 1989 年解释了 Omega (alpha (n)) 的平均时间内可以获得任何并查集。 ","date":"2021-01-11","objectID":"/2021/01/%E5%B9%B6%E6%9F%A5%E9%9B%86/:0:2","tags":["golang","算法"],"title":"并查集","uri":"/2021/01/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"categories":["月霜天的小笔记"],"content":"例题 Leetcode547 班上有 N 名学生。其中有些人是朋友，有些则不是。他们的友谊具有是传递性。如果已知 A 是 B 的朋友，B 是 C 的朋友，那么我们可以认为 A 也是 C 的朋友。所谓的朋友圈，是指所有朋友的集合。 给定一个 N * N 的矩阵 M，表示班级中学生之间的朋友关系。如果M[i][j] = 1，表示已知第 i 个和 j 个学生互为朋友关系，否则为不知道。你必须输出所有学生中的已知的朋友圈总数。 示例 1: 输入: [[1,1,0], [1,1,0], [0,0,1]] 输出: 2 说明：已知学生0和学生1互为朋友，他们在一个朋友圈。 第2个学生自己在一个朋友圈。所以返回2。 示例 2: 输入: [[1,1,0], [1,1,1], [0,1,1]] 输出: 1 说明：已知学生0和学生1互为朋友，学生1和学生2互为朋友，所以学生0和学生2也是朋友，所以他们三个在一个朋友圈，返回1。 注意： N 在[1,200]的范围内。 对于所有学生，有M[i][i] = 1。 如果有M[i][j] = 1，则有M[j][i] = 1。 题解: func findCircleNum(isConnected [][]int) (ans int) { n := len(isConnected) parent := make([]int,n) for i := range parent { parent[i] = i } var find func(x int) int find = func(x int) int { if parent[x] != x { parent[x] = find(parent[x]) } return parent[x] } merge := func(from,to int) { parent[find(from)] = find(to) } for i := 0; i \u003c n; i++ { for j := i+1; j \u003c n; j++ { if isConnected[i][j] == 1 { merge(i,j) } } } for i, p := range parent { if i == p { ans++ } } return } ","date":"2021-01-11","objectID":"/2021/01/%E5%B9%B6%E6%9F%A5%E9%9B%86/:0:3","tags":["golang","算法"],"title":"并查集","uri":"/2021/01/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"categories":["月霜天的小教程"],"content":"RocketMQ 消息队列作为高并发系统的组件之一，能够帮助业务系统解构提高开发效率和系统稳定性。 优势： 削峰填谷：解决瞬时写压力导致的消息丢失、系统崩溃等问题 系统解耦：处理不同重要程度和不同能力级别系统之间的消息 提升性能：当存在一对多调用是，可以发一条消息给消息系统，让消息系统通知相关系统 蓄流压测：可以堆积一定的消息量来压测 ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:1:0","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"安装RocketMQ 官方地址 # git clone https://github.com/apache/rocketmq-docker.git # cd rocketmq-docker/ # ls CONTRIBUTING.md image-build LICENSE NOTICE product README.md stage.sh templates # cd image-build/ # ls build-image.sh Dockerfile-alpine Dockerfile-centos scripts update.sh ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:2:0","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"创建RocketMQ镜像 sh build-image.sh RMQ-VERSION BASE-IMAGE RMQ-VERSION BASE-IMAGE支持centos，alpine两种方式 我们使用 sh build-image.sh 4.7.1 alpine 构建时间有点长，需要耐心等待。 当构建完成之后会提示 Successfully built 128108c2e50d Successfully tagged apacherocketmq/rocketmq:4.7.1-alpine 那么我们就能查询到镜像 # docker images |grep mq apacherocketmq/rocketmq 4.7.1-alpine 128108c2e50d 4 9 seconds ago 145MB ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:2:1","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"生成配置 # cd .. # ls CONTRIBUTING.md image-build LICENSE NOTICE product README.md stage.sh templates # sh stage.sh 4.7.1 (这里的4.7.1对应之前的镜像版本) Stage version = 4.7.1 mkdir /root/rocketmq/rocketmq-docker/stages/4.7.1 staged templates into folder /root/rocketmq/rocketmq-docker/stages/4.7.1 # ls CONTRIBUTING.md image-build LICENSE NOTICE product README.md stages stage.sh templates 生成了stages目录，里面存放配置模板文件 # cd stages/ # ls 4.7.1 # cd 4.7.1/ # ls templates # cd templates/ # ls data kubernetes play-docker-compose.sh play-docker.sh play-kubernetes.sh ssl docker-compose play-consumer.sh play-docker-dledger.sh play-docker-tls.sh play-producer.sh 1、单机 ./play-docker.sh alpine 2、docker-compose ./play-docker-compose.sh 3、kubernetes集群 ./play-kubernetes.sh 4、Cluster of Dledger storage(RocketMQ需要4.4.0版本以上) ./play-docker-dledger.sh 5、TLS ./play-docker-tls.sh ./play-producer.sh ./play-consumer.sh 我这里选择的是单机部署，可以看到生成了两个容器 # docker ps |grep mq 5b557ea1e6be apacherocketmq/rocketmq:4.7.1-alpine \"sh mqbroker\" 25 seconds ago Up 24 seconds 0.0.0.0:10909-\u003e10909/tcp, 9876/tcp, 0.0.0.0:10911-10912-\u003e10911-10912/tcp rmqbroker 8b1318aee5d6 apacherocketmq/rocketmq:4.7.1-alpine \"sh mqnamesrv\" 26 seconds ago Up 25 seconds 10909/tcp, 0.0.0.0:9876-\u003e9876/tcp, 10911-10912/tcp rmqnamesrv 验证RocketMQ启动成功 1、使用命令 docker ps|grep rmqbroker 找到RocketMQ broker的容器id 2、使用命令 docker exec -it 5b557ea1e6be ./mqadmin clusterList -n {nameserver_ip}:9876 验证RocketMQ broker工作正常 # docker exec -it 5b557ea1e6be ./mqadmin clusterList -n {nameserver_ip}:9876 RocketMQLog:WARN No appenders could be found for logger (io.netty.util.internal.PlatformDependent0). RocketMQLog:WARN Please initialize the logger system properly. #Cluster Name #Broker Name #BID #Addr #Version #InTPS(LOAD) #OutTPS(LOAD) #PCWait(ms) #Hour #SPACE DefaultCluster 5b557ea1e6be 0 172.17.0.8:10911 V4_7_1 0.00(0,0ms) 0.00(0,0ms) 0 447225.46 -1.0000 ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:2:2","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"升级 cd image-build ./update.sh ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:2:3","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"安装GUI # docker pull apacherocketmq/rocketmq-console:2.0.0 # docker run -e \"JAVA_OPTS=-Drocketmq.namesrv.addr=192.168.150.70:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false\" -p 6881:8080 -t apacherocketmq/rocketmq-console:2.0.0 ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:3:0","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"golang client使用问题 由于使用的docker服务启动，broker的地址是内网地址，需要将地址修改为外网地址 # docker ps |grep mq 8abb966542a3 apacherocketmq/rocketmq-console:2.0.0 \"sh -c 'java $JAVA...\" 17 hours ago Up 17 hours 0.0.0.0:6881-\u003e8080/tcp dazzling_tesla 5b557ea1e6be apacherocketmq/rocketmq:4.7.1-alpine \"sh mqbroker\" 18 hours ago Up 18 hours 0.0.0.0:10909-\u003e10909/tcp, 9876/tcp, 0.0.0.0:10911-10912-\u003e10911-10912/tcp rmqbroker 8b1318aee5d6 apacherocketmq/rocketmq:4.7.1-alpine \"sh mqnamesrv\" 18 hours ago Up 18 hours 10909/tcp, 0.0.0.0:9876-\u003e9876/tcp, 10911-10912/tcp rmqnamesrv # docker exec -it 5b557ea1e6be bash // 进入到容器内部修改配置 # vi ../confbroker.conf 在文件中添加 brokerIP1=xxx.xxx.xxx.xxx 然后重启broker, docker restart 5b557ea1e6be ==这里需要去修改启动脚本 ./play-docker.sh 里的start_namesrv_broker() 函数中的docker启动命令，在mybroker后面添加-c ../conf/broker.conf== # Start Broker docker run -d -v `pwd`/data/broker/logs:/home/rocketmq/logs -v `pwd`/data/broker/store:/home/rocketmq/store --name rmqbroker --link rmqnamesrv:namesrv -e \"NAMESRV_ADDR=namesrv:9876\" -p 10909:10909 -p 10911:10911 -p 10912:10912 apacherocketmq/rocketmq:4.7.1${TAG_SUFFIX} sh mqbroker -c ../conf/broker.conf 这样查看cluster会发现Address变成外网地址。 ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:3:1","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"client-go Topic package main import ( \"context\" \"fmt\" \"github.com/apache/rocketmq-client-go/v2/admin\" \"github.com/apache/rocketmq-client-go/v2/primitive\" ) func main() { topic := \"Develop\" nameSrvAddr := []string{\"192.168.150.70:9876\"} brokerAddr := \"192.168.150.70:10911\" testAdmin, err := admin.NewAdmin(admin.WithResolver(primitive.NewPassthroughResolver(nameSrvAddr))) if err != nil { panic(err) } // 创建topic err = testAdmin.CreateTopic( context.Background(), admin.WithTopicCreate(topic), admin.WithBrokerAddrCreate(brokerAddr)) if err != nil { fmt.Println(\"Create topic error:\", err) } // 删除topic err = testAdmin.DeleteTopic( context.Background(), admin.WithTopicDelete(topic), //admin.WithBrokerAddrDelete(brokerAddr), //admin.WithNameSrvAddr(nameSrvAddr), ) err = testAdmin.Close() if err != nil { fmt.Println(\"Shutdown admin error:\", err) } } ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:3:2","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"client-go 生产者 package main import ( \"context\" \"fmt\" \"github.com/apache/rocketmq-client-go/v2\" \"github.com/apache/rocketmq-client-go/v2/primitive\" \"github.com/apache/rocketmq-client-go/v2/producer\" \"strconv\" ) func main() { addr,err := primitive.NewNamesrvAddr(\"192.168.150.70:9876\") if err != nil { panic(err) } topic := \"Develop\" p,err := rocketmq.NewProducer( producer.WithGroupName(\"my_service\"), producer.WithNameServer(addr), producer.WithCreateTopicKey(topic), producer.WithRetry(1)) if err != nil { panic(err) } err = p.Start() if err != nil { panic(err) } // 发送异步消息 res,err := p.SendSync(context.Background(),primitive.NewMessage(topic,[]byte(\"send sync message\"))) if err != nil { fmt.Printf(\"send sync message error:%s\\n\",err) } else { fmt.Printf(\"send sync message success. result=%s\\n\",res.String()) } // 发送消息后回调 err = p.SendAsync(context.Background(), func(ctx context.Context, result *primitive.SendResult, err error) { if err != nil { fmt.Printf(\"receive message error:%v\\n\",err) } else { fmt.Printf(\"send message success. result=%s\\n\",result.String()) } },primitive.NewMessage(topic,[]byte(\"send async message\"))) if err != nil { fmt.Printf(\"send async message error:%s\\n\",err) } // 批量发送消息 var msgs []*primitive.Message for i := 0; i \u003c 5; i++ { msgs = append(msgs, primitive.NewMessage(topic,[]byte(\"batch send message. num:\"+strconv.Itoa(i)))) } res,err = p.SendSync(context.Background(),msgs...) if err != nil { fmt.Printf(\"batch send sync message error:%s\\n\",err) } else { fmt.Printf(\"batch send sync message success. result=%s\\n\",res.String()) } // 发送延迟消息 msg := primitive.NewMessage(topic,[]byte(\"delay send message\")) msg.WithDelayTimeLevel(3) res,err = p.SendSync(context.Background(),msg) if err != nil { fmt.Printf(\"delay send sync message error:%s\\n\",err) } else { fmt.Printf(\"delay send sync message success. result=%s\\n\",res.String()) } // 发送带有tag的消息 msg1 := primitive.NewMessage(topic,[]byte(\"send tag message\")) msg1.WithTag(\"tagA\") res,err = p.SendSync(context.Background(),msg1) if err != nil { fmt.Printf(\"send tag sync message error:%s\\n\",err) } else { fmt.Printf(\"send tag sync message success. result=%s\\n\",res.String()) } err = p.Shutdown() if err != nil { panic(err) } } ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:3:3","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小教程"],"content":"client-go 消费者 // 在v2.1.0-rc5.0不支持，会在下一个版本中支持 func PullConsumer() { topic := \"Develop\" // 消费者主动拉取消息 // not c1,err := rocketmq.NewPullConsumer( consumer.WithGroupName(\"my_service\"), consumer.WithNsResolver(primitive.NewPassthroughResolver([]string{\"192.168.150.70:9876\"}))) if err != nil { panic(err) } err = c1.Start() if err != nil { fmt.Println(err) os.Exit(-1) } queue := primitive.MessageQueue{ Topic: topic, BrokerName: \"broker-a\", // 使用broker的名称 QueueId: 0, } err = c1.Shutdown() if err != nil { fmt.Println(\"Shutdown Pull Consumer error: \",err) } offset := int64(0) for { resp,err := c1.PullFrom(context.Background(),queue,offset,10) if err != nil { if err == rocketmq.ErrRequestTimeout { fmt.Printf(\"timeout\\n\") time.Sleep(time.Second) continue } fmt.Printf(\"unexpected error: %v\\n\",err) return } if resp.Status == primitive.PullFound { fmt.Printf(\"pull message success. nextOffset: %d\\n\",resp.NextBeginOffset) for _, ext := range resp.GetMessageExts() { fmt.Printf(\"pull msg: %s\\n\",ext) } } offset = resp.NextBeginOffset } } func PushConsumer() { topic := \"Develop\" // 消息主动推送给消费者 c2,err := rocketmq.NewPushConsumer( consumer.WithGroupName(\"my_service\"), consumer.WithNsResolver(primitive.NewPassthroughResolver([]string{\"192.168.150.70:9876\"})), consumer.WithConsumeFromWhere(consumer.ConsumeFromFirstOffset), // 选择消费时间(首次/当前/根据时间) consumer.WithConsumerModel(consumer.BroadCasting)) // 消费模式(集群消费:消费完其他人不能再读取/广播消费：所有人都能读) if err != nil { panic(err) } err = c2.Subscribe( topic,consumer.MessageSelector{ Type: consumer.TAG, Expression: \"*\", // 可以 TagA || TagB }, func(ctx context.Context, msgs ...*primitive.MessageExt) (consumer.ConsumeResult, error) { orderlyCtx,_ := primitive.GetOrderlyCtx(ctx) fmt.Printf(\"orderly context: %v\\n\",orderlyCtx) for i := range msgs { fmt.Printf(\"Subscribe callback: %v\\n\",msgs[i]) } return consumer.ConsumeSuccess,nil }) if err != nil { fmt.Printf(\"Subscribe error:%s\\n\",err) } err = c2.Start() if err != nil { fmt.Println(err) os.Exit(-1) } time.Sleep(time.Minute) err = c2.Shutdown() if err != nil { fmt.Println(\"Shutdown Consumer error: \",err) } } ","date":"2021-01-07","objectID":"/2021/01/rocketmq/:3:4","tags":["docker","rocketmq"],"title":"docker安装部署Rocketmq","uri":"/2021/01/rocketmq/"},{"categories":["月霜天的小笔记"],"content":"一 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:1:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"有20瓶药丸，其中19瓶装有1克/粒的药丸，余下一瓶装有1.1克/粒的药丸。给你一台称重精准的天平，怎么找出较重的那瓶药丸？天平只能使用一次。 初次看到这题，如果不限制次数，那么可以二分法，天平两边10个比较，直到找到较重的为止。 但是，现在限制只能使用一次天平。 怎么办呢？ 假设只有两瓶药丸，一瓶较重，从两瓶中各取一粒，称重为2.1克，我们无法得知是从哪一瓶多出的0.1克。 我们需要将因子不平衡，如果从1号药瓶取出1粒，从2号药瓶取出2粒，如果算出重量是3.1克，那么1号瓶较重，如果算出重量为3.2克，那么2号瓶较重。 我们将这个结论推广一下，从1号药瓶取出1粒，从2号药瓶取出2粒，以此类推，如果每粒药丸均重1克，那么得到总重量为（1+2+3+…+20=21*20/2=210）, 因此，如果称重为210.9克，那么较重的那瓶来自于9号瓶。 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:2:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"二 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:3:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"有个8*8的棋盘，其中对角的角落有两个方块被切掉了。给定31块多米诺骨牌，一块骨牌恰好可以覆盖两个格子。用31块骨牌能否盖住整个棋盘呢？ 乍一看，棋盘88=64，多米诺312=62，刚好能盖住。。其实是错觉 假设棋盘有32个黑格和32个白格交叉排列，切掉对角的方格是同种颜色的，此时只剩30个黑格和32个白格（或32个黑格和30个白格）， 而一块多米诺骨牌必须要覆盖一个白格和一个黑格，31块多米诺骨牌要覆盖31个白格和31个黑格。 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:4:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"三 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:5:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"有两个水壶，容量为5升和3升，若水量不限量，怎么用这两个水壶得到4升的水？注：水壶不规则形状，无法精确装满半壶水。 5升 3升 注释 5 0 装满5升的壶 2 3 用5升的壶装满3升的壶 0 2 将5升壶中的2升水倒入3升壶中 5 2 装满5升壶 4 3 用5升壶装满3升壶 5升 3升 注释 0 3 装满3升壶 3 3 将3升壶倒入5升壶中，同时装满3升壶 5 1 将3升壶倒入5升壶中 1 0 将3升壶中的1升水倒入5升壶中 1 3 装满3升壶 4 0 将3升壶倒入5升壶中 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:6:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"四 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:7:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"在岛上住着一群人，有一天来了一个游客，定了奇怪的规矩：所有的蓝眼睛必须尽快离开岛。 每个人都能看到别人眼睛的颜色，但不知道自己眼睛的颜色（别人不能告知）， 此外他们不知道有多少个蓝眼睛，只知道至少有一个蓝眼睛，每个人都是聪明的，那么蓝眼睛要花几天才能离开这个岛呢？ 假设有c个蓝眼睛，且c\u003e0 1、c=1：只有一个蓝眼睛 蓝眼睛的人观察之后发现没有蓝眼睛，那么一定能推导出自己是蓝眼睛，因此他会当天离开 2、c=2：两个蓝眼睛 两个蓝眼睛看到对方，不确定c=1或2，但是由于上种情况，他们知道c=1时，蓝眼睛当天会离开，如果第二天发现对方没有离开，那么一定能推导出自己也是蓝眼睛，于是，两个蓝眼睛会在第二天离开 3、c\u003e2 如果c=3，这三个人会意识到有2-3个人是蓝眼睛，如果2人蓝眼睛，会在第二天全部离开，因此，如果第二天另外两个人都在岛上，每个人都能推导出自己是蓝眼睛，于是会在第三天离开。 当逐步提高c时，发现这个逻辑是适用的。 如果有c人蓝眼睛，则所有的蓝眼睛要用c天离开这个岛 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:8:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"五 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:9:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"有个建筑高100米。若从第N层或更高的楼层扔鸡蛋，鸡蛋会破，若从N层以下的楼层扔下来不会破。 恰好你有两个鸡蛋，求出N，并要求最差情况下扔鸡蛋次数最少。 我们发现，无论我们怎么扔鸡蛋，第二个鸡蛋都必须在破掉的那一层和没有破掉的那一层逐层累加。 例如，鸡蛋1在5层没破，10层没破，15层破了，那么鸡蛋2必须从11,12,13,14尝试 具体做法 假设步长为10 鸡蛋1从10层扔下，如果破掉了，最多需要扔10次 鸡蛋1从100层扔下才破掉，最多需要扔19次。 那么我们的目的就是求这个步长，使得最好情况和最差情况类似。 也就是说，鸡蛋1每扔一次，就要减少鸡蛋2扔的次数。 例如，鸡蛋1从20层扔，然后从30层扔，鸡蛋2可能要扔9次， 若鸡蛋1再扔一次，我们要让鸡蛋2扔的次数减少，也就是说鸡蛋1要从39层开始扔。 因此 x + （x-1） + （x-2） +… + 1 = x(x+1)/2=100 -\u003e x=14 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:10:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"六 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:11:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小笔记"],"content":"走廊上有100个关上的储物柜。 第一轮，将100柜子全部打开； 第二轮，每数两个柜子关上一个； 第三轮，每隔两个柜子切换柜子状态（就是将关上的柜子打开，打开的柜子关上）； 照此规律，重复100次，当结束时，有多少个柜子是打开的？ 柜子n会在每隔因子对应的那一轮切换状态，例如15的因子有1,3,5,15,因子个数为偶数，所以柜子15是关着的 那么什么样的整数因子的个数是奇数？ 我们可以将因子配对，15的因子有(1,15),(3,5)。 那么36的因子有(1,36),(2,18),(3,12),(4,9),(6,6),注意(6,6)其实是一个因子,36有奇数个因子 结论:如果是完全平方数会有奇数个因子，100以内的完全平方数有 1,4,9,16,25,36,49,64,81,100.共10个 ","date":"2020-12-15","objectID":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/:12:0","tags":["智力"],"title":"6道有趣的智力题","uri":"/2020/12/%E6%99%BA%E5%8A%9B%E9%A2%98/"},{"categories":["月霜天的小教程"],"content":"安装材料 raspberry pi 4b 4G *1 128G 三星TF卡 *1 micro接口转HDMI转接线 *1 电源适配器 5V 3A *1 ","date":"2020-11-27","objectID":"/2020/11/install_os/:1:0","tags":["raspberry"],"title":"树莓派安装ubuntu系统","uri":"/2020/11/install_os/"},{"categories":["月霜天的小教程"],"content":"安装系统 ","date":"2020-11-27","objectID":"/2020/11/install_os/:2:0","tags":["raspberry"],"title":"树莓派安装ubuntu系统","uri":"/2020/11/install_os/"},{"categories":["月霜天的小教程"],"content":"1、下载 在windows上下载 raspberry pi imager 用来安装系统 由于我们已经在 已经下载好了 OS，所以我们直接烧录系统。 ","date":"2020-11-27","objectID":"/2020/11/install_os/:2:1","tags":["raspberry"],"title":"树莓派安装ubuntu系统","uri":"/2020/11/install_os/"},{"categories":["月霜天的小教程"],"content":"2、进入系统 输入账号密码，默认ubuntu：ubuntu，需要重新设置密码。 此时需要连接网线、显示器、键盘。 更新软件源，由于树莓派，使用ubuntu-ports，然后更新 # cp /etc/apt/sources.list /etc/apt/sources.list.bak # 然后替换软件源 # apt update 安装软件 # apt install net-tools wireless-tools wpasupplicant udhcpc 查看网卡 # iwconfig lo no wireless extensions. eth0 no wireless extensions. wlan0 no wireless extensions. 启动网卡 # ifconfig wlan0 up # ifconfig 此时就能看到网卡信息了。 配置wifi信息 # vi wpa_supplicant.conf country=GB ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev update_config=1 # wpa_passphrase wifi名称 wifi密码 \u003e\u003e wpa_supplicant.conf 此时再启动wpa_cli后台wpa_supplicant # wpa_supplicant -iwlan0 -c wpa_supplicant.conf -B 查看wifi连接状态 # wpa_cli -iwlan0 status 扫描可用wifi # wpa_cli -i wlan0 scan 查看扫描结果 # wpa_cli -i wlan0 scan_results 新增wifi编码 # wpa_cli -iwlan0 add_network 配置wifi名称 # wpa_cli -iwlan0 set network 编码 ssid \"wifi名称\" 配置wifi密码 # wpa_cli -iwlan0 set network 编码 psk \"wifi密码\" 查看wifi列表 # wpa_cli -iwlan0 list_network 选择wifi # wpa_cli -iwlan0 select_network 使用wifi # wpa_cli -iwlan0 enable_network 断开wifi # wpa_cli -iwlan0 disconnect 重连wifi # wpa_cli -iwlan0 reconnect 停止使用wifi # wpa_cli -iwlan0 disable_network 编码 保存wifi # wpa_cli -iwlan0 save_config 此时wifi已经连接成功，但是还没有分配ip地址 udhcpc -iwlan0 -q 此时成功连接wifi。 ","date":"2020-11-27","objectID":"/2020/11/install_os/:2:2","tags":["raspberry"],"title":"树莓派安装ubuntu系统","uri":"/2020/11/install_os/"},{"categories":["月霜天的小教程"],"content":"添加DNS # vi /etc/resolv.conf nameserver 114.114.114.114 ","date":"2020-11-27","objectID":"/2020/11/install_os/:2:3","tags":["raspberry"],"title":"树莓派安装ubuntu系统","uri":"/2020/11/install_os/"},{"categories":["月霜天的小教程"],"content":"下载安装docker docker官网 1、卸载旧版本 # apt-get remove docker docker-engine docker.io containerd runc 2、添加repository # apt-get update # apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common # curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - # apt-key fingerprint 0EBFCD88 # add-apt-repository \\ \"deb [arch=armhf] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" 3、安装docker # apt-get update # apt-get install docker-ce docker-ce-cli containerd.io 第三步一直提示 Unable to locate package docker-ce-cli 那就只能使用脚本的方式安装 # curl -sSL https://get.docker.com | sh # docker version Client: Version: 18.01.0-ce API version: 1.35 Go version: go1.9.2 Git commit: 03596f5 Built: Wed Jan 10 20:05:35 2018 OS/Arch: linux/arm64 Experimental: false Orchestrator: swarm Server: Engine: Version: 18.01.0-ce API version: 1.35 (minimum version 1.12) Go version: go1.9.2 Git commit: 03596f5 Built: Wed Jan 10 20:03:37 2018 OS/Arch: linux/arm64 Experimental: false 执行hello-world # docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world 256ab8fe8778: Already exists Digest: sha256:e7c70bb24b462baa86c102610182e3efcb12a04854e8c582838d92970a09f323 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (arm64v8) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 添加镜像源 # cat /etc/docker/daemon.json { \"registry-mirrors\": [\"https://c2Zra3lhZDYK.mirror.aliyuncs.com\"] } # systemctl daemon-reload # systemctl restart docker ","date":"2020-11-27","objectID":"/2020/11/install_os/:3:0","tags":["raspberry"],"title":"树莓派安装ubuntu系统","uri":"/2020/11/install_os/"},{"categories":["月霜天的小笔记"],"content":"简介 先来看一下 json.Unmarshal 的注释 大意是 json 解析的时候会调用 Unmarshaler 的接口。那么我们就可以自定义解析数据了。 先看一个例子 package main import ( \"encoding/json\" \"fmt\" \"time\" ) const textJson = `{\"name\":\"xiaoming\",\"duration\":\"5s\"}` func main() { var o Object json.Unmarshal([]byte(textJson),\u0026o) fmt.Printf(\"%+v\\n\",o) } type Object struct { Name string Time time.Duration } func (o *Object) UnmarshalJSON(data []byte) error { tmp := struct { Name string `json:\"name\"` Duration string `json:\"duration\"` }{} err := json.Unmarshal(data,\u0026tmp) if err != nil { return err } dur,err := time.ParseDuration(tmp.Duration) if err != nil { return err } o.Name = tmp.Name o.Time = dur return nil } 你可能觉得打印的数据和textJson没什么区别。 但是实际上打印的o.Time是个时间类型的数据了，从string转到time.Duration类型，这个可以很轻松的转换。 但是这里还会有一个坑，来看另一个例子 package main import ( \"encoding/json\" \"fmt\" \"time\" ) var testJSON = `{\"num\":5,\"duration\":\"5s\"}` type Nested struct { Dur time.Duration `json:\"duration\"` } func (n *Nested) UnmarshalJSON(data []byte) error { *n = Nested{} tmp := struct { Dur string `json:\"duration\"` }{} fmt.Printf(\"parsing nested json %s \\n\", string(data)) if err := json.Unmarshal(data, \u0026tmp); err != nil { fmt.Printf(\"failed to parse nested: %v\", err) return err } tmpDur, err := time.ParseDuration(tmp.Dur) if err != nil { fmt.Printf(\"failed to parse duration: %v\", err) return err } (*n).Dur = tmpDur return nil } type Object struct { Nested Num int `json:\"num\"` } //uncommenting this method still doesnt help. //tmp is parsed with the completed json at Nested //which doesnt take care of Num field, so Num is zero value. func (o *Object) UnmarshalJSON(data []byte) error { *o = Object{} tmp := struct { Nested Num int `json:\"num\"` }{} fmt.Printf(\"parsing object json %s \\n\", string(data)) if err := json.Unmarshal(data, \u0026tmp); err != nil { fmt.Printf(\"failed to parse object: %v\", err) return err } fmt.Printf(\"tmp object: %+v \\n\", tmp) (*o).Num = tmp.Num (*o).Nested = tmp.Nested return nil } func main() { obj := Object{} if err := json.Unmarshal([]byte(testJSON), \u0026obj); err != nil { fmt.Printf(\"failed to parse result: %v\", err) return } fmt.Printf(\"result: %+v \\n\", obj) } 最终输出的结果是 parsing object json {\"num\":5,\"duration\":\"5s\"} parsing nested json {\"num\":5,\"duration\":\"5s\"} tmp object: {Nested:{Dur:5s} Num:0} result: {Nested:{Dur:5s} Num:0} 这里你可能要疑问了，为什么数据丢失了，num从5变成了0？ 那么为什么会出现这种情况呢？ 用一个简单的例子说明一下 package main import \"fmt\" type Funer interface{ Name()string PrintName() } type A struct { } func (a *A) Name() string { return \"a\" } func (a *A) PrintName() { fmt.Println(a.Name()) } type B struct { A } func (b *B) Name() string { return \"b\" } func getBer() Funer { return \u0026B{} } func main() { b := getBer() b.PrintName() } 这是一个类似继承的实现，它最终会打印 a 。 这是因为golang没有继承方法，它只会调用自己的指针的数据，如果是C/C++，它会实现多态，打印 b 。 这样就会导致 json 数据的接口调用是从外部到内部的接口调用，谁的指针方法就实现谁的指针方法。 那么上面那种情况证明解决呢？ package main import ( \"encoding/json\" \"fmt\" \"time\" ) var testJSON = `{\"num\":5,\"duration\":\"5s\"}` type Nested struct { Dur time.Duration `json:\"duration\"` } func (obj *Object) UnmarshalJSON(data []byte) error { tmp := struct { Dur string `json:\"duration\"` Num int `json:\"num\"` }{} if err := json.Unmarshal(data, \u0026tmp); err != nil { return err } dur, err := time.ParseDuration(tmp.Dur) if err != nil { return err } obj.Dur = dur obj.Num = tmp.Num return nil } type Object struct { Nested Num int `json:\"num\"` } var _ json.Unmarshaler = (*Object)(nil) func main() { obj := Object{} _ = json.Unmarshal([]byte(testJSON), \u0026obj) fmt.Printf(\"result: %+v \\n\", obj) } 在内部不使用继承，通过的结构来解析数据就可以了。 ","date":"2020-11-25","objectID":"/2020/11/json_unmarshal/:1:0","tags":["json","golang"],"title":"如何自定义让json解析出自定义值","uri":"/2020/11/json_unmarshal/"},{"categories":["月霜天的小教程"],"content":"前言 在开始监控你的服务之前，你需要通过添加prometheus客户端来添加监控。 可以找 第三方exporter 监控你的服务，也可以自己编写exporter。 目前已经有很多不同的语言编写的客户端库，包括官方提供的Go，Java，Python，Ruby。 已有客户端库 在了解编写exporter之前，可以先5分钟学会搭建prometheus ","date":"2020-11-20","objectID":"/2020/11/exporter/:1:0","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"简单的exporter服务 先写一个简单的http服务，在9095端口启动了一个能够为prometheus提供监控指标的HTTP服务。你可以在 http://localhost:9095/metrics 看到这些指标。 package main import ( \"github.com/prometheus/client_golang/prometheus/promhttp\" \"net/http\" ) func main() { http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) }) http.Handle(\"/metrics\",promhttp.Handler()) http.ListenAndServe(\":9095\",nil) } 虽然偶尔会手动访问/metrics页面查看指标数据，但是将指标数据导入prometheus才方便。 global:scrape_interval:15s# 默认抓取间隔，15s向目标抓取一次数据external_labels:monitor:'prometheus-monitor'# 抓取对象scrape_configs:- job_name:'exporter'# 名称，会在每一条metrics添加标签{job_name:\"prometheus\"}scrape_interval:5s# 抓取时间static_configs:# 抓取对象- targets:['localhost:9095'] 那么在 http://localhost:9090/ 浏览器输入 PromQL 表达式 go_info,就会看到如图的结果 ","date":"2020-11-20","objectID":"/2020/11/exporter/:2:0","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"监控指标 ","date":"2020-11-20","objectID":"/2020/11/exporter/:3:0","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"Counter(计数器类型) Counter记录的是事件的数量或大小，只增不减，除非发生重置。 Counter主要有两个方法 # 将counter加1 Inc() # 增加指定值，如果\u003c0会panic Add(float64) package main import ( \"github.com/prometheus/client_golang/prometheus\" \"github.com/prometheus/client_golang/prometheus/promauto\" \"github.com/prometheus/client_golang/prometheus/promhttp\" \"net/http\" \"time\" ) var ( failures = prometheus.NewCounterVec(prometheus.CounterOpts{ Name: \"hq_failture_total\", Help: \"failure counts\", },[]string{\"device\"}) // 可以使用promauto自动注册 success = promauto.NewCounterVec(prometheus.CounterOpts{ Name: \"hq_failture_total\", Help: \"failure counts\", },[]string{\"device\"}) ) func init() { prometheus.MustRegister(failures) } func main() { go func() { failures.WithLabelValues(\"/dev/sda\").Add(3.2) time.Sleep(time.Second) failures.WithLabelValues(\"/dev/sda\").Inc() time.Sleep(time.Second) failures.WithLabelValues(\"/dev/sdb\").Inc() time.Sleep(time.Second) failures.WithLabelValues(\"/dev/sdb\").Add(1.5) }() http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) }) http.Handle(\"/metrics\",promhttp.Handler()) http.ListenAndServe(\":9095\",nil) } ","date":"2020-11-20","objectID":"/2020/11/exporter/:3:1","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"Gauge(仪表盘类型) Gauge是可增可减的指标类，更关注于数值本身。 Gauge主要有几种方法 # 设置任意值 Set(float64) # 加1 Inc() # 减1 Dec() # 加任意数，如果是负数，那么就会减去 Add(float64) # 和当前值的差值 Sub(float64) # 设置值为当前时间戳 SetToCurrentTime() package main import ( \"github.com/prometheus/client_golang/prometheus\" \"github.com/prometheus/client_golang/prometheus/promhttp\" \"net/http\" \"time\" ) var ( failures = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Name: \"hq_failture_total\", Help: \"failure counts\", },[]string{\"device\"}) ) func init() { prometheus.MustRegister(failures) } func main() { go func() { failures.WithLabelValues(\"/dev/sda\").Add(5) failures.WithLabelValues(\"/dev/sdb\").Set(10) time.Sleep(time.Second * 5) failures.WithLabelValues(\"/dev/sda\").Inc() failures.WithLabelValues(\"/dev/sdb\").Add(3) time.Sleep(time.Second * 5) failures.WithLabelValues(\"/dev/sda\").Dec() failures.WithLabelValues(\"/dev/sdb\").SetToCurrentTime() time.Sleep(time.Second* 5) failures.WithLabelValues(\"/dev/sda\").Sub(1) failures.WithLabelValues(\"/dev/sdb\").Dec() time.Sleep(time.Second* 5) time.Sleep(time.Second) }() http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) }) http.Handle(\"/metrics\",promhttp.Handler()) http.ListenAndServe(\":9095\",nil) } ","date":"2020-11-20","objectID":"/2020/11/exporter/:3:2","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"Summary(摘要类型) 表示一段时间数据采样结果，由_count,_sum构成 Summary只有一种方法 Observe(float64) 你可以访问 /metrics 可以看到hq_failture_total_sum和hq_failture_total_count hq_failture_total_sum代表观察值的总和 hq_failture_total_count代表观察到的条数 package main import ( \"github.com/prometheus/client_golang/prometheus\" \"github.com/prometheus/client_golang/prometheus/promhttp\" \"net/http\" \"time\" ) var ( failures = prometheus.NewSummaryVec(prometheus.SummaryOpts{ Name: \"hq_failture_total\", Help: \"failure counts\", },[]string{\"device\"}) ) func init() { prometheus.MustRegister(failures) } func main() { var count float64 go func() { t := time.NewTicker(time.Second) for { count++ failures.WithLabelValues(\"/dev/sdc\").Observe(count) \u003c-t.C } }() http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) }) http.Handle(\"/metrics\",promhttp.Handler()) http.ListenAndServe(\":9095\",nil) } ","date":"2020-11-20","objectID":"/2020/11/exporter/:3:3","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"Histogram(直方图类型) summary可以提供平均延迟数据，但是如果你想要分位数呢？ 那么就可以使用Histogram分位数. Histogram只有一种方法 Observe(float64) 你可以访问 /metrics 可以看到hq_failture_total_sum和hq_failture_total_count、hq_failture_total_bucket package main import ( \"github.com/prometheus/client_golang/prometheus\" \"github.com/prometheus/client_golang/prometheus/promhttp\" \"math/rand\" \"net/http\" \"time\" ) var ( failures = prometheus.NewHistogramVec(prometheus.HistogramOpts{ Name: \"hq_failture_total\", Help: \"failure counts\", },[]string{\"device\"}) ) func init() { prometheus.MustRegister(failures) } func main() { go func() { t := time.NewTicker(time.Second) for { failures.WithLabelValues(\"/dev/sdc\").Observe(rand.Float64()) \u003c-t.C } }() http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hello world\")) }) http.Handle(\"/metrics\",promhttp.Handler()) http.ListenAndServe(\":9095\",nil) } 那么什么是bucket(桶)？桶记录小于监控指标的数量 默认的buckets范围为{0.005，0.01，0.025，0.05，0.075，0.1，0.25，0.5，0.75，1，2.5，5，7.5，10} PromQL函数histogram_quantile可以用来统计桶中的分位数。例如，0.95分位数的表达式为 histogram_quantile(0.95,rate(hq_failture_total_bucket[1m])) ","date":"2020-11-20","objectID":"/2020/11/exporter/:3:4","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"如何给指标命名？ Prometheus 指标需要以字母开头，后面可以跟着任意数量的字母，数字，下划线。 命名的整体结构是 library_name_unit_suffix 虽然 [a-zA-Z_:][a-zA-Z0-9_:]* 是Prometheus中有效的命名规则的正则表达式，但你要避免是有某些有效值。 你不应该在测控指标使用冒号，因为它是为记录规则中使用而保留的。以下划线开头的名称是为prometheus内部使用而保留的。 _total,_count,_sum和_bucket这些后缀是留给counter，summary和histogram指标使用的。 除了在counter类型的指标上始终具有_total后缀外，不要将其他后缀放在指标名称的末尾。 ","date":"2020-11-20","objectID":"/2020/11/exporter/:4:0","tags":["prometheus"],"title":"Golang exporter的使用方法","uri":"/2020/11/exporter/"},{"categories":["月霜天的小教程"],"content":"简介 prometheus是一个开源的系统监控和警报工具包，最初由SoundCloud开发。自2012年始，许多公司和组织已经采用了prometheus，该项目拥有活跃的开发人员和用户社区。 它现在是一个独立的开源项目，独立于任何公司进行维护。着重于此，prometheus在2016年加入CNCF，是继kubernetes之后第二个托管的项目。 官网地址： Prometheus github地址： github 架构图 ","date":"2020-11-19","objectID":"/2020/11/prometheus/:1:0","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"下载与安装 安装方式有很多种，如果你是windows用户，那么只需要在本地起个二进制服务就可以。如果你是linux用户，可以通过docker等更加灵活方式部署。 ","date":"2020-11-19","objectID":"/2020/11/prometheus/:2:0","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"二进制 二进制下载地址 tar xvfz prometheus-*.tar.gz cd prometheus-* ./prometheus --config.file=prometheus.yml 当然你可以下载最新的源码进行编译获取最新的二进制文件。 mkdir -p $GOPATH/src/github.com/prometheus cd $GOPATH/src/github.com/prometheus git clone https://github.com/prometheus/prometheus.git cd prometheus make build ./prometheus -config.file=your_config.yml ","date":"2020-11-19","objectID":"/2020/11/prometheus/:2:1","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"docker # 使用 /opt/prometheus/prometheus.yml 的配置 docker run --name prometheus -d -p 127.0.0.1:9090:9090 -v /opt/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus ","date":"2020-11-19","objectID":"/2020/11/prometheus/:2:2","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"helm helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo add stable https://charts.helm.sh/stable helm repo update # Helm 3 $ helm install [RELEASE_NAME] prometheus-community/prometheus # Helm 2 $ helm install --name [RELEASE_NAME] prometheus-community/prometheus ","date":"2020-11-19","objectID":"/2020/11/prometheus/:2:3","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"配置文件 prometheus已经能够起来了，我们也需要对服务做一些个性化的配置，让prometheus能够获取到数据。 global:scrape_interval:15s# 默认抓取间隔，15s向目标抓取一次数据external_labels:monitor:'prometheus-monitor'# 抓取对象scrape_configs:- job_name:'prometheus'# 名称，会在每一条metrics添加标签{job_name:\"prometheus\"}scrape_interval:5s# 抓取时间static_configs:# 抓取对象- targets:['localhost:9090'] 重启完毕后，我们可以看到这两个界面。 ","date":"2020-11-19","objectID":"/2020/11/prometheus/:2:4","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"安装exporter 如何获取数据源？从下面的链接你可以挑选一些官方或非官方的exporter来监控你的服务。 exporters and integrations 例如：Node Exporter 暴露了如linux等UNIX系统的内核和机器级别的指标(windows用户应用wmi_exporter)。它提供了很多标准的指标如CPU、内存、磁盘空间、硬盘I/O和网络带宽。此外，它还提供了从负载率平均值到主板温度等很多内核暴露的问题。 下载运行之后，我们需要更新prometheus.yml，然后 重启 prometheus加载新的配置 global:scrape_interval:15s# 默认抓取间隔，15s向目标抓取一次数据external_labels:monitor:'codelab-monitor'# 抓取对象scrape_configs:- job_name:'prometheus'# 名称，会在每一条metrics添加标签{job_name:\"prometheus\"}scrape_interval:5s# 抓取时间static_configs:# 抓取对象- targets:['localhost:9090']- job_name:'node'scrape_interval:5sstatic_configs:- targets:['localhost:9100'] ","date":"2020-11-19","objectID":"/2020/11/prometheus/:3:0","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"告警通知 如果你需要设定特定的规则，例如cpu/内存超过了设定值，需要将告警数据发送到你的邮件、微信、钉钉等，那么你就需要Alertmanager。 告警分为两个部分。首先需要在prometheus中添加告警规则，定义告警产生的逻辑，其次Altermanager将触发的警报转化为通知，例如邮件，呼叫和聊天消息。 global:scrape_interval:15s# 默认抓取间隔，15s向目标抓取一次数据evaluation_interval:10sexternal_labels:monitor:'codelab-monitor'# 规则文件rule_files:- rules.ymlalerting:alertmanagers:- static_configs:- targets:- localhost:9093# 抓取对象scrape_configs:- job_name:'prometheus'# 名称，会在每一条metrics添加标签{job_name:\"prometheus\"}scrape_interval:5s# 抓取时间static_configs:# 抓取对象- targets:['localhost:9090']- job_name:'node'scrape_interval:5sstatic_configs:- targets:['localhost:9100'] # 规则文件rules.ymlgroups:- name:examplerules:- alert:InstanceDownexpr:up == 0for:1m 按照 evaluation_interval 的配置，InstanceDown告警每10s将被执行1次。如果持续1m收到数据，那么这个告警就会被触发。在达到设定的时间长度前，这个告警处于 pending 状态，在 Alerts 页面可以单击警告查看包括它的标签在内的更多详细信息。 注：通常建议至少5min以减少噪声从而减轻固有监控的各种情况。 既然有一个被触发的告警，需要 Alertmanager 针对它做一些事。 ","date":"2020-11-19","objectID":"/2020/11/prometheus/:4:0","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"Alertmanager 如何管理告警通知？ 比如我只想工作时间收到告警，那么可以设置告警事件为09:00-21:00。 比如我某个服务不想收到通知，那么可以暂时关闭通知。 下载地址 现在需要为 Alertmanager 创建一个配置文件。这里有很多中方式让Alertmanager 通知到你。这里使用SMTP。 global:smtp_smarthost:'localhost:25'smtp_from:'youraddress@example.org'route:receiver:example-emailreceivers:- name:'example-email'email_configs:- to:'youraddress@example.org' 启动Alertmanager，现在可以在浏览器输入 http://localhost:9093 来访问 Alertmanager，在这个页面你将看到触发的告警，如果所有的配置正确并正常启动，一两分钟后就会收到邮件告警通知。 ","date":"2020-11-19","objectID":"/2020/11/prometheus/:5:0","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":["月霜天的小教程"],"content":"总结 这个prometheus由exporter、prometheus server、Alertmanager构成。 exporter收集数据，prometheus server 拉取exporter数据，然后根据告警规则，将告警推送到Alertmanager处理。 中间还衍生了许多其他组件，例如pushgateway(客户端将数据push到pushgateway，由prometheus定期拉取)，grafana图标页面等。 ","date":"2020-11-19","objectID":"/2020/11/prometheus/:6:0","tags":["prometheus"],"title":"5分钟学会搭建Prometheus","uri":"/2020/11/prometheus/"},{"categories":null,"content":" 希望成为一个有趣味儿的人。 A golang developer ","date":"2020-11-19","objectID":"/about/:0:0","tags":null,"title":"About me","uri":"/about/"}]